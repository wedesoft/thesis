@pparticle{RefWorks:16,
	author={B. P. Amavasai and S. Meikle and R. B. Yates},
	year={2000},
	title={A robust vision system for micro-object manipulation},
	journal={Proceedings of the SPIE - The International Society for Optical Engineering},
	volume={4194},
	pages={112-120},
	note={M1: Copyright 2001, IEE},
	abstract={Semi-autonomous and fully autonomous assembly and manipulation of micro-objects is a complex process. As part of the MINIMAN micro-robot project, a vision subsystem is required which can recognise and track objects both under an optical microscope and within a scanning electron microscope. This subsystem is required as part of a more complex system for assembling and manipulating micro-objects. The two different operating environments provide many challenges when building a generic vision system due to the vast differences in the quality of the images. The paper provides a detailed description of this new vision system, together with a discussion and analysis of its flexibility and extensibility. Results of the system's ability to recognise rigid objects robust to camera noise and object occlusions are given, and the adaptability of the system to recognising biological objects is discussed. Finally, an overview is provided of the communication strategy between the vision subsystem and the micro-robot control system},
	keywords={force sensors; image sensors; industrial manipulators; microassembling; micromanipulators; microsensors; object recognition; robot vision; tactile sensors},
	isbn={0277-786X},
	url={http://dx.doi.org/10.1117/12.403691}
}

@article{RefWorks:18,
	author={B. P. Amavasai and R. B. Yates and S. Meikle},
	year={2000},
	month=nov,
	title={Vision control for a MEMS robotic system},
	journal={Measurement and Control},
	volume={33},
	number={9},
	pages={269-273},
	note={M1: Copyright 2000, IEE},
	abstract={MINIMAN is a European Union sponsored ESPIRIT basic research project which combines the expertise of six leading European academic institutions and two industrial companies. The three-year project (which started at the end of 1998) seeks to explore the possibility of using microrobots in real-world applications. Here the term microrobotics refers to the ability to manipulate and/or assemble objects that are micron-sized or larger. The robot itself is centimetres in size with a piezo-actuated drive and manipulation system providing the small and precise motion required. The complete system is controlled by an innovative vision system, with the vision sensor (camera) being mounted remotely from the robot. This vision subsystem must recognise, track and provide feedback position information regarding the discrete small objects that form a miniature assembly. Consequently the objects are magnified and the assembly task is performed under either an optical microscope or a scanning electron microscope},
	keywords={image sensors; microrobots; microsensors; mobile robots; piezoelectric actuators; robot vision},
	isbn={0020-2940}
}
@inproceedings{RefWorks:42,
	author={Fumihito Arai and Akiko Kawaji and Poom Luangjarmekorn and Toshio Fukuda and Kouichi Itoigawa},
	year={2001},
	month=may,
	title={Three-Dimensional Bio-Micromanipulation under the Microscope},
	booktitle={Proc. IEEE International Conference on Robotics \& Automation},
	pages={604-609},
	annote={\href{http://ieeexplore.ieee.org/iel5/7423/20179/00932616.pdf}{Recognition of focussed elliptical objects}}
}
@book{RefWorks:44,
	author={Axel BÃ¼rkle},
	year={2004},
	title={Optische 2,5D-Rekonstruktion mikroskopischer Objekte},
	publisher={Logos Verlag Berlin},
	note={note: "ISBN 3-8325-0468-0"}
}
@article{RefWorks:246,
	author={Jean-Philippe Bacher and Stefano Bottinelli and Jean-Marc Breguet and Reymond Clavel},
	year={2002},
	title={Delta$^3$: A new ultra-high precision micro-robot. Design and control of a flexure mechanism},
	journal={Journal Europeen des Systemes Automatises},
	volume={36},
	number={9},
	pages={1263-1275},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={In the fields of micro-positioning, micro-manipulation and micro-machining, the required motion precision is continuously increasing. The demand also increases for high dynamic performances (large bandwidth, high closed loop stiffness, etc.). In many cases an inappropriate mechanical structure prevents to achieve these objectives. The use of flexure mechanisms and parallel kinematics allows to reach them. Thanks to these choices, mechanical structures are light-weighted and free of backlash, wear, and stick-slip. This paper presents through an example, the design procedure and the control of a flexure-based robot. The example used is a three degrees of freedom (dof) parallel robot (X, Y, Z) that is a transposition in a flexure mechanism of the Delta robot kinematics.},
	keywords={Micromanipulators; Mobile robots; Flexible manipulators; Precision engineering; Motion control; Mechanisms; Kinematics; Degrees of freedom (mechanics); Micromachining},
	isbn={1269-6935}
}
@inproceedings{RefWorks:58,
	author={G. Begelman and M. Lifshits and E. Rivlin},
	year={2004},
	month=sep,
	title={Map-Based Microscope Positioning},
	booktitle={BMVC 2004},
	publisher={Technion, Israel},
	url={http://www.bmva.ac.uk/bmvc/2004/papers/paper_175.pdf}
}
@inproceedings{RefWorks:164,
	author={Fariborz Behi and Mehran Mehregany and Kaigham J. Gabriel},
	year={1990},
	title={A microfabricated three-degree-of-freedom parallel mechanism},
	booktitle={Proceedings - IEEE Micro Electro Mechanical Systems: An Investigation of Micro Structures, Sensors, Actuators, Machines and Robots, Feb 11-14 1990},
	publisher={Publ by IEEE, Piscataway, NJ, USA},
	address={Napa Valley, CA, USA},
	organization={AT&T Bell Lab, Holmdel, NJ, USA},
	pages={159-165},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={A microfabricated, three-degree-of-freedom, passive, closed-chain, planar mechanism with the potential for low-torque precision positioning applications is presented. A parallel-link mechanism design is selected rather than a serial-link implementation, since parallel-link mechanisms can operate with stationary actuators and are more rigid than their serial counterparts. Polysilicon surface micromachining is used to fabricate a mechanism which has a total area of 0.13 mm0RW1S34RfeSDcfkexd09rT321RW1S34RfeSDcfkexd09rT3 and a workspace of approximately 0.01 mm0RW1S34RfeSDcfkexd09rT321RW1S34RfeSDcfkexd09rT3. The fabrication process for the mechanism is described, identifying the effect on device performance of constraints imposed by the microfabrication; most notably joint clearances, component nonplanarity, and residual-stress-induced linkage deformations. The requisite formulations for the kinematics and dynamics of the device are presented which, in conjunction with the documented measurements of friction on structures of similar geometry and material, indicate that the dominant torque loads are due to friction.},
	keywords={Electromechanical Devices -- Microelectromechanical; Mechanisms--Degrees of Freedom; Control, Mechanical Variables--Position; Microelectronics--Machining; Kinematics; Materials Handling--Manipulators},
	url={http://dx.doi.org/10.1109/MEMSYS.1990.110269}
}
@article{RefWorks:27,
	author={Serge Belongie and Jitendra Malik and Jan Puzicha},
	year={2002},
	title={Shape matching and object recognition using shape contexts},
	journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
	volume={24},
	number={4},
	pages={509-522},
	note={Compilation and indexing terms, Copyright 2005 Elsevier Engineering Information, Inc.},
	abstract={We present a novel approach to measuring similarity between shapes and exploit it for object recognition. In our framework, the measurement of similarity is preceded by 1) solving for correspondences between points on the two shapes, 2) using the correspondences to estimate an aligning transform. In order to solve the correspondence problem, we attach a descriptor, the shape context, to each point. The shape context at a reference point captures the distribution of the remaining points relative to it, thus offering a globally discriminative characterization. Corresponding points on two similar shapes will have similar shape contexts, enabling us to solve for correspondences as an optimal assignment problem. Given the point correspondences, we estimate the transformation that best aligns the two shapes; regularized thin-plate splines provide a flexible class of transformation maps for this purpose. The dissimilarity between the two shapes is computed as a sum of matching errors between corresponding points, together with a term measuring the magnitude of the aligning transform. We treat recognition in a nearest-neighbor classification framework as the problem of finding the stored prototype shape that is maximally similar to that in the image. Results are presented for silhouettes, trademarks, handwritten digits, and the COIL data set.},
	keywords={Computer vision; Approximation theory; Computational methods; Probability; Problem solving; Algorithms; Object recognition},
	isbn={0162-8828},
	url={http://dx.doi.org/10.1109/34.993558}
}
@inproceedings{RefWorks:111,
	author={G. Benner and J. Frey and M. Rob-Mebemer and W. Probst},
	year={1994},
        month=aug,
	title={New computer-powered TEM with unique imaging capabilities},
	booktitle={Proceedings of the 52nd Annual Meeting of the Microscopy Society of America, Jul 31-Aug 5 1994},
	series={Proceedings - Annual Meeting, Microscopy Society of America},
	address={New Orleans, LA, USA},
	organization={Carl Zeiss, Oberkochen, Germany},
	pages={490-491},
	note={Compilation and indexing terms, Copyright 2005 Elsevier Engineering Information, Inc.},
	abstract={The unique imaging capabilities of Zeiss EM 906, a computer-powered transmission electron microscope, is described. The computer network consists of a DOS-compatible system computer, four subsystems controlled by separate microprocessor and a flexible data and program memory. The computer compensates the continuous variation of the selected electron optical parameter through the use of a polynomial function to calculate intermediate values for every lens. The continuous zoom system was applied in the EM 906 to implement a continuous magnification zoom and a continuous brightness zoom.},
	keywords={Imaging techniques; Computer networks; Microprocessor chips; Data storage equipment; Electron optics; Electron lenses; Polynomials; Image processing; Interpolation; Approximation theory; Transmission electron microscopy},
	isbn={0424-8201}
}
@inproceedings{RefWorks:47,
	author={A. Bergander and W. Driesen and T. Varidel and M. Meizoso and J. -M Breguet},
	year={2004},
	month=sep,
	title={Mobile cm$^3$-microrobots with tools for nanoscale imaging and micromanipulation},
	booktitle={Mechatronics \& Robotics 2004},
	publisher={IEEE Industrial Electronics Society; APS - European Centre for Mechatronics},
	note={Platform, rotary actuators and atomic-force experiment}
}
@inproceedings{RefWorks:125,
	author={S. S. Bhasin and S. Chaudhuri},
	year={2001},
	title={Depth from defocus in presence of partial self occlusion},
	booktitle={8th International Conference on Computer Vision, Jul 9-12 2001},
	series={Proceedings of the IEEE International Conference on Computer Vision},
	publisher={Institute of Electrical and Electronics Engineers Inc},
	address={Vancouver, BC},
	organization={Department of Electrical Engineering, Indian Inst. of Technol.-Bombay, Mumbai, 400076, India},
	volume={1},
	pages={488-493},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={Contrary to the normal belief we show that self occlusion is present in any real aperture image and we present a method on how we can take care of the occlusion while recovering the depth using the defocus as the cue. The space-variant blur is modeled as an MRF and the MAP estimates are obtained for both the depth map and the everywhere focused intensity image. The blur kernel is adjusted in the regions where occlusion is present, particularly at the regions of discontinuities in the scene. The performance of the proposed algorithm is tested over synthetic data and the estimates are found to be better than the earlier schemes where such subtle effects were ignored.},
	keywords={Computer vision; Image processing; Focusing; Cameras; Algorithms; Image quality; Parameter estimation; Optical transfer function; Computer simulation},
	url={http://dx.doi.org/10.1109/ICCV.2001.937556}
}
@techreport{RefWorks:38,
	author={Ilya Blayvas and Roman Goldenberg and Michael Lifshits and Michael Rudzsky and Ehud Rivlin},
	year={2003},
	month=jul,
	title={Geometric Hashing: Rehashing for Bayesian Voting},
	institute={Computer Science Department, Technion Israel Institute of Technology},
        url={http://www.cs.technion.ac.il/users/wwwb/cgi-bin/tr-get.cgi/2003/CIS/CIS-2003-07.pdf},
	annote={study on optimal bin-size for geometric hashing}
}

@article{RefWorks:63,
	author={T. Boland and E. E. Johnston and A. Huber and B. D. Ratner},
	year={1998},
	title={Recognition and Nanolithography with the Atomic Force Microscope},
	journal={ACS Symposium Series},
	volume={694},
	pages={342-350}
}
@article{RefWorks:65,
	author={T. Boland and E. E. Johnston and B. D. Ratner},
	year={1996},
	title={Recognition and nanolithography with the atomic force microscope},
	journal={American Chemical Society, Polymer Preprints, Division of Polymer Chemistry},
	volume={37},
	number={2},
	pages={593-594}
}
@inproceedings{RefWorks:31,
	author={Robert C. Bolles and Martin A. Fischler},
	year={1981},
	title={RANSAC-BASED APPROACH TO MODEL FITTING AND ITS APPLICATION TO FINDING CYLINDERS IN RANGE DATA},
	booktitle={Proceedings of the 7th International Joint Conference on Artificial Intelligence.},
	address={Vancouver, BC, Can},
	organization={SRI, Menlo Park, Calif, USA},
	volume={2},
	pages={637-643},
	note={Compilation and indexing terms, Copyright 2005 Elsevier Engineering Information, Inc.},
        url={dli.iiit.ac.in/ijcai/IJCAI-81-VOL-2/PDF/009.pdf},
	keywords={PATTERN RECOGNITION SYSTEMS}
}
@inproceedings{RefWorks:84,
	author={Y. Shan and B. Matei and H. S. Sawhney and R. Kumar and D. Huber and M. Hebert},
	year={2004},
	title={Linear model hashing and batch RANSAC for rapid and accurate object recognition},
	booktitle={Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 27 June-2 July 2004},
	series={Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
	publisher={IEEE Comput. Soc},
	address={Washington, DC, USA},
	organization={Sarnoff Corp., Princeton, NJ, USA;},
	volume={2},
	pages={121-128},
	note={M1: Copyright 2004, IEE},
	abstract={This paper proposes a joint feature-based model indexing and geometric  constraint based alignment pipeline for efficient and accurate  recognition of 3D objects from a large model database. Traditional  approaches either first prune the model database using indexing without  geometric alignment or directly perform recognition based alignment.  The indexing based pruning methods without geometric constraints can  miss the correct models under imperfections such as noise, clutter and  obscurations. Alignment based verification methods have to linearly  verify each model in the database and hence do not scale up. The  proposed techniques use spin images as semi-local shape descriptors and  locality-sensitive hashing (LSH) to index into a joint spin image  database for all the models. The indexed models represented in the  pruned set are further pruned using progressively complex geometric  constraints. A simple geometric configuration of multiple spin images,  for instance a doublet, is first used to check for geometric  consistency. Subsequently, full Euclidean geometric constraints are  applied using RANSAC-based techniques on the pruned spin images and the  models to verify specific object identity. As a result, the combined  indexing and geometric alignment based pipeline is able to focus on  matching the most promising models, and generate far less pose  hypotheses while maintaining the same level of performance as the  sequential alignment based recognition. Furthermore, compared to  geometric indexing techniques like geometric hashing, the construction  time and storage complexity for the proposed technique remains linear  in the number of features rather than higher order polynomial.  Experiments on a 56 3D model database show promising results},
	keywords={computer vision; image recognition; image representation; image sequences; object detection; very large databases; visual databases},
	isbn={0 7695 2158 4},
        url=http://www.ri.cmu.edu/pub\_files/pub4/shan\_y\_2004\_1/shan\_y\_2004\_1.pdf}
}
@inproceedings{RefWorks:130,
	author={Christoph Brein},
	year={2005},
	title={Segmentation of cartridge cases based on illumination and focus series},
	booktitle={Proceedings of SPIE-IS and T Electronic Imaging - Image and Video Communications and Processing 2005, Jan 18-20 2005},
	series={Proceedings of SPIE - The International Society for Optical Engineering},
	publisher={International Society for Optical Engineering, Bellingham, WA 98227-0010, United States},
	address={San Jose, CA, United States},
	organization={Institut fur Mess- und Regelungstechnik, Universitat Karlsruhe (TH), D-76128 Karlsruhe, Germany},
	volume={5685},
	chapter={PART 1},
	pages={228-238},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={Cartridge cases are important forensic specimen for the identification of weapons. The illumination conditions in the area of the firing pin marks and the breech face marks are very different and have to be treated separately to achieve an appropriate image quality for a visual inspection. Furthermore, not only the comparison but also the detection of the different and independent forensic marks should be automated. Both problems lead to the task of segmenting the different parts of the cartridge case bottom. In this paper, two automated approaches for the segmentation of cartridge cases are investigated and compared. The aim of the segmentation is the detection of the cartridge case border, the primer, the firing pin mark and additionally the letters around the primer. The first approach uses images obtained under systematically varied illumination conditions. After a preprocessing step a circle detection is applied to find the circular structures. The analysis of illumination series combined with a connected components labeling method detect the letters. In a second approach, the depth-from-focus method is used to obtain 21/2D-data. This data is segmented applying a plane estimation technique. This results directly in the detection of the letters. Afterwards a circle detection algorithm identifies the parameters of the circular structures. With the introduced methods it is possible to optimize the illumination in order to realize a higher contrast of both the striation marks on the cartridge case surface and of the indentation of the firing pin independently. The improved image quality helps the examiner in identifying weapons and will help to improve the automated comparison strategies. &copy; 2005 SPIE and IS and T.},
	keywords={Image segmentation; Lighting; Image quality; Feature extraction; Parameter estimation; Least squares approximations; Errors; Hough transforms; Random processes; Mathematical operators; Optimization; Algorithms},
	isbn={0277-786X},
	url={http://dx.doi.org/10.1117/12.585763}
}
@inproceedings{RefWorks:154,
	author={H. Benjamin Brown and Patrick M. Muir and Alfred A. Rizzi and Maria C. Sensi and Ralph L. Hollis},
	year={2001},
	title={A precision manipulatory module for assembly in minifactory environment},
	booktitle={2001 IEEE/RSJ International Conference on Intelligent Robots and Systems, Oct 29-Nov 3 2001},
	publisher={Institute of Electrical and Electronics Engineers Inc},
	address={Maui, HI},
	organization={The Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, United States},
	volume={2},
	pages={1030-1035},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={In this paper we describe mechanical and electronic design of a precision, 2-DOF robot manipulator. The manipulator is one of a wide variety of modular robotic agents in the minifactory, a rapidly depoyable precision assembly system under development in our laboratory. The manipulator, in cooperation with another type of 2-DOF robot, termed a courier, can perform 4-DOF assembly operations emulating a SCARA. This arrangement provides increased precision, higher throughput, smaller footprint, and increased flexibility relative to the SCARA.},
	keywords={Manipulators; Degrees of freedom (mechanics); Robotic assembly; Modular robots; Systems analysis; End effectors; Computer operating systems; Three term control systems},
	url={http://dx.doi.org/10.1109/IROS.2001.976304}
}
@inproceedings{RefWorks:177,
	author={A. Buerkle and S. Fatikow},
	year={2000},
	title={Laser measuring system for a flexible microrobot-based micromanipulation station},
	booktitle={2000 IEEE/RSJ International Conference on Intelligent Robots and Systems, Oct 31-Nov 5 2000},
	publisher={Institute of Electrical and Electronics Engineers Inc},
	address={Takamatsu},
	organization={Universita&die;t Karlsruhe (TH), Computer Science Department, IPR, D-76128 Karlsruhe, Germany},
	volume={1},
	pages={799-804},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={There is an increasing interest in performing assembly of microsystems (i.e. non-destructive transportation, precise manipulation, and exact positioning of microcomponents) by flexible microrobots. A microrobot-based microassembly desktop station is being developed at the University of Karlsruhe. In this paper, new implementation results of a computer vision based automatic control system of a mobile microrobot with an integrated flexible manipulator are discussed. The operations of the robot manipulator take place under a microscope equipped with a CCD-camera. A major drawback of this system is its lack of depth information. For this reason, the sensor system has been enhanced by a line laser, using laser triangulation. The set-up of the modified sensor system is described. The measuring principle is based on a method called sheet of light triangulation, a variation of standard triangulation. This approach is described in detail; its advantages and limitations are discussed.},
	keywords={Flexible manipulators; Robots; Cameras; Triangulation; Sensors}
}
@inproceedings{RefWorks:17,
	author={A. Burkle and F. Schmoeckel and H. Worn and B. P. Amavasai and F. Caparrelli and J. R. Travis},
	year={2001},
	title={A versatile vision system for micromanipulation tasks},
	booktitle={Proceedings on International Conference on Multi-Sensor Fusion and Integration for Intelligent Systems, 20-22 Aug. 2001},
	series={Conference Documentation International Conference on Multisensor Fusion and Integration for Intelligent Systems. MFI 2001 (Cat. No.01TH8590)},
	publisher={VDI/VDE Soc. Meas. & Autom. Control},
	address={Baden-Baden, Germany},
	organization={Fak. fur Inf., Karlsruhe Univ., Germany;},
	pages={271-276},
	note={M1: Copyright 2002, IEE},
	abstract={Semi-autonomous and fully autonomous assembly and manipulation of micro-objects is a complex process. To this purpose, flexible microrobot systems have been designed and developed. These robots are generally required to operate in a wide range of environments to perform tasks such as microassembly, cell manipulation and particle grasping. As part of the MINIMAN project, a flexible microrobot system has been developed which can operate under a light microscope as well as in the chamber of a scanning electron microscope (SEM). This system is highly flexible, reconfigurable and uses a wide range of sensor information (force, tactile and vision) in a closed-loop controlled strategy. The paper presents an overview of the vision system and its architecture for vision-controlled micromanipulation. The different modules of the vision system and the communication interface to the control system are herewith described in detail},
	keywords={closed loop systems; flexible manipulators; microassembling; micromanipulators; object recognition; position control; robot vision},
	isbn={3 00 008260 3},
	url={http://dx.doi.org/10.1109/MFI.2001.1013546}
}
@article{RefWorks:67,
	author={X. Y. Cai and S. Christie and F. Kvasnik},
	year={1991},
	title={Micro-pattern recognition using a microscope coherent optical processor (M-COP)},
	journal={IEE Conference Publication},
	number={342},
	pages={226-230}
}
@inproceedings{RefWorks:26,
	author={Gustavo Carneiro and Allan D. Jepson},
	year={2004},
	title={Pruning local feature correspondences using shape context},
	booktitle={Proceedings of the 17th International Conference on Pattern Recognition, ICPR 2004, Aug 23-26 2004},
	series={Proceedings - International Conference on Pattern Recognition},
	publisher={Institute of Electrical and Electronics Engineers Inc., Piscataway, NJ 08855-1331, United States},
	address={Cambridge, United Kingdom},
	organization={Department of Computer Science, University of Toronto, Toronto, Ont., Canada},
	volume={3},
	pages={16-19},
	note={Compilation and indexing terms, Copyright 2005 Elsevier Engineering Information, Inc.},
	abstract={We propose a novel approach to improve the distinctiveness of local image features without significantly affecting their robustness with respect to image deformations. Local image features have proven to be successful in computer vision tasks involving partial occlusion, background noise, and various types of image deformations. However, the relatively high number of outliers that have to be rejected from the correspondences set, formed during the search for similar features, still plagues this approach. The task of rejecting outliers is usually based on estimating the global spatial transform suffered by the features in the correspondences set. This presents two problems: i) it cannot properly deal with non-rigid objects, and ii) it is sensitive to a high number of outliers. Here, we address these problems by combining typical local features [2, 7] with shape context [1]. A performance evaluation shows that this new semi-local feature generally provides higher distinctiveness and robustness to image deformations, thus potentially increasing the inlier/ outlier ratio in the correspondences set. Also, we show that in wide baseline stereo matching, and non-rigid motion applications, the use of the novel semi-local feature not only provides robustness to non-rigid deformations, but also produces a higher inlier/outlier ratio than the standard Hough clustering of the global spatial transform of parameters.},
	keywords={Computer vision; Computational geometry; Robustness (control systems); Performance; Evaluation; Image processing; Hough transforms; Mathematical models; Feature extraction},
	isbn={1051-4651}
}
@inproceedings{RefWorks:151,
	author={I. Chartier and C. Bory and A. Fuchs and D. Freida and N. Manaresi and M. Ruty and J. Bablet and K. Gilbert and N. Sarrut and F. Baleras and Ch Villiers and L. Fulbert},
	year={2004},
	title={Fabrication of hybrid plastic-silicon micro-fluidic devices for individual cell manipulation by dielectrophoresis},
	booktitle={Microfluidics, BioMEMS, and Medical Microsystems II, Jan 26-27 2004},
	series={Proceedings of SPIE - The International Society for Optical Engineering},
	publisher={International Society for Optical Engineering, Bellingham, WA 98227-0010, United States},
	address={San Jose, CA., United States},
	organization={CEA-Leti, BioChip lab, 38054 Grenoble, France},
	volume={5345},
	pages={7-16},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={During the last decade, world-wide developments in micro-fabrication technologies have led to numerous Lab-On-a-Chip (LOC) micro-systems covering a wide spectrum of biotechnological applications. Although early LOC developments were driven by glass and silicon micro-fabrication techniques, in recent years polymeric-based LOC have been intensively developed. Taking advantage of each material, a hybrid device associating an active silicon chip with a passive polymeric micro-part has been developed to produce an addressable Cell-chip for individual cell manipulation and sorting. The complete hybrid micro-fluidic device fabrication is described here, including polymer structuring, hermetical sealing, biocompatibility studies, and fluidic interconnections with the sample as well as detection aspects. The cell manipulation is based on dielectrophoresis, which allows cell motion without fluid flow. First biological results will be presented.},
	keywords={Microelectromechanical devices; Fluidic devices; Silicon; Biomedical engineering; Cells; Electrophoresis; Polymers; Biocompatibility},
	isbn={0277-786X},
	url={http://dx.doi.org/10.1117/12.530705}
}
@article{RefWorks:136,
	author={Surajit Chaudhuri and Zhiyuan Chen and Kyuseok Shim and Yuqing Wu},
	year={2005},
	title={Storing XML (with XSD) in SQL databases: Interplay of logical and physical designs},
	journal={IEEE Transactions on Knowledge and Data Engineering},
	volume={17},
	number={12},
	pages={1595-1609},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={Much of business XML data has accompanying XSD specifications. In many scenarios, "shredding" such XML data into a relational storage is a popular paradigm. Optimizing evaluation of XPath queries over such XML data requires paying careful attention to both the logical and physical designs of the relational database where XML data is shredded. None of the existing solutions has taken into account physical design of the generated relational database. In this paper, we study the interplay of logical and physical design and conclude that 1) solving them independently leads to suboptimal performance and 2) there is substantial overlap between logical and physical designs: some well-known logical design transformations generate the same mappings as physical design. Furthermore, existing search algorithms are inefficient to search the extremely large space of logical and physical design combinations. We propose a search algorithm that carefully avoids searching duplicated mappings and utilizes the workload information to further prune the search space. Experimental results confirm the effectiveness of our approach. &copy; 2005 IEEE.},
	keywords={Relational database systems; XML; Data acquisition; Query languages; Algorithms; Mathematical transformations; Optimization},
	isbn={1041-4347},
	url={http://dx.doi.org/10.1109/TKDE.2005.204}
}
@inproceedings{RefWorks:155,
	author={Michael L. Chen and Shinji Kume and Alfred A. Rizzi and Ralph L. Hollis},
	year={2000},
	title={Visually guided coordination for distributed precision assembly},
	booktitle={ICRA 2000: IEEE International Conference on Robotics and Automation, Apr 24-Apr 28 2000},
	publisher={Institute of Electrical and Electronics Engineers Inc., Piscataway, NJ, USA},
	address={San Francisco, CA, USA},
	organization={Carnegie Mellon Univ, Pittsburgh, PA, USA},
	volume={2},
	pages={1651-1656},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={We document our initial efforts to instantiate visually-guided cooperative behaviors between robotic agents in the minifactory environment. Minifactory incorporates high-precision 2-DOF robotic agents to perform micron-level precision 4-DOF assembly tasks. Here we utilize two minifactory agents to perform visual servoing. We present a detailed description of the control and communication systems used to coordinate the agents. To provide a suitable communications infrastructure, we describe the development of a new inter-agent communication system which uses low-latency protocols carried by a commercial 100 Mb Ethernet network. Finally, we conclude by presenting experimental results from our first coordinated multi-agent task, the visually guided positioning of a small medical device.},
	keywords={Robotics; Precision engineering; Degrees of freedom (mechanics); Servomechanisms; Robotic assembly; Distributed computer systems; Image processing; Algorithms; Computer vision; Hough transforms},
	isbn={1050-4729},
	url={http://dx.doi.org/10.1109/ROBOT.2000.844833}
}
@article{RefWorks:146,
	author={Changhyun Cho and Sungchul Kang and Munsang Kim and Jae-Bok Song},
	year={2005},
	title={Macro-micro manipulation with visual tracking and its application to wheel assembly},
	journal={International Journal of Control, Automation and Systems},
	volume={3},
	number={3},
	pages={461-468},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={This paper proposes a wheel-assembly automation system, which assembles a wheel into a hub of a vehicle hung to a moving hanger in a car manufacturing line. A macro-micro manipulator control strategy is introduced to increase the system bandwidth and tracking accuracy to ensure insertion tolerance. A camera is equipped at the newly designed wheel gripper, which is attached at the center of the end-effector of the macro-micro manipulator and is used to measure position error of the hub of the vehicle in real time. The redundancy problem in the macro-micro manipulator is solved without complicated calculation by assigning proper functions to each part so that the macro part tracks the velocity error while the micro part regulates the fine position error. Experimental results indicate that tracking error satisfies the insertion tolerance of assembly (&plusmn; 1mm), and thus it is verified that the proposed system can be applied to the wheel assembly task on a moving hanger in the manufacturing line.},
	keywords={Manipulators; Automation; Error analysis; Real time systems; Conveyors; Functions; Cameras},
	isbn={1598-6446},
        url={http://www.ijcas.org/admin/paper/files/IJCAS_v3_n3_pp.461-468.pdf}
}
@article{RefWorks:139,
	author={Sung Yug Choi and Jang Myung Lee},
	year={2006/2/1},
	title={Applications of moving windows technique to autonomous vehicle navigation},
	journal={Image and Vision Computing},
	volume={24},
	number={2},
	pages={120-130},
	keywords={Moving window; Lane detection; Obstacle detection; Mobile robot; Corridor driving}
}
@inproceedings{RefWorks:126,
	author={Ugur Cilingiroglu and Emre Cilingiroglu and Sicheng Chen and B. Siddik Yarman},
	year={2003},
	title={Real-time range sensing with a Scheimpflug camera and a single custom sensor/processor chip},
	booktitle={Real Time Imaging VII, Jan 22-23 2003},
	series={Proceedings of SPIE - The International Society for Optical Engineering},
	publisher={The International Society for Optical Engineering},
	address={Santa Clara, CA, United States},
	organization={Texas A and M University, Electrical Engineering Department, 3128 TAMU, College Station, TX 77843-3128, United States},
	volume={5012},
	pages={110-121},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={An image-based range sensing technique is presented. The technique is originally considered for highway collision avoidance applications but its generality makes it suitable for application in robotics, manufacturing and metrology as well. It relies on depth from focus but, unlike conventional techniques, it extracts range with a single unmodulated Scheimpflug camera in continuous time. The range extraction algorithm is memoryless and simple enough to be implemented on the same chip with photosensors. The technique deploys a sensor plane that is tilted at a non-orthogonal angle with respect to the optical axis of the lens, and the optical axis intersects the sensor plane at the focal point. This optical arrangement creates a focusable object plane in an orientation parallel to the optical axis, and thus, enables range sensing along the same axis. The paper elaborates on the details of focus sensing on the tilted sensor plane, describes the CMOS sensor/processor chip designed and prototyped for this application, and presents experimental results.},
	keywords={Image processing; Range finding; Real time systems; Cameras; Microprocessor chips; Collision avoidance; Robotics; Photosensitivity; CMOS integrated circuits},
	isbn={0277-786X},
	url={http://dx.doi.org/10.1117/12.477480}
}
@inproceedings{RefWorks:162,
	author={R. V. Dantu and N. J. Dimopoulos and R. V. Patel and A. J. Al-Khalili},
	year={1990},
	title={Micro-manipulators for automatic wafer probing},
	booktitle={Applications of Artificial Intelligence VIII, Apr 17-19 1990},
	publisher={Publ by Int Soc for Optical Engineering, Bellingham, WA, USA},
	address={Orlando, FL, USA},
	organization={Concordia Univ, Montreal, Que, Can},
	volume={1293 pt 2},
	pages={711-722},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={This paper deals with an important problem encountered in automating VLSI wafer probing. In this automation, vision is used for accurately guiding and lowering a probe to make contact with the wafer. The variance of pixel values of the probe and experimental observations are employed for determination of contact between the probe and the wafer. Analytical expressions are derived in the paper for the variance of the pixel values of the object with a uniform background and the variation of these values with respect to the distance of the object from the surface is studied. This relationship is experimentally verified for the detection of touch, when the probe is approaching the target pad.},
	keywords={Robots, Industrial -- Proximity Sensors; Computer Vision; Materials Handling - Manipulators; Semiconductor Device Testing},
	isbn={0277-786X; 0-8194-0344-X}
}
@inproceedings{RefWorks:33,
	author={Mayur Datar and Piotr Indyk and Nicole Immorlica and Vahab S. Mirrokni},
	year={2004},
	title={Locality-sensitive hashing scheme based on p-stable distributions},
	booktitle={Proceedings of the Twentieth Annual Symposium on Computational Geometry (SCG'04), Jun 9-11 2004},
	series={Proceedings of the Annual Symposium on Computational Geometry},
	publisher={Association for Computing Machinery, New York, NY 10036-5701, United States},
	address={Brooklyn, NY, United States},
	organization={Department of Computer Science, Stanford University, Stanford, CA, United States},
	pages={253-262},
	note={Compilation and indexing terms, Copyright 2005 Elsevier Engineering Information, Inc.},
	abstract={We present a novel Locality-Sensitive Hashing scheme for the Approximate Nearest Neighbor Problem under l0RW1S34RfeSDcfkexd09rT4p1RW1S34RfeSDcfkexd09rT4 norm, based on p-stable distributions. Our scheme improves the running time of the earlier algorithm for the case of the l0RW1S34RfeSDcfkexd09rT421RW1S34RfeSDcfkexd09rT4 norm. It also yields the first known provably efficient approximate NN algorithm for the case p less than or equal 1. We also show that the algorithm finds the exact near neigbhor in O(log n) time for data satisfying certain "bounded growth" condition. Unlike earlier schemes, our LSH scheme works directly on points in the Euclidean space without embeddings. Consequently, the resulting query time bound is free of large factors and is simple and easy to implement. Our experiments (on synthetic data sets) show that the our data structure is up to 40 times faster than kd-tree.},
	keywords={Data structures; Approximation theory; Computational geometry; Computational complexity; Data compression; Data mining; Information retrieval; Pattern recognition; Database systems; Algorithms; Computational methods},
	url={http://dx.doi.org/10.1145/997817.997857}
}
@article{RefWorks:138,
	author={M. M. David},
	year={2003},
	month=mar,
	title={ANSI SQL hierarchical processing can fully integrate native XML},
	journal={SIGMOD Record},
	volume={32},
	number={1},
	pages={41-46},
	note={M1: Copyright 2003, IEE},
	abstract={Most SQL-based XML vendor support is through interoperation and not integration. One reason for this is that XML is inherently hierarchical and SQL is supposedly not. This paper demonstrates how ANSI SQL along with its relational Cartesian product model can naturally perform complete and flexible hierarchical query processing. With this ANSI SQL inherent hierarchical processing capability, native XML data can be fully and seamlessly integrated into SQL processing and operated on at a full hierarchical level. This paper describes the basic stages involved in this hierarchical SQL processing: hierarchical data modeling, hierarchical working set creation, and hierarchical Cartesian product processing. These processes enable a complete relational, XML, and legacy data integration which maintains ANSI SQL compatibility even while performing the most complex multi-leg hierarchical processing, and includes the dynamic, direct, and controlled hierarchical joining of hierarchical structures. Also covered are ANSI SQL hierarchical support features: hierarchical SQL views, hierarchical data filtering, and hierarchical optimization. These make standard SQL a well rounded and complete hierarchical processor. With this full hierarchical level of processing established, it is shown how the relational Cartesian product engine can be seamlessly replaced with a hierarchical engine, greatly increasing processing and memory utilization, and enabling advanced XML hierarchical data capabilities},
	keywords={ANSI standards; data models; hypermedia markup languages; query processing; relational databases; SQL},
	isbn={0163-5808}
}
@inproceedings{RefWorks:15,
	author={J. Domingo and M. Puig-Vidal and J. Lopez and J. Samitier},
	year={1999},
	title={Nonlinear control system based on fuzzy logic technique applied to drive piezoactuators for micro robotic applications MINIMAN: MINIaturised robot for micro MANipulation},
	booktitle={1999 7th IEEE Conference on Emerging Technologies and Factory Automation. Proceedings ETFA'99, 18-21 Oct. 1999},
	series={1999 7th IEEE International Conference on Emerging Technologies and Factory Automation. Proceedings ETFA '99 (Cat. No.99TH8467)},
	publisher={IEEE},
	address={Barcelona, Spain},
	organization={Dept. of Electron., Barcelona Univ., Spain},
	volume={1},
	pages={559-563},
	note={M1: Copyright 2000, IEE},
	abstract={Today several tasks in applications ranging from biology and medicine to microsystems technology demand for high-precision handling techniques. Transport and manipulation of biological cells or assembly of micromechanical parts are important applications for microrobots. A lot of these tasks have to be carried out by humans, but the manual capabilities are restricted to certain tolerances. So manual operation imposes severe restrictions on high quality production because of drastically miniaturised mechanical systems. In the last five years, researchers have developed new micromanipulation systems for applications in industry, biology or medicine. All of them work as telemanipulation systems and the robot, with miniaturised end effectors, is directly operated by the user. The aim of this work-in-progress manuscript is to present the state of our work in the micromanipulation control of a micro gripper. Due to the high resolution restrictions, this micro gripper is based in piezoceramic material and the control system is performed using fuzzy logic techniques},
	keywords={fuzzy control; micromanipulators; microrobots; nonlinear control systems; piezoelectric actuators},
	isbn={0 7803 5670 5},
	url={http://dx.doi.org/10.1109/ETFA.1999.815404}
}
@inproceedings{RefWorks:41,
	author={W. Driesen and T. Varidel and S. RÃ©gnier and J. -M Breguet},
	year={2004},
	month=oct,
	title={Micro manipulation by adhesion with two collaborating mobile micro robots},
	booktitle={Proceedings of the 4th International Workshop on Microfactories (IWMF)},
	url={http://microrobotics.epfl.ch/pdf/Adhesion\_IWMF04.pdf},
        annote={Transfering pollen micro sphere with two manipulators}
}
@inproceedings{RefWorks:122,
	author={Toshihito Egami and Shunichiro Oe and Kenji Terada and Toshiyuki Kashiwagi},
	year={2001},
	title={Three dimensional measurement using color image and movable CCD system},
	booktitle={27th Annual Conference of the IEEE Industrial Electronics Society IECON'2001, Nov 29-Dec 2 2001},
	series={IECON Proceedings (Industrial Electronics Conference)},
	publisher={Institute of Electrical and Electronics Engineers Computer Society},
	address={Denver, CO},
	organization={Dept. of Info. Sci. and Intell. Syst, Faculty of Engineering, Tokushima University, Minami-josanjima, Tokushima-shi, Japan},
	volume={1},
	pages={1932-1936},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={This paper deals with a new distance measurement method of color images by using an RGB color histogram. We measure the distance based on the principle of Depth-from-focus. It needs to detect focal position among many images with different focusing position. Our method is based that the more focal area has the less color frequency. By this method, we detect the focal area without using spatial frequency as conventional methods. The validity of our method is verified by some experimental results.},
	keywords={Color image processing; Charge coupled devices; Focusing; Distance measurement; Geometrical optics; Lenses; Image segmentation; Light reflection; Edge detection; Three dimensional},
	url={http://dx.doi.org/10.1109/IECON.2001.975586}
}
@article{RefWorks:184,
	author={R. Estana and J. Seyfried and F. Schmoeckel and M. Thiel and A. Buerkle and H. Woern},
	year={2004},
	title={Exploring the micro- and nanoworld with cubic centimetre-sized autonomous microrobots},
	journal={Industrial Robot},
	volume={31},
	number={2},
	pages={159-178},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={In order to bridge the increasing gap between the micro- and nanotechnologies, a European consortium is currently developing and investigating a cluster of mobile, wireless cubic centimetre-sized microrobots. The control and sensor issues which are to be solved for such a robot system are demanding. This paper describes the work carried out by one of the project partners. An interferometrical principle employing the so-called "mechanical" interferometer based on the Moire-effect is used for the position sensor system. Further sensor systems involve "local" microscope cameras, for which the extraction of depth information is crucial.},
	keywords={Nanotechnology; Robotics; Sensors; Robots; Light emitting diodes; Interferometry; Manipulators; Interferometers; Cameras; Computer software; Error analysis; Algorithms},
	isbn={0143-991X},
	url={http://dx.doi.org/10.1108/01439910410522847}
}
@inproceedings{RefWorks:187,
	author={S. Fahlbusch and D. D'Attanasio and S. Fatikow and H. Woern and P. Dario},
	year={1998},
	title={Force sensing in microrobotic systems-a brief overview and first experimental results},
	booktitle={Proceedings of MME'98. Micromechanics Europe, 3-5 June 1998},
	series={Ninth Micromechanics Europe Workshop. MME'98. Proceedings},
	publisher={SINTEF},
	address={Ulvik, Norway},
	organization={Inst. for Process Control & Robotics, Karlsruhe Univ., Germany},
	pages={167-70},
	note={M1: Copyright 1999, IEE},
	abstract={This paper describes available methods of force sensing and gives an overview about the current research work in the field of micro force sensors, which is one of the important objectives during manipulation of microobjects. Small sizes of microparts and end-effectors in &mu;m or even nm range make it difficult to find an optimal solution in terms of accuracy, sensitivity and cost of the sensor equipment. A prototype of a force sensor based on strain gauges has been realised and its repeatability, precision and linearity quantified. A simple method that links system parameters and system performance is presented and verified, concerning cantilever type end-effectors for microgrippers},
	keywords={dexterous manipulators; force sensors; micromanipulators; microsensors; strain gauges}
}
@inproceedings{RefWorks:185,
	author={S. Fahlbusch and T. Doll and W. Kammrath and K. Weiss and S. Fatikow and J. Seyfried},
	year={2000},
	title={Development of a flexible piezoelectric micro-robot for the handling of micro-objects},
	booktitle={Proceedings of 7th International Conference on New Actuators - ACTUATOR 2000, 19-21 June 2000},
	series={ACTUATOR 2000. 7th International Conference on New Actuators and International Exhibition on Smart Actuators and Drive Systems. Conference Proceedings},
	publisher={MESSE BREMEN GMBH},
	address={Bremen, Germany},
	organization={Inst. for Process Control & Robotics, Karlsruhe Univ., Germany},
	pages={431-434},
	note={M1: Copyright 2002, IEE},
	abstract={Microsystems can be divided into monolithic and hybrid microsystems. Monolithic microsystems are built by numerous fabrication steps on one substrate, each step adding a new layer or structuring an existing layer of the microsystem. Monolithic microsystems require almost no assembly besides their integration into a macro-system. Hybrid microsystems, on the other hand, are manufactured by a much broader range of micro-techniques, because parts are assembled to form the final microsystem after their manufacturing. Hybrid microsystems demand for micro-assembly techniques which might become very complex, depending on the complexity of the system. In this paper, a new micro-robot, RobotMan, is presented which includes sensors for position and force measurement. This robot combines two different actuator concepts, piezoelectric positioning elements and electromagnetic micromotors, to enable high-precision manipulation of micro-objects},
	keywords={dexterous manipulators; electromagnetic actuators; flexible manipulators; force sensors; microactuators; micromanipulators; micromotors; micropositioning; microrobots; piezoelectric actuators},
	isbn={3 933339 02 2}
}
@inproceedings{RefWorks:13,
	author={S. Fahlbusch and S. Fatikow and J. Seyfried and A. Buerkle},
	year={1999},
	title={Flexible microrobotic system MINIMAN: design, actuation principle and control},
	booktitle={1999 IEEE/ASME International Conference on Advanced Intelligent Mechatronics, 19-23 Sept. 1999},
	series={1999 IEEE/ASME International Conference on Advanced Intelligent Mechatronics (Cat. No.99TH8399)},
	publisher={IEEE},
	address={Atlanta, GA, USA},
	organization={Inst. for Process Control & Robotics, Karlsruhe Univ., Germany},
	pages={156-161},
	note={M1: Copyright 1999, IEE},
	abstract={Microsystem technology demands for advanced manipulation facilities which can assemble complex microsystems consisting of many single components (i.e. hybrid microsystems). To perform fully automated microassembly, problems specific to the handling of micro parts have to be considered. It is necessary to introduce flexible, highly precise and fast microassembly methods. Therefore, different microrobots, which offer the possibility to carry out an assembly process under a light optical microscope with a motion resolution of up to 20 nm and speeds of up to 3 cm/s, have been developed by an interdisciplinary research group at the University of Karlsruhe. These robots are embedded into a microassembly desktop station. The paper presents the design, actuation principle and control of the flexible microrobotic system MINIMAN},
	keywords={assembly planning; computer vision; flexible manipulators; microactuators; microassembling; micromanipulators; piezoelectric actuators},
	isbn={0 7803 5038 3},
	url={http://dx.doi.org/10.1109/AIM.1999.803159}
}
@inproceedings{RefWorks:201,
	author={S. Fatikow},
	year={1996},
	title={A microrobot-based automatic desk-station for assembly of micromachines},
	booktitle={Proceedings of 12th International Conference on CAD/CAM Robotics and Factories of the Future, 14-16 Aug. 1996},
	series={Proceedings of the Twelfth International Conference on CAD/CAM Robotics and Factories of the Future},
	publisher={Middlesex Univ. Press},
	address={London, UK},
	organization={Inst. for Real-Time Comput. Syst. & Robotics, Karlsruhe Univ., Germany},
	pages={174-179},
	note={M1: Copyright 1997, IEE},
	abstract={This paper presents an automated micromanipulation desk-station for microassembly tasks including a piezoelectrically driven microrobot placed on a high-precision x-y-stage of a light microscope, a CCD-camera as a local sensor subsystem, a laser sensor unit as a global sensor subsystem, and a Pentium PC equipped additionally with a frame grabber. The microrobot has three piezoelectrically driven legs and two autonomous manipulators; it can perform high-precision manipulations (with an accuracy of up to 10 nm) and a nondestructive transport (at a speed of several mm/sec) of very small objects under a microscope. To control the robot automatically a new control system concept, including a task planning level and a real-time execution level, is being developed. Apart from micro assembly tasks the station can be used for handling biological cells or testing silicon chips},
	keywords={CCD image sensors; industrial manipulators; laser beam applications; microassembling; micromechanical devices; optical microscopes; piezoceramics; piezoelectric devices; position control; robot vision}
}
@inproceedings{RefWorks:200,
	author={S. Fatikow and M. Benz},
	year={1998},
	month={04/30},
	title={A microrobot-based automated micromanipulation station for assembly of microsystems},
	booktitle={ASI '96: Life Cycle Approaches to Production Systems: Management, Control and Supervision, 2-6 June 1996},
	series={Comput. Ind. (Netherlands)},
	publisher={Elsevier},
	address={Toulouse, France},
	organization={Fac. for Comput. Sci., Karlsruhe Univ., Germany},
	volume={36},
	chapter={1-2},
	pages={155-162},
	note={M1: Copyright 1998, IEE},
	abstract={The development of new types of miniaturized and microrobots with human-like capabilities play an important role in different application tasks. One of the main problems of present-day research is, for example, to assemble a whole microsystem from different microcomponents. This paper presents an automated micromanipulation desktop station including a piezoelectrically driven microrobot placed on the highly-precise x-y stage of a light microscope, a CCD-camera as a local sensor subsystem, a laser sensor unit as a global sensor subsystem, and a Pentium PC equipped additionally with an optical grabber. The microrobot has three piezoelectrically driven legs and two autonomous manipulators as end effectors; it can perform highly-precise manipulations (with an accuracy of up to 10 nm) and a nondestructive transport (at a speed of several mm/s) of very small objects under a microscope. To perform manipulations automatically, a control system, including a task planning level and a real-time execution level, is being developed},
	keywords={CCD image sensors; industrial manipulators; industrial robots; integrated circuit manufacture; microassembling; microcomputer applications; real-time systems},
	isbn={0166-3615},
	url={http://dx.doi.org/10.1016/S0166-3615(97)00110-3}
}
@article{RefWorks:19,
	author={S. Fatikow and U. Rembold and H. Worn},
	year={1998},
	title={Design and control of flexible microrobots for an automated microassembly desktop-station},
	journal={Proceedings of the SPIE - The International Society for Optical Engineering},
	volume={3202},
	pages={66-77},
	note={M1: Copyright 1998, IEE},
	abstract={There is an increasing interest in performing microsystem assembly (i.e. non-destructive transportation, precise manipulation, and exact positioning of microcomponents) using flexible microrobots. A new concept of a flexible robot-based microassembly desktop station and two prototypes of piezoelectric microassembly robots, MINIMAN and PROHAM, have previously been developed. In this paper, the motion control approach of these robots is discussed. This control approach is based on the geometric description of the robot platform and aims at following the optimal motion trajectory to minimize the operation time and to keep the robot end effector under microscope supervision. Besides excellent abilities both robots have some disadvantages such as the relatively high drive voltage of the piezoactuators or the instability of grasp-and-hold operations. For this reason, several new piezoelectric microrobots that employ different locomotion and object handling principles have lately been developed. The design and functions of these microrobots are shown},
	keywords={industrial manipulators; microactuators; microassembling; motion control; piezoelectric actuators; position control},
	isbn={0277-786X},
	url={http://dx.doi.org/10.1117/12.298046}
}
@article{RefWorks:197,
	author={S. Fatikow and J. Seyfried and St Fahlbusch and A. Buerkle and F. Schmoeckel},
	year={2000},
	title={Flexible microrobot-based microassembly station},
	journal={Journal of Intelligent and Robotic Systems: Theory and Applications},
	volume={27},
	number={1-2},
	pages={135-169},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={A wide range of microcomponents can today be produced using various microfabrication techniques. The assembly of complex microsystems consisting of several single components (i.e., hybrid microsystems) is, however, a difficult task that is seen to be a real challenge for the robotic research community. It is necessary to conceive flexible, highly precise and fast microassembly methods. In this paper, the development of a microrobot-based microassembly station is presented. Mobile piezoelectric microrobots with dimensions of some cm0RW1S34RfeSDcfkexd09rT331RW1S34RfeSDcfkexd09rT3 and with at least 5 DOF can perform various manipulations either under a light microscope or within the vacuum chamber of a scanning electron microscope. The components of the station developed and its control system are described. The latter comprises a vision-based sensor system for automatic robot control, user interfaces, a re-configurable parallel computer array and an assembly planning system. Specific problems that occur when using microrobots in an SEM and our research activities on the development of force microsensors integrated into the microrobots' grippers are described as well.},
	keywords={Mobile robots; Robotic assembly; Piezoelectric devices; Degrees of freedom (mechanics); Scanning electron microscopy; Image sensors; Computer vision; Manipulators; User interfaces; Grippers},
	isbn={0921-0296},
	url={http://dx.doi.org/10.1023/A:1008106331459}
}
@inproceedings{RefWorks:196,
	author={S. Fatikow and J. Seyfried and A. Faizullin},
	year={2000},
	title={Computer aided planning system of a flexible microrobot-based microassembly station},
	booktitle={Computer Aided Systems Theory - EUROCAST'99, 29 Sept.-2 Oct. 1999},
	series={Computer Aided Systems Theory - EUROCAST'99. Selection of Papers from the 7th International Workshop on Computer Aided Systems Theory. Proceedings (Lecture Notes in Computer Science Vol.1798)},
	publisher={Springer-Verlag},
	address={Vienna, Austria},
	organization={Inst. for Process Control & Robotics, Karlsruhe Univ., Germany},
	pages={414-434},
	note={M1: Copyright 2001, IEE},
	abstract={The assembly of complex microsystems consisting of several single components (i.e. hybrid microsystems) is a task which has to be solved to make mass production of microsystems possible. Therefore, it is necessary to introduce flexible, highly precise and fast microassembly methods. In this paper, the control system of a microrobot-based microassembly desktop station that has been developed at the University of Karlsruhe, is presented from the lower to the planning levels. This comprises vision-based closed-loop control, user interfaces, a reconfigurable computer-array, execution planning and assembly planning algorithms tailored to the needs of the microassembly station},
	keywords={assembly planning; computer aided production planning; flexible manufacturing systems; industrial manipulators; microassembling; micromanipulators; micromechanical devices; microrobots; mobile robots; robot vision; user interfaces},
	isbn={3 540 67822 0}
}
@article{RefWorks:194,
	author={S. Fatikow and J. Seyried and St Fahlbusch and A. Buerkle and F. Schmoeckel},
	year={2000},
	month=jan,
	title={A flexible microrobot-based microassembly station},
	journal={Journal of Intelligent and Robotic Systems: Theory and Applications},
	volume={27},
	number={1-2},
	pages={135-169},
	note={M1: Copyright 2000, IEE},
	abstract={A wide range of microcomponents can today be produced using various microfabrication techniques. The assembly of complex microsystems consisting of several single components (i.e. hybrid microsystems) is, however, a difficult task that is seen to be a real challenge for the robotic research community. It is necessary to conceive flexible, highly precise and fast microassembly methods. In the paper, the development of a microrobot-based microassembly station is presented. Mobile piezoelectric microrobots with dimensions of some cm0RW1S34RfeSDcfkexd09rT331RW1S34RfeSDcfkexd09rT3 and with at least 5 DOF can perform various manipulations either under a light microscope or within the vacuum chamber of a scanning electron microscope. The components of the station developed and its control system are described. The latter comprises a vision-based sensor system for automatic robot control, user interfaces, a re-configurable parallel computer array and an assembly planning system. Specific problems that occur when using microrobots in an SEM and our research activities on the development of force microsensors integrated into the microrobots' grippers are described as well},
	keywords={assembly planning; CAD; flexible manipulators; force sensors; microassembling; micromanipulators; microrobots; microsensors; mobile robots; motion control; piezoelectric devices; position control; robot vision; scanning electron microscopy},
	isbn={0921-0296},
	url={http://dx.doi.org/10.1023/A:1008106331459}
}
@article{RefWorks:179,
	author={Sergej Fatikow and Mirko Benz},
	year={1998},
	title={Microrobot-based automated micromanipulation station for assembly of microsystems},
	journal={Computers in Industry},
	volume={36},
	number={1-2},
	pages={155-162},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={The development of new types of miniaturized and microrobots with human-like capabilities play an important role in different application tasks. One of the main problem of present-day research is, for example, to assemble a whole microsystem from different microcomponents. This paper presents an automated micromanipulation desktop station including a piezoelectrically driven microrobot placed on the highly-precise x-y stage of a light microscope, a CCD-camera as a local sensor subsystem, a laser sensor unit as a global sensor subsystem, and a Pentium PC equipped additionally with an optical grabber. The microrobot has three piezoelectrically driven legs and two autonomous manipulators as endeffectors; it can perform highly-precise manipulations (with an accuracy of up to 10 nm) and a nondestructive transport (at a speed of several mm/s) of very small objects under a microscope. To perform manipulations automatically, a control system, including a task planning level and a real-time execution level, is being developed.},
	keywords={Robotic assembly; Actuators; Piezoelectric devices; Charge coupled devices; Sensors; Manipulators; End effectors; Motion planning; Real time systems; Optical microscopy},
	isbn={0166-3615},
	url={http://dx.doi.org/10.1016/S0166-3615(97)00110-3}
}
@inproceedings{RefWorks:203,
	author={Sergej Fatikow and Karoly Santa},
	year={1998},
	title={Planning and control of a microassembly process in a flexible microrobot-based desktop station},
	booktitle={Microrobotics and Micromanipulation, Nov 4-5 1998},
	publisher={The International Society for Optical Engineering},
	address={Boston, MA, United States},
	organization={University of Karlsruhe, Inst. for Proc. Control and Robotics, 76128 Karlsruhe, Germany},
	volume={3519},
	pages={24-35},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={There is an increasing interest in performing assembly of microsystems (i.e. non-destructive transportation, precise manipulation, and exact positioning of microcomponents) by flexible microrobots. A microrobot-based microassembly desktop station is being developed at the University of Karlsruhe. Several prototypes of piezoelectric driven microrobots and a design of the flexible microassembly desktop station were already presented at the last years' SPIE-meetings. In this paper, some implementation results of the station's planning and control system are presented. On the planning level, a common microassembly model for a computer-aided assembly planning is suggested - which is based on geometric reasoning - and its components are discussed in detail. The feasibility criteria for the generation of feasible assembly sequences and the optimization criteria for selecting the optimal assembly plan are described. For stations employing several microrobots, a method for decomposition of an assembly plan is suggested. Since the station's microrobots are rather complicated systems, it is very hard to find a useful robot model for the control purposes. For this reason, control methods to be used for positioning of a microrobot, which do not require an exact system model and which allow a reasonable compromise between the real-time processing and the exactness. An intelligent neural controller for positioning a microrobot has been developed.},
	keywords={Robotic assembly; Micromanipulators; Flexible manipulators; Process control; Personal computers; Piezoelectric devices; Computer aided manufacturing; Mathematical models; Computer simulation; Optimization; Neural networks; Intelligent control; Position control},
	isbn={0277-786X},
	url={http://dx.doi.org/10.1117/12.325746}
}
@inproceedings{RefWorks:114,
	author={L. Fei and P. Fraundorf},
	year={1993},
	title={Bayesian removal of noise for increased sensitivity in vector pattern recognition lattice imaging of interfaces},
	booktitle={Proceedings of the 51st Annual Meeting Microscopy Society of America, Aug 1-6 1993},
	series={Proceedings - Annual Meeting, Microscopy Society of America},
	publisher={Publ by San Francisco Press Inc, San Francisco, CA, USA},
	address={Cincinnati, OH, USA},
	organization={Univ of Missouri-St. Louis, St. Louis, MO, USA},
	pages={994-995},
	note={Compilation and indexing terms, Copyright 2005 Elsevier Engineering Information, Inc.},
	abstract={Based on statistical inference, Bayesian removal of noise can be used to reduce the amount of non-periodic noise in images after acquisition. According to previous study, the basic principle of Bayesian phase-model background subtraction is that the optimum (rms error minimizing strategy) Fourier phases of the noise can be obtained provided the amplitudes of the noise is given, while the noise amplitude can often be estimated from the image itself. A summary of the implementation of noise removal is presented. A vector pattern recognition mapping procedure is applied in order to see the improvement quantitatively.},
	keywords={Acoustic noise; Pattern recognition; Image processing; Crystal lattices; Composition effects; Transmission electron microscopy; Sensitivity analysis; Vectors; Statistical methods; Fourier transforms; Algorithms; Cells; Interfaces (materials)},
	isbn={0424-8201}
}
@article{RefWorks:175,
	author={Thomas Fischer and Karoly Santa and Sergej Fatikow},
	year={1997},
	title={Sensor system and powerful computer system for controlling a microrobot-based micromanipulation station},
	journal={Journal of Micromechanics and Microengineering},
	volume={7},
	number={3},
	pages={256-258},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={Mobile microrobots, which are capable of performing microscopic motions, have become a subject of great interest all over the world. They have the potential to be used for a variety of applications: in industry for assembly of microsystems or for the testing of silicon chips; in medicine for handling biological cells, etc. A new model of an automated micromanipulation station, which includes piezoelectric microrobots is now being built by an interdisciplinary research group at the Univ of Karlsruhe, Germany. This paper describes a sensor system and a powerful tailorable computer for controlling the micromanipulation station.},
	keywords={Manipulators; Microelectromechanical devices; Mobile robots; Sensors; Computer systems},
	isbn={0960-1317},
	url={http://dx.doi.org/10.1088/0960-1317/7/3/048}
}
@article{RefWorks:92,
	author={M. A. Fischler and R. C. Bolles},
	year={1981},
	month=jun,
	title={Random sample consensus: a paradigm for model fitting with applications to image analysis and automated cartography},
	journal={Communications of the ACM},
	volume={24},
	number={6},
	pages={381-395},
	note={M1: Copyright 2005, IEE},
	abstract={A new paradigm, Random Sample Consensus (RANSAC), for fitting a model to experimental data is introduced. RANSAC is capable of interpreting/smoothing data containing a significant percentage of gross errors, and is thus ideally suited for applications in automated image analysis where interpretation is based on the data provided by error-prone feature detectors. The authors describe the application of RANSAC to the Location Determination Problem (LDP): given an image depicting a set of landmarks with known locations, determine that point in space from which the image was obtained. In response to a RANSAC requirement, new results are derived on the minimum number of landmarks needed to obtain a solution, and algorithms are presented for computing these minimum-landmark solutions in closed form. These results provide the basis for an automatic system that can solve the LDP under difficult viewing and analysis conditions. Implementation details and computational examples are also presented},
	keywords={computerised picture processing},
	isbn={0001-0782},
	url={http://dx.doi.org/10.1145/358669.358692}
}
@book{RefWorks:40,
	author={David A. Forsyth and Jean Ponce},
	year={2003},
	title={Computer Vision: A modern Approach},
	publisher={Prentice Hall},
	note={annote: Excellent overview of the recent state of computer vision.}
}

@misc{RefWorks:57,
  author = 	 {Dennis M. Freeman and Alexander J. Aranyosi and Michael J. Gordon and Stanley S. Hong},
  year = 	 {1998},
  month = 	 jun,
  title = 	 {Multidimensional Motion Analysis of MEMS Using Computer Microvision},
  note =         {\url{http://umech.mit.edu/freeman/talks/sssaw98/talk.html}},
  howpublished = {Presentation for the Solid-State Sensor and Actuator Workshop, Hilton Head Island, SC, June 1998}
}

@inproceedings{RefWorks:8,
	author={H. Furusawa and S. Ikebata},
	year={1987},
	title={Microorganism detection from microscope image},
	booktitle={Proceedings of the International Workshop on Industrial Applications of Machine Vision and Machine Intelligence. Seiken Symposium (Cat. no. 87TH0166-9), 2-5 Feb. 1987},
	series={Proceedings of the International Workshop on Industrial Applications of Machine Vision and Machine Intelligence. Seiken Symposium (Cat. no. 87TH0166-9)},
	publisher={IEEE},
	address={Tokyo, Japan},
	organization={Mitsubishi Electr. Corp., Hyogo, Japan},
	pages={86-90},
	note={M1: Copyright 2005, IEE},
	abstract={A method which is capable of measuring automatically the number of microorganisms of a certain kind in a sewage disposal plant is proposed. The recognition of such creatures is usually difficult owing to their variable appearance. A method of recognizing such objects using the extended Hough transform concept has been developed; it achieves an over 80% recognition rate},
	keywords={biology computing; computerised pattern recognition; engineering computing; transforms; water treatment}
}
@inproceedings{RefWorks:147,
	author={Michael Gauthier and Beatriz Lopez-Walle and Cedric Clevy},
	year={2005},
	title={Comparison between micro-objects manipulations in dry and liquid mediums},
	booktitle={2005 IEEE International Symposium on Computational Intelligence in Robotics and Automation CIRA 2005, Jun 27-30 2005},
	series={Proceedings of IEEE International Symposium on Computational Intelligence in Robotics and Automation, CIRA},
	publisher={Institute of Electrical and Electronics Engineers Inc., Piscataway, NJ 08855-1331, United States},
	address={Espoo, Finland},
	organization={Laboratory of Automation of Besancon, LAB, UMR-CNRS-6596, 25000 Besancon, France},
	pages={707-712},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={In the submillimetric objects manipulations, the adhesion (capillary force, pull-off force and Van-der-Waals force) and the electrostatic forces affect the behavior of the micro-objects. These forces decrease significantly when the micro-objects are submerged in a liquid medium. So a microassembly task is easier to perform in a submerged medium than in air. Consequently, the study of the micro-objects assembly automation in liquid mediums is a promising topic. This article introduces a review of the major differences between dry and submerged micromanipulation. The influences of the medium on electrostatic forces, pull-off force and hydrodynamic forces are presented. Adhesion perturbations are significally reduced in liquid and hydrodynamic forces are advantageous to limit the maximal micro-objects velocity. Some comparative experimental micromanipulations are described and prove the interest of the liquid medium. &copy; 2005 IEEE.},
	keywords={Manipulators; Adhesion; Capillarity; Van der Waals forces; Electrostatics; Hydrodynamics; Perturbation techniques; Automation}
}
@article{RefWorks:135,
	author={Saeed Shiry Ghidary and Yasushi Nakata and Hiroshi Saito and Motofumi Hattori and Toshi Takamori},
	year={2002},
	title={Multi-modal interaction of human and home robot in the context of room map generation},
	journal={Autonomous Robots},
	volume={13},
	number={2},
	pages={169-184},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={In robotics, the idea of human and robot interaction is receiving a lot of attention lately. In this paper, we describe a multi-modal system for generating a map of the environment through interaction of a human and home robot. This system enables people to teach a newcomer robot different attributes of objects and places in the room through speech commands and hand gestures. The robot learns about size, position, and topological relations between objects, and produces a map of the room based on knowledge learned through communication with the human. The developed system consists of several sections including: natural language processing, posture recognition, object localization and map generation. This system combines multiple sources of information and model matching to detect and track a human hand so that the user can point toward an object of interest and guide the robot to either go near it or to locate that object's position in the room. The positions of objects in the room are located by monocular camera vision and depth from focus method.},
	keywords={Robotics; Human computer interaction; Robot programming; Natural language processing systems; Pattern recognition; Motion planning; Collision avoidance; Position control; Computer vision; Focusing},
	isbn={0929-5593},
	url={http://dx.doi.org/10.1023/A:1019689509522}
}
@inproceedings{RefWorks:134,
	author={Saeed Shiry Ghidary and Yasushi Nakata and Hiroshi Saito and Motofumi Hattori and Toshi Takamori},
	year={2001},
	title={Multi-modal human robot interaction for map generation},
	booktitle={2001 IEEE/RSJ International Conference on Intelligent Robots and Systems, Oct 29-Nov 3 2001},
	series={IEEE International Conference on Intelligent Robots and Systems},
	publisher={Institute of Electrical and Electronics Engineers Inc},
	address={Maui, HI},
	organization={Department of Computer System, Engineering Faculty, Kobe University, Kobe, Japan},
	volume={4},
	pages={2246-2251},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={This paper describes an interface for multi modal human robot interaction, which enables people to introduce a newcomer robot about different attributes of objects and places in the room through speech commands and hand gestures. Robot makes an environment map of the room based on knowledge learned through communication with human and uses this map for navigation. The developed system consists of several sections including: natural language processing, posture recognition, object localization and map generation. This system uses combination of multiple sources of information and model matching to detect and track a human hand so that the user can point toward an object of interest and guide the robot to go near to it or locate that object's position in the room. The position of objects in the room is located by monocular camera vision and depth from focus method.},
	keywords={Human computer interaction; Anthropomorphic robots; User interfaces; Object recognition; Natural language processing systems; Pattern matching; Mathematical models; Cameras; Computer vision},
	url={http://dx.doi.org/10.1109/IROS.2001.976404}
}
@inproceedings{RefWorks:36,
	author={M. A. Greenspan and L. Shang and P. Jasiobedzki},
	year={2004},
	month=jun,
	title={Efficient Tracking with the Bounded Hough Transform},
	booktitle={CVPR'04: Computer Vision and Pattern Recognition},
	url={http://www.ece.queensu.ca/hpages/faculty/greenspan/papers/GreShaJas04.pdf},
        annote={paper about hough-tracking}
}
@article{RefWorks:66,
	author={Qing Guo and Ruli Wang},
	year={1993},
	title={Techniques of hybrid electro-optic real-time pattern recognition applied to scanning tunnel microscope},
	journal={Hongwai Yu Haomibo Xuebao/Journal of Infrared and Millimeter Waves},
	volume={12},
	number={1},
	pages={16-20}
}
@article{RefWorks:241,
	author={D. S. Haliyo and S. Regnier and J. -C Guinot},
	year={2003},
	month=nov,
	title={[mu]MAD, the adhesion based dynamic micro-manipulator},
	journal={European Journal of Mechanics, A/Solids},
	volume={22},
	number={6},
	pages={903-916},
	note={M1: Copyright 2004, IEE},
	abstract={In this paper, a micro-manipulation method based on adhesion forces and dynamic effects is proposed. A prototype manipulator, called [mu]MAD, has been constructed and successfully experimented. Moreover, the advanced capabilities of [mu]MAD, especially two new interesting applications, are presented: sorting of micro-objects and mechanical characterizations},
	keywords={adhesion; manipulator dynamics; micromanipulators},
	isbn={0997-7538},
	url={http://dx.doi.org/10.1016/S0997-7538(03)00071-8}
}
@inproceedings{RefWorks:149,
	author={Sinan Haliyo and Fabien Dionnet and Stephane Regnier},
	year={2003},
	title={Advanced micro-manipulation applications},
	booktitle={2003 IEEE/RSJ International Conference on Intelligent Robots and Systems, Oct 27-31 2003},
	series={IEEE International Conference on Intelligent Robots and Systems},
	publisher={Institute of Electrical and Electronics Engineers Inc},
	address={Las Vegas, NV, United States},
	organization={Laboratoire de Robotique de Paris, UPMC-CNRS, 92265 Fontenay Aux Roses, France},
	volume={2},
	pages={1870-1875},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={A micro-manipulation method based on adhesion forces and dynamic effects has been proposed in our previous papers. A prototype manipulator, called [mu]MAD, has been constructed and successfully experimented. This paper describes the advanced capabilities of [mu]MAD, especially two new interesting applications: sorting of micro-objects and mechanical characterizations.},
	keywords={Robotics; Micromanipulators; Adhesion; Grippers; Glass; Piezoelectric materials; Ceramic materials; End effectors; Van der Waals forces},
	url={http://dx.doi.org/10.1109/IROS.2003.1248916}
}
@inproceedings{RefWorks:160,
	author={Ralph L. Hollis},
	year={1985},
	title={FINE POSITIONING DEVICE FOR ENHANCING ROBOT PRECISION},
	booktitle={Robots 9, Conference Proceedings. Volume 1: Advancing Applications.},
	publisher={Robotics Int of SME, Dearborn, MI, USA},
	address={Detroit, MI, Engl},
	organization={IBM, Yorktown, NY, USA},
	pages={6-28},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={Addition of a small, fast, precise positioner to the terminal link of a general purpose robot results in a coarse-fine positioning system with advanced capabilities. The fine positioner includes a compact combination of two-dimensional linear motor, flexure springs, position sensor and digital controller. The spring flexure assembly is rigid against all forces and torques except in the orthogonal x- and y- directions. The compliance of the device can be set by the digital controller loop gain. An absence of transmission elements, brushes, and sliding or rolling bearings makes the device completely free of wear, silent, without lubrication, and free of particle-producing action that could contaminate the work area.},
	keywords={ROBOTICS -- Optimization; ELECTRIC MOTORS, LINEAR - Applications; SPRINGS - Applications},
	isbn={0-87263-189-3}
}
@inproceedings{RefWorks:5,
	author={Hongyuan Wang and Shenggen Zeng and Chengang Yu and Xiaogang Wang and Deshen Xia},
	year={2001},
	title={The research of microscopic image segmentation and recognition on the cancer cells fallen into peritoneal effusion},
	booktitle={Proceedings International Workshop on Medical Imaging and Augmented Reality, 10-12 June 2001},
	series={Proceedings International Workshop on Medical Imaging and Augmented Reality},
	publisher={IEEE Computer. Soc},
	address={Shatin, Hong Kong, China},
	organization={Dept. of Comput., Nanjing Univ. of Sci. & Tech., China},
	pages={253-258},
	note={M1: Copyright 2001, IEE},
	abstract={Auto-segmentation of cells is one of the most interesting segmentation problems due to the complex nature of the cell tissues and to the inherent problems of video microscopic images. Objects, which are variant, narrow range of gray levels, non-random noise, are ubiquitous problems presented in this kind of image. Considering the above characteristics, an adaptive min-distance algorithm is proposed in this paper, which is available to segment the suspected cell and nucleus from the complex background in the microscopic image of cells fallen into peritoneal effusion. 15 features of the cancer cell and calculating formulas are presented respectively. These features are employed to construct a backpropagation neural network classifier which classifies and recognizes the cancer cells fallen into peritoneal effusion. Tests are performed using clinical cases recommended by the pathologists, results show that the proposed algorithm can efficiently segment the cell image and receive higher accuracy of cancer cell diagnosis},
	keywords={backpropagation; cancer; image classification; image segmentation; medical image processing; neural nets},
	isbn={0 7695 1113 9},
	url={http://dx.doi.org/10.1109/MIAR.2001.930296}
}
@inproceedings{RefWorks:180,
	author={Helge Hulsen and Stefan Garnica and Sergej Fatikow},
	year={2003},
	title={Extended Kohonen Networks for the Pose Control of Microrobots in a Nanohandling Station},
	booktitle={PROCEEDINGS of the 2003 IEEE INTERNATIONAL SYMPOSIUM on INTELLIGENT CONTROL, Oct 5-8 2003},
	publisher={Institute of Electrical and Electronics Engineers Inc},
	address={Houston, TX, United States},
	organization={Division Microrobotics, University of Oldenburg, D-26111 Oldenburg, Germany},
	pages={116-121},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={A microrobot-based nanohandling station, which is able to handle objects in the micrometer range and below, is introduced. A functional description of the microrobot's mobile platform is given as well as an overview over the control system architecture and the low-level control part. The application of an extended Kohonen network for the adaptive open-loop pose control of the mobile platform is presented with theoretical background and implementation details. Its performance is analysed by means of simulation results.},
	keywords={Robotics; Control system analysis; Electric potential; Degrees of freedom (mechanics); Manipulators; Computer simulation},
	url={http://dx.doi.org/10.1109/ISIC '03.2003.1253924}
}
@article{RefWorks:161,
	author={Ian W. Hunter and Serge Lafontaine and Paul M. F. Nielsen and Peter J. Hunter and John M. Hollerbach},
	year={1990},
	title={Manipulation and dynamic mechanical testing of microscopic objects using a tele-micro-robot system},
	journal={IEEE Control Systems Magazine},
	volume={10},
	number={2},
	pages={3-9},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={A microrobot having two high-performance parallel drive limbs which has been developed for manipulation, surgery, and dynamic mechanical testing of very small objects such as single living cells is described. The end points of each limb move in overlapping spherical workspaces of 1-mm diameter with minimum open- and closed-loop movements of 1 nm and 10 nm, respectively. The displacement bandwidth of all six microrobot axes exceeds 1 kHz for small displacements. A three-dimensional laser vision system with a resolution of 50 to 100 nm has been developed to provide the microrobot with volume images containing magnitude, phase, polarization, and spectral information. A macro version of the microrobot has been built to permit force-reflecting teleoperation of the microrobot. The telemicrorobot system permits both microscopic objects and continuum models to be felt. A high-performance parallel computer has been designed, and partially constructed, to meet the substantial computational and control requirements of the telemicrorobot system.},
	keywords={Robotics; Remote Control; Materials Handling--Manipulators; Vision--Artificial; Lasers; Computer Systems, Digital--Parallel Processing},
	isbn={0730-6598},
	url={http://dx.doi.org/10.1109/37.45787}
}
@inproceedings{RefWorks:165,
	author={Ian W. Hunter and Serge Lafontaine and Poul M. F. Nielsen and Peter J. Hunter and John M. Hollerbach},
	year={1989},
	title={Manipulation and dynamic mechanical testing of microscopic objects using a tele-micro-robot system},
	booktitle={IEEE International Conference on Robotics and Automation - 1989, May 14-19 1989},
	publisher={Publ by IEEE, Piscataway, NJ, USA},
	address={Scottsdale, AZ, USA},
	organization={McGill Univ, Montreal, Que, Can},
	pages={1553-1558},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={A microrobot having two high-performance parallel drive limbs has been developed for manipulation surgery, and dynamic mechanical testing of very small objects such as single living cells. The end-points of each limb move in overlapping spherical workspaces of 1 mm diameter with minimum open- and closed-loop movements of 1 nm and 10 nm, respectively. With optimal nonlinear model-based controllers the limbs can move at up to 2 m/s relative to each other. A variety of end effectors, including ferroelectric polymer microgrippers, may be attached to the limbs to permit cell manipulation. A 3-D laser vision system with resolution of 50 to 100 nm has been developed to provide the microrobot with volume images containing magnitude, phase, polarization, and special information. A macro version of the microrobot has been built to enable force-reflecting teleoperation of the microrobot. The telemicrorobot system permits both microscopic objects and continuum models to be felt. A high-performance parallel computer has been designed to meet the substantial computational and control requirements of the system.},
	keywords={Robotics -- Vision Systems; Actuators; Materials Handling--Manipulators; Control Systems, Nonlinear; Biomedical Equipment--Robot Applications},
	url={http://dx.doi.org/10.1109/ROBOT.1989.100199}
}
@article{RefWorks:240,
	author={Huy-Hoang Pham and I-Ming Chen and Hsien-Chi Yeh},
	year={2005},
	title={Micro-motion selective-actuation XYZ flexure parallel mechanism: design and modeling},
	journal={Journal of Micromechatronics},
	volume={3},
	number={1},
	pages={51-73},
	note={M1: Copyright 2005, IEE},
	abstract={This paper presents the design of a selective-actuation flexure parallel mechanism that could provide three de-coupled micro-motions along the X-, Y- and Z-axes. This mechanism could be used as an ultra-precision positioning system. The modeling of this flexure parallel mechanism is then established based on a pseudo-rigid-body model with consideration of deformation of the flexure member. The factor of deformation allowed the formulation of accurate kinematics analysis of the flexure mechanism. Via this modeling, dimension and free shape of the mechanism are determined based on the criteria of isotropic resolution transmission scale. An experiment was set up to verify the modeling and the design. The experiment shows the advantage of the proposed model versus the model currently used. The similarity of the resolutions obtained from the experiment and predicted by the optimal design shows the validity of the resolution evaluation and the optimal design},
	keywords={manipulator kinematics; microactuators; micromanipulators; micropositioning},
	isbn={1389-2258},
	url={http://dx.doi.org/10.1163/156856305323383919}
}
@misc{RefWorks:54,
  author = 	 {IBMT},
  year = 	 {2005},
  title = 	 {Fraunhofer Institut Biomedizinische Technik, St. Ingbert},
  url =          {http://www.ibmt.fraunhofer.de/}
}
@article{RefWorks:83,
	author={Piotr Indyk and Rajeev Motwani},
	year={1998},
	title={Approximate nearest neighbors: Towards removing the curse of dimensionality},
	journal={Conference Proceedings of the Annual ACM Symposium on Theory of Computing},
	pages={604-613}
}

@misc{RefWorks:50,
  author = 	 {IPR},
  year = 	 {2005},
  title = 	 {Institute for Process Control and Robotics, University Fridericiana, Karlsruhe},
  url =          {http://wwwipr.ira.uka.de/}
}
@article{RefWorks:4,
	author={Jia-Guu Leu and Hok-Lai Yau},
	year={1991},
	title={Detecting the dislocations in metal crystals from microscopic images},
	journal={Pattern Recognition},
	volume={24},
	number={1},
	pages={41-56},
	note={M1: Copyright 2005, IEE},
	abstract={Studying the distribution of dislocations in metal crystalline structures has been an important subject in metallurgic science for many years. The authors describe a computer vision based process which automatically extracts dislocations from one type of electron microscopic images which contain such dislocations. In these microscopic images, dislocations appear as dark and triangularly shaped regions. However, some of them are lumped together and form regions of complex shapes. In the suggested process the first step is to extract the boundaries of all the dark regions. The next is to trace along the extracted boundaries to detect possible corners and edges of the dislocations. The last step is to determine the existence of the dislocations and their locations by detecting properly spaced and oriented corners and edges. Experiments have shown that this process is very effective. The approach is comprehensive and deals with many important issues in image processing and pattern recognition},
	keywords={computerised pattern recognition; computerised picture processing; dislocations; electron microscope examination of materials; electron microscopy; metallography; physics computing},
	isbn={0031-3203},
	url={http://dx.doi.org/10.1016/0031-3203(91)90115-L}
}
@article{RefWorks:249,
	author={Jing Liu and Yi-Xin Zhou and Tian-Hua Yu},
	year={2004},
	month=feb,
	title={Freeze tweezer to manipulate mini/micro objects},
	journal={Journal of Micromechanics and Microengineering},
	volume={14},
	number={2},
	pages={269-276},
	note={M1: Copyright 2004, IEE},
	abstract={In this paper, we propose a freeze tweezer using the freezing force of a small volume of nucleotide ice to manipulate mini/micro objects in an aqueous state. Several prototypes of such a device based on the Joule-Thompson throttling effect have been fabricated and there have been preliminary demonstrations of their applicability in manipulating a wide variety of objects. By regulating the freezing conditions of the cooler, an ice ball can be formed between the tweezer tip and the object it contacts and then the object can be picked up. This freezing force is strong enough to manipulate objects with any shape, electric charge, light or heavy, biological or non-living, on the condition that the contact area can be frozen. Successful manipulation of a series of specific objects presented in this paper indicates that it would be much easier for the freeze tweezer to handle objects with smaller size. Therefore, further nanoscale freeze tweezers following the same idea as above can be put forward; this is expected to have exciting applications in micro/nano engineering field. Furthermore, theoretical analysis and experiments have been performed to quantify the response time of the freeze tweezer and the mechanical force generated on the tweezer tip. This study has also raised quite a few new fundamental issues related to the fabrication and practices of the freeze tweezer},
	keywords={biological techniques; freezing; grippers; Joule-Thomson effect; low-temperature techniques; micromanipulators; nanotechnology},
	isbn={0960-1317},
	url={http://dx.doi.org/10.1088/0960-1317/14/2/015}
}
@inproceedings{RefWorks:89,
	author={A. E. Johnson and M. Hebert},
	year={1997},
	title={Surface registration by matching oriented points},
	booktitle={Proceedings. International Conference on Recent Advances in 3-D Digital Imaging and Modeling (Cat. No.97TB100134), 12-15 May 1997},
	series={Proceedings. International Conference on Recent Advances in 3-D Digital Imaging and Modeling (Cat. No.97TB100134)},
	publisher={IEEE Comput. Soc. Press},
	address={Ottawa, Ont., Canada},
	organization={Robotics Inst., Carnegie Mellon Univ., Pittsburgh, PA, USA},
	pages={121-128},
	note={M1: Copyright 1997, IEE},
	abstract={For registration of 3-D free-form surfaces we have developed a representation which requires no knowledge of the transformation between views. The representation comprises descriptive images associated with oriented points on the surface of an object. Constructed using single point bases, these images are data level shape descriptions that are used for efficient matching of oriented points. Correlation of images is used to establish point correspondences between two views; from these correspondences a rigid transformation that aligns the views is calculated. The transformation is then refined and verified using a modified iterative closest point algorithm. To demonstrate the generality of our approach, we present results from multiple sensing domains},
	keywords={image matching; image registration; image representation; iterative methods; object recognition},
	isbn={0 8186 7943 3},
	url={http://dx.doi.org/10.1109/IM.1997.603857}
}
@inproceedings{RefWorks:90,
	author={A. E. Johnson and M. Hebert},
	year={1997},
	title={Recognizing objects by matching oriented points},
	booktitle={Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 17-19 June 1997},
	series={Proceedings. 1997 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.97CB36082)},
	publisher={IEEE Comput. Soc},
	address={San Juan, Puerto Rico},
	organization={Robotics Inst., Carnegie Mellon Univ., Pittsburgh, PA, USA},
	pages={684-689},
	note={M1: Copyright 1997, IEE},
	abstract={We present an approach to recognition of complex objects in cluttered 3-D scenes that does not require feature extraction or segmentation. Our object representation comprises descriptive images associated with each oriented point on the surface of an object. Using a single point basis constructed from an oriented point, the position of other points on the surface of the object can be described by two parameters. The accumulation of these parameters for many points on the surface of the object results in an image at each oriented point. These images, localized descriptions of the global shape of the object, are invariant to rigid transformations. Through correlation of images, point correspondences between a model and scene data are established and then grouped using geometric consistency. The effectiveness of our algorithm is demonstrated with results showing recognition of complex objects in cluttered scenes with occlusion},
	keywords={computational geometry; computer vision; image matching; image representation; object recognition},
	isbn={0 8186 7822 4},
	url={http://dx.doi.org/10.1109/CVPR.1997.609400}
}
@article{RefWorks:91,
	author={Andrew E. Johnson and Martial Hebert},
	year={1999},
	title={Using spin images for efficient object recognition in cluttered 3D scenes},
	journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
	volume={21},
	number={5},
	pages={433-449},
	note={Compilation and indexing terms, Copyright 2005 Elsevier Engineering Information, Inc.},
	abstract={We present a 3D shape-based object recognition system for simultaneous recognition of multiple objects in scenes containing clutter and occlusion. Recognition is based on matching surfaces by matching points using the spin image representation. The spin image is a data level shape descriptor that is used to match surfaces represented as surface meshes. We present a compression scheme for spin images that results in efficient multiple object recognition which we verify with results showing the simultaneous recognition of multiple objects from a library of 20 models. Furthermore, we demonstrate the robust performance of recognition in the presence of clutter and occlusion through analysis of recognition trials on 100 scenes.},
	keywords={Computer vision; Three dimensional; Clutter (information theory); Image compression; Computer simulation; Image analysis; Object recognition},
	isbn={0162-8828},
	url={http://dx.doi.org/10.1109/34.765655}
}
@inproceedings{RefWorks:7,
	author={A. E. Kayaalp and A. R. Rao and R. Jain},
	year={1989},
	title={Scanning electron microscope based stereo analysis [for semiconductor IC inspection]},
	booktitle={Proceedings CVPR '89 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.89CH2752-4), 4-8 June 1989},
	series={Proceedings CVPR '89 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.89CH2752-4)},
	publisher={IEEE Comput. Soc. Press},
	address={San Diego, CA, USA},
	organization={Dept. of Electr. Eng. & Comput. Sci., Michigan Univ., Ann Arbor, MI, USA},
	pages={429-434},
	note={M1: Copyright 2005, IEE},
	abstract={A novel technique to analyze stereo images generated from a scanning electron microscope (SEM) for inspection of wafers for process control is presented. The two main features of this technique are that it uses a binary linear programming approach to set up and solve the correspondence problem, and that it uses constraints based on the physics of SEM image formation. Binary linear programming is a powerful tool with which to tackle constrained optimization problems, especially in the cases that involve matching between one data set and another. The authors also analyze the process of SEM image formation, and present constraints that are useful in solving the stereo correspondence problem. This technique has been solved on many images. Results for a few wafers are included},
	keywords={computer vision; inspection; integrated circuit testing; linear programming; process computer control; scanning electron microscopy},
	isbn={0 8186 1952 x},
	url={http://dx.doi.org/10.1109/CVPR.1989.37882}
}
@article{RefWorks:248,
	author={Thomas P. Koninckx and Luc Van Gool},
	year={2006},
	title={Real-time range acquisition by adaptive structured light},
	journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
	volume={28},
	number={3},
	pages={432-445},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={The goal of this paper is to provide a "self-adaptive" system for real-time range acquisition. Reconstructions are based on a single frame structured light illumination. Instead of using generic, static coding that is supposed to work under all circumstances, system adaptation is proposed. This occurs on-the-fly and renders the system more robust against instant scene variability and creates suitable patterns at startup. A continuous trade-off between speed and quality is made. A weighted combination of different coding cues - based upon pattern color, geometry, and tracking - yields a robust way to solve the correspondence problem. The individual coding cues are automatically adapted within a considered family of patterns. The weights to combine them are based on the average consistency with the result within a small time-window. The integration itself is done by reformulating the problem as a graph cut. Also, the camera-projector configuration is taken into account for generating the projection patterns. The correctness of the range maps is not guaranteed, but an estimation of the uncertainty is provided for each part of the reconstruction. Our prototype is implemented using unmodified consumer hardware only and, therefore, is cheap. Frame rates vary between 10 and 25 fps, dependent on scene complexity. &copy; 2006 IEEE.},
	keywords={Imaging systems; Real time systems; Image reconstruction; Lighting; Image coding; Data acquisition; Pattern recognition; Estimation},
	isbn={0162-8828}
}
@inproceedings{RefWorks:181,
	author={A. Kortschack and O. C. Hanssler and C. Rass and S. Fatikow},
	year={2003},
	title={Driving principles of Mobile Microrobots for Micro- and Nanohandling},
	booktitle={2003 IEEE/RSJ International Conference on Intelligent Robots and Systems, Oct 27-31 2003},
	publisher={Institute of Electrical and Electronics Engineers Inc},
	address={Las Vegas, NV, United States},
	organization={University of Oldenburg, Divison Microrobotics Engineering, Oldenburg, Germany},
	volume={2},
	pages={1895-1900},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={This paper presents newly developed mobile microrobots with high precision in the sub-micrometer range, while offering a macroscopic workspace. The main parts of the mobile microrobots, a mobile platform and a manipulator unit, are explained. The mobile platform's actuation is based on the slip-stick-principle. Because of a new arrangement of the components promising characteristics have been investigated. Especially of interest is the low voltage needed to drive the actuators, because it makes possible the integration of batteries. A manipulation unit with actuators based on a combination of electric motors and piezoelectric actuators is described as well. Finally the future effort and outlook is discussed.},
	keywords={Mobile robots; Manipulators; Actuators; Electric batteries; Electric motors; Piezoelectric devices; Microscopes; Thin films; Quality control},
	url={http://dx.doi.org/10.1109/IROS.2003.1248920}
}
@article{RefWorks:183,
	author={A. Kortschack and A. Shirinov and T. Truper and S. Fatikow},
	year={2005},
	month=jul,
	title={Development of mobile versatile nanohandling microrobots: design, driving principles, haptic control},
	journal={Robotica},
	volume={23},
	pages={419-434},
	note={M1: Copyright 2005, IEE},
	abstract={Special micromanipulators are needed to manipulate very small objects. Most micromanipulators are specialized to perform a task they are designed for, but are too inflexible to adapt to other problems. Therefore, flexible newly developed mobile microrobots are presented with precision in the sub-micrometer range while offering a macroscopic workspace. The main parts of each mobile microrobot, the mobile platform, the manipulator and end effectors, are explained in detail, with some experimental data given. The new driving principle of the mobile platform allows high resolution, low energy consumption, which makes an on-board power supply feasible and a maximum velocity of several mm/s. Useful human interfaces are needed for a successful teleoperation. The most important interface next to the vision feedback is a haptic interface. The paper presents a newly developed haptic interface for a micromanipulation station. The mechanical design and the design of the control system of the haptic interface are discussed in details. The control architecture of the micromanipulation station and the integration of the haptic device into the micromanipulation station are presented},
	keywords={control system synthesis; end effectors; flexible manipulators; haptic interfaces; mechanical engineering computing; micromanipulators; microrobots; mobile robots; nanopositioning},
	isbn={0263-5747},
	url={http://dx.doi.org/10.1017/S0263574704000852}
}
@inproceedings{RefWorks:35,
	author={Akio Kosaka and Akito Saito and Yukihito Furuhashi and Takao Shibasaki},
	year={2000},
	title={Augmented reality system for surgical navigation using robust target vision},
	booktitle={CVPR '2000: IEEE Conference on Computer Vision and Pattern Recognition, Jun 13-Jun 15 2000},
	series={Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
	publisher={Institute of Electrical and Electronics Engineers Computer Society, Los Alamitos, CA, USA},
	address={Hilton Head Island, SC, USA},
	organization={Olympus Optical Co, Ltd, Tokyo, Jpn},
	volume={2},
	pages={187-194},
	note={Compilation and indexing terms, Copyright 2005 Elsevier Engineering Information, Inc.},
	abstract={This paper presents a robust and accurate vision-based augmented reality system for surgical navigation. The key point of our system is a robust and real-time monocular vision algorithm to estimate the 3D pose of surgical tools, utilizing specially designed code markers and Kalman filter-based position updating. The vision system is not impaired by occlusion and rapid change of illumination. The augmented reality system super-imposes the 3D object wireframe onto the live viewing image taken from the surgical microscope as well as displaying other useful navigation information, while allowing the surgeons to freely change its zoom and focus for viewing. The experimental results verified the robustness and usefulness of the system, and acquired the image registration error less than 2 mm.},
	keywords={Surgery; Algorithms; Three dimensional; Kalman filtering; Microscopes; Image processing; Computer vision},
	isbn={1063-6919},
	url={http://dx.doi.org/10.1109/CVPR.2000.854777}
}
@inproceedings{RefWorks:123,
	author={Hiroyasu Koshimizu and Kazunori Takagi and Takashi Watanabe},
	year={2002},
	title={Visual inspection PC system for quality control of electronic devices},
	booktitle={Optomechatronic Systems III, Nov 12-14 2002},
	series={Proceedings of SPIE - The International Society for Optical Engineering},
	publisher={The International Society for Optical Engineering},
	address={Stuttgart, Germany},
	organization={Chukyo University, Toyota, Aichi Prefecture 470-0393, Japan},
	volume={4902},
	pages={165-173},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={We have been developing an image processing method for the automatic inspection of electronic devices and implemented it on PC. And this system was already fabricated in the real production line for collecting the practical performance. 2D edge detection method for evaluating the surface recognition of the printed circuit board was proposed so far, and the validity was clarified. In this paper the outline of this system is firstly explained and the performance of this system is reported in detail. However, since some defects appear at the top surface of the mold cannot be detected even with a set of this 2D inspection procedure, new 3-dimensional inspection of the flatness of the mold top surface was introduced. Depth from Focus Method was implemented in order to enforce this system to cope with 3-dimensional defects. An image processing method for evaluating the flatness of the face of the device is now developed by analyzing this 3D image. Affine transformation is employed here to reduce the geometric distortions inherent in the given images.},
	keywords={Computer vision; Personal computers; Inspection; Consumer electronics; Quality control; Image processing; Edge detection; Printed circuit boards; Defects; Three dimensional; Mathematical transformations; Computer simulation},
	isbn={0277-786X},
	url={http://dx.doi.org/10.1117/12.467256}
}
@article{RefWorks:112,
	author={Kaustubh Kulkarni},
	year={2002},
	title={Image Processing Techniques for Transmission Electron Microscope},
	journal={ISA TECH/EXPO Technology Update Conference Proceedings},
	volume={424-425},
	pages={1217-1224},
	note={Compilation and indexing terms, Copyright 2005 Elsevier Engineering Information, Inc.},
	abstract={Various image processing techniques for transmission electron microscopy (TEM) were discussed. TEM is used to obtain informations on microstructure, crystal structure and microchemistry. The principles of TEM and its application in atomic structure analysis of the solid state were also presented. An advantage of TEM which is in the selection of diffraction beams for generating the images was also discussed.},
	keywords={Optical resolving power; Crystal structure; Microstructure; Diffraction; Crystal lattices; Fourier transforms; Transmission electron microscopy; Monte Carlo methods; Computer simulation; Image processing},
	isbn={1054-0032}
}
@article{RefWorks:115,
	author={Veli-Tapani Kuokkala},
	year={1996},
	title={microScope for windows - a simulation program for transmission electron micrographs},
	journal={Journal of Computer-Assisted Microscopy},
	volume={8},
	number={2},
	pages={63-74},
	note={Compilation and indexing terms, Copyright 2005 Elsevier Engineering Information, Inc.},
	abstract={microScope for Windows is a simulation program for transmission electron micrographs based on the dynamical two-beam theory of electron diffraction and the column approximation. The program, written in Visual Basic 4.0 for running under Microsoft Windows 3.1 or Windows 95, calculates and displays 256 gray level brightfield and darkfield images of dislocations and stacking faults on the screen and prints hardcopies of the computed micrographs on any output device supported by Microsoft Windows. microScope for Windows is an effective and easy-to-use tool for defect identification by visual matching of experimental and computed micrographs and for demonstration of images produced by varying diffracting conditions and sample geometry.},
	keywords={Computer simulation; Transmission electron microscopy; Electron diffraction; Image processing; Dislocations (crystals); Stacking faults; Computer software},
	isbn={1040-7286}
}
@article{RefWorks:144,
	author={Toru Kuzumaki and Yoshitaka Mitsuda},
	year={2006},
	title={Nanoscale mechanics of carbon nanotube evaluated by nanoprobe manipulation in transmission electron microscope},
	journal={Japanese Journal of Applied Physics, Part 1: Regular Papers and Short Notes and Review Papers},
	volume={45},
	number={1 A},
	pages={364-368},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={We investigated the nanoscale mechanics of individual multiwalled carbon nanotubes (MWCNTs) by a nanoprobe manipulation technique in a transmission electron microscope (TEM). The force applied to individual MWCNTs was measured using a commercially available Si cantilever installed in a manipulator. It was clearly observed that this force is released by buckling like deformation. The average Young's modulus of the MWCNTs estimated using a conventional mechanical theory was approximately 1.1 TPa. Although the MWCNTs exhibited a high flexibility, the deformation of the MWCNTs above the elastic limit led to structural defects, which resulted in a local plastic deformation. Nanomechanics measurements in the TEM revealed that the structural defects cause stiffness deterioration. &copy; 2006 The Japan Society of Applied Physics.},
	keywords={Carbon nanotubes; Transmission electron microscopy; Plastic deformation; Mechanical properties; Defects; Buckling},
	isbn={0021-4922},
	url={http://dx.doi.org/10.1143/JJAP.45.364}
}
@inproceedings{RefWorks:22,
	author={Y. Lamdan and H. J. Wolfson},
	year={1988},
	title={Geometric hashing: a general and efficient model-based recognition scheme},
	booktitle={Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), 5-8 Dec. 1988},
	series={Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1)},
	publisher={IEEE Comput. Soc. Press},
	address={Tampa, FL, USA},
	organization={Courant Inst. of Math., New York Univ., NY, USA},
	pages={238-249},
	note={M1: Copyright 2005, IEE},
	abstract={A general method for model-based object recognition in occluded scenes is presented that is based on geometric hashing. The method stands out for its efficiency. The general framework of the method is described and its applications illustrated for various recognition problems both in 3-D and 2-D. Special attention is given to the recognition of 3-D objects in occluded scenes from 2-D gray-scale images. Experimental results are included for this important case},
	keywords={computerised pattern recognition; computerised picture processing},
	isbn={0 8186 0883 8}
}
@inproceedings{RefWorks:39,
	author={Bart Lamiroy and Patrick Gros},
	year={1996},
	month=apr,
	title={Rapid Object Indexing and Recognition Using Enhanced Geometric Hashing},
	booktitle={Proceedings of the 4th European Conference on Computer Vision, Cambridge, England},
	volume={1},
	pages={59-70},
	url=  {ftp://ftp.inrialpes.fr/pub/movi/publications/imag-ftp/Lamiroy\_eccv96.ps.gzGeometric voting on 3D-objects}
}
@article{RefWorks:88,
	author={S. Lazebnik and C. Schmid and J. Ponce},
	year={2005},
	month=aug,
	title={A sparse texture representation using local affine regions},
	journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
	volume={27},
	number={8},
	pages={1265-1278},
	note={M1: Copyright 2005, IEE},
	abstract={This paper introduces a texture representation suitable for recognizing images of textured surfaces under a wide range of transformations, including viewpoint changes and nonrigid deformations. At the feature extraction stage, a sparse set of affine Harris and Laplacian regions is found in the image. Each of these regions can be thought of as a texture element having a characteristic elliptic shape and a distinctive appearance pattern. This pattern is captured in an affine-invariant fashion via a process of shape normalization followed by the computation of two novel descriptors, the spin image and the RIFT descriptor. When affine invariance is not required, the original elliptical shape serves as an additional discriminative feature for texture recognition. The proposed approach is evaluated in retrieval and classification tasks using the entire Brodatz database and a publicly available collection of 1,000 photographs of textured surfaces taken from different viewpoints},
	keywords={computer vision; image recognition; image representation; image texture; visual databases},
	isbn={0162-8828},
	url={http://dx.doi.org/10.1109/TPAMI.2005.151}
}
@inproceedings{RefWorks:87,
	author={S. Lazebnik and C. Schmid and J. Ponce},
	year={2003},
	title={A sparse texture representation using affine-invariant regions},
	booktitle={CVPR 2003: Computer Vision and Pattern Recognition Conference, 18-20 June 2003},
	series={Proceedings 2003 IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
	publisher={IEEE Comput. Soc},
	address={Madison, WI, USA},
	organization={Beckman Inst., Univ. of Illinois, Urbana, IL, USA;},
	volume={2},
	pages={319-324},
	note={M1: Copyright 2003, IEE},
	abstract={This paper introduces a texture representation suitable for recognizing images of textured surfaces under a wide range of transformations, including viewpoint changes and nonrigid deformations. At the feature extraction stage, a sparse set of affine-invariant local patches is extracted from the image. This spatial selection process permits the computation of characteristic scale and neighborhood shape for every texture element. The proposed texture representation is evaluated in retrieval and classification tasks using the entire Brodatz database and a collection of photographs of textured surfaces taken from different viewpoints},
	keywords={edge detection; image classification; image representation; image retrieval; image texture; visual databases},
	isbn={0 7695 1900 8},
	url={http://dx.doi.org/10.1109/CVPR.2003.1211486}
}
@article{RefWorks:127,
	author={Qi Li and Hua-Jun Feng and Zhi-Hai Xu},
	year={2005},
	title={Method of improving autofocus speed based on defocus estimation},
	journal={Guangdianzi Jiguang/Journal of Optoelectronics Laser},
	volume={16},
	number={7},
	pages={850-853},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={A new location method of focused position for autofocus was put forward. In current autofocus system, a lot of time was taken to acquire and process a serial of images and drive focus lens through all possible imaging positions, which is not compatible with the demand of rapid focus. The new method estimated defocus degree at three imaging position respectively, driven lens to focused range, then searched within the range and found best imaging position. Proposed method has some advantages, such as higher accuracy, shorter focus time, and needn't calibrate exactly imaging system. Experiments show that the new method has improved focus speed remarkably (about 37%), and has the same accuracy as depth from focus (DFF) method.},
	keywords={Focusing; Imaging systems; Estimation; Image processing; Imaging techniques; Cameras; Lenses},
	isbn={1005-0086}
}
@inproceedings{RefWorks:28,
	author={David Liu and Tsuhan Chen},
	year={2004},
	title={Soft shape context for iterative closest point registration},
	booktitle={2004 International Conference on Image Processing, ICIP 2004, Oct 18-21 2004},
	series={Proceedings - International Conference on Image Processing, ICIP},
	publisher={Institute of Electrical and Electronics Engineers Computer Society, Piscataway, NJ 08855-1331, United States},
	address={Singapore},
	organization={Department of Electrical and Computer Engineering, Carnegie Mellon University, Pittsburgh, PA, United States},
	volume={5},
	pages={1081-1084},
	note={Compilation and indexing terms, Copyright 2005 Elsevier Engineering Information, Inc.},
	abstract={This paper introduces a shape descriptor, the soft shape context, motivated by the shape context method. Unlike the original shape context method, where each image point was hard assigned into a single histogram bin, we instead allow each image point to contribute to multiple bins, hence more robust to distortions. The soft shape context can easily be integrated into the iterative closest point (ICP) method as an auxiliary feature vector, enriching the representation of an image point from spatial information only, to spatial and shape information. This yields a registration method more robust than the original ICP method. The method is general for 2D shapes. It does not calculate derivatives, hence being able to handle shapes with junctions and discontinuities. We present experimental results to demonstrate the robustness compared with the standard ICP method. &copy; 2004 IEEE.},
	keywords={Robustness (control systems); Computer vision; Database systems; Information analysis; Mathematical models; Set theory; Algorithms; Image analysis},
	isbn={1522-4880}
}
@article{RefWorks:239,
	author={P. A. Liu and Q. Li},
	year={2003},
	title={Kinematics and dynamics of a general-purpose, parallel, compliant micromanipulator},
	journal={Proceedings of the Institution of Mechanical Engineers, Part K (Journal of Multi-Body Dynamics)},
	volume={217},
	number={K1},
	pages={39-50},
	note={M1: Copyright 2003, IEE},
	abstract={Kinematic and dynamic modelling of a 3-DOF planar parallel manipulator is presented in this paper. An equilateral triangle forms the output stage of the mechanism, and three driving structures, connected via three links, provide stroke magnification to the output stage. Aiming at achieving micromotions, this manipulator is developed using compliant material. In order to reduce assembly errors, a monolithic structure is adopted in this design. Hence, the joints in this mechanism are all flexural hinges. Since the masses and moments of inertia can be neglected in this lightweight micromanipulator, and the joint resistances are greatly increased owing to the flexure of the joints, new problems arise in the design and modelling of such a mechanism. The results presented in this paper will provide useful information for the design and applications of parallel, compliant micromanipulators},
	keywords={manipulator dynamics; manipulator kinematics; micromanipulators},
	isbn={1464-4193},
	url={http://dx.doi.org/10.1243/146441903763049432}
}

@article{RefWorks:86,
	author={D. G. Lowe},
	year={2004},
	month=nov,
	title={Distinctive image features from scale-invariant keypoints},
	journal={International Journal of Computer Vision},
	volume={60},
	number={2},
	pages={91-110},
	note={M1: Copyright 2005, IEE},
	abstract={This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are invariant to image scale and rotation, and are shown to provide robust matching across a substantial range of affine distortion, change in 3D viewpoint, addition of noise, and change in illumination. The features are highly distinctive, in the sense that a single feature can be correctly matched with high probability against a large database of features from many images. This paper also describes an approach to using these features for object recognition. The recognition proceeds by matching individual features to a database of features from known objects using a fast nearest-neighbor algorithm, followed by a Hough transform to identify clusters belonging to a single object, and finally performing verification through least-squares solution for consistent pose parameters. This approach to recognition can robustly identify objects among clutter and occlusion while achieving near real-time performance},
	keywords={computer graphics; feature extraction; Hough transforms; image matching; object recognition},
	isbn={0920-5691},
	url={http://dx.doi.org/10.1023/B:VISI.0000029664.99615.94}
}

@inproceedings{RefWorks:85,
	author={D. G. Lowe},
	year={1999},
	title={Object recognition from local scale-invariant features},
	booktitle={Proceedings of the Seventh IEEE International Conference on Computer Vision, 20-27 Sept. 1999},
	series={Proceedings of the Seventh IEEE International Conference on Computer Vision},
	publisher={IEEE Comput. Soc},
	address={Kerkyra, Greece},
	organization={Dept. of Comput. Sci., British Columbia Univ., Vancouver, BC, Canada},
	volume={2},
	pages={1150-1157},
	note={M1: Copyright 1999, IEE},
	abstract={An object recognition system has been developed that uses a new class of local image features. The features are invariant to image scaling, translation, and rotation, and partially invariant to illumination changes and affine or 3D projection. These features share similar properties with neurons in inferior temporal cortex that are used for object recognition in primate vision. Features are efficiently detected through a staged filtering approach that identifies stable points in scale space. Image keys are created that allow for local geometric deformations by representing blurred image gradients in multiple orientation planes and at multiple scales. The keys are used as input to a nearest neighbor indexing method that identifies candidate object matches. Final verification of each match is achieved by finding a low residual least squares solution for the unknown model parameters. Experimental results show that robust object recognition can be achieved in cluttered partially occluded images with a computation time of under 2 seconds},
	keywords={computational geometry; feature extraction; image matching; least squares approximations; object recognition},
	isbn={0 7695 0164 8}
}
@misc{RefWorks:53,
  author = 	 {LSRO/EPFL},
  year = 	 {2005},
  title = 	 {High Precision Robotics Group,Ecole Polytechnique FÃ©dÃ©rale de Lausanne},
  url =          {http://microrobotics.epfl.ch/}
}
@article{RefWorks:64,
	author={M. Ludwig and W. Dettmann and H. E. Gaub},
	year={1997},
	title={Atomic force microscope imaging contrast based on molecular recognition},
	journal={Biophysical journal},
	volume={72},
	number={1},
	pages={445-448}
}
@article{RefWorks:141,
	author={S. Mahmoodi and B. S. Sharif},
	year={2006/2/1},
	title={Nonlinear optimisation method for image segmentation and noise reduction using geometrical intrinsic properties},
	journal={Image and Vision Computing},
	volume={24},
	number={2},
	pages={202-209},
	keywords={Optimisation; Edge detection; Noise reduction; Partial differential equations; Differential geometry}
}
@article{RefWorks:198,
	author={A. Mardanov and J. Seyfried and S. Fatikow},
	year={1999},
	title={Automated assembly system for a microassembly station},
	journal={Computers in Industry},
	volume={38},
	number={2},
	pages={93-102},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={The production of complex microsystems from a number of microcomponents made of different materials requires flexible, precise mechanisms, which can finely manipulate different types of objects. The microassembly has its specifics caused by the tiny dimensions of the robots, high accuracy and complicated vision and control systems required. This paper presents a concept of an intelligent microassembly planning system. This system has been implemented in a micromanipulation station with mobile piezoelectric microrobots, which has been developed at the Institute for Process Control and Robotics (IPR) at the University of Karlsruhe. This research considers the assembly system as a complex system and represents a microassembly environment for the microassembly station. The information flow, interacting and functioning of separate parts of the micromanipulation station are determined and the integration of the assembly subsystem into the station are presented. The principal approaches for each part of the system are given.},
	keywords={Computer integrated manufacturing; Factory automation; Computer systems programming; Computer control systems; Strategic planning; Intelligent robots; Mobile robots; Computer vision; Personal computers; Manipulators},
	isbn={0166-3615},
	url={http://dx.doi.org/10.1016/S0166-3615(98)00111-0}
}
@article{RefWorks:75,
	author={J. McArthur},
	year={1972},
	title={The rapid identification of Vibrio cholerae. A method for the recognition of Vibrio cholerae literally within seconds, with the microscope held in the hand and under adverse conditions},
	journal={Transactions of the Royal Society of Tropical Medicine and Hygiene},
	volume={66},
	number={4},
	pages={538-539}
}
@article{RefWorks:94,
	author={A. S. Mian and M. Bennamoun and R. A. Owens},
	year={2006},
	title={A novel representation and feature matching algorithm for automatic pairwise registration of range images},
	journal={International Journal of Computer Vision},
	volume={66},
	number={1},
	pages={19-40},
	note={Compilation and indexing terms, Copyright 2005 Elsevier Engineering Information, Inc.},
	abstract={Automatic registration of range images is a fundamental problem in 3D modeling of free-from objects. Various feature matching algorithms have been proposed for this purpose. However, these algorithms suffer from various limitations mainly related to their applicability, efficiency, robustness to resolution, and the discriminating capability of the used feature representation. We present a novel feature matching algorithm for automatic pairwise registration of range images which overcomes these limitations. Our algorithm uses a novel tensor representation which represents semi-local 3D surface patches of a range image by third order tensors. Multiple tensors are used to represent each range image. Tensors of two range images are matched to identify correspondences between them. Correspondences are verified and then used for pairwise registration of the range images. Experimental results show that our algorithm is accurate and efficient. Moreover, it is robust to the resolution of the range images, the number of tensors per view, the required amount of overlap, and noise. Comparisons with the spin image representation revealed that our representation has more discriminating capabilities and performs better at a low resolution of the range images. &copy; 2006 Springer Science + Business Media, Inc.},
	keywords={Feature extraction; Algorithms; Optical resolving power; Spurious signal noise; Object recognition; Tensors; Image processing},
	isbn={0920-5691},
	url={http://dx.doi.org/10.1007/s11263-005-3221-0}
}
@misc{RefWorks:49,
  author = 	 {MiCRoN},
  year = 	 {2005},
  title = 	 {Miniaturised Co-operative Robots advancing towards the Nano range},
  url =          {http://wwwipr.ira.uka.de/\%7Emicron/},
  annote = {"~" in url-command doesn't work}
}
@article{RefWorks:24,
	author={Krystian Mikolajczyk and Cordelia Schmid},
	year={2005},
	title={A performance evaluation of local descriptors},
	journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
	volume={27},
	number={10},
	pages={1615-1630},
	note={Compilation and indexing terms, Copyright 2005 Elsevier Engineering Information, Inc.},
	abstract={In this paper, we compare the performance of descriptors computed for local interest regions, as, for example, extracted by the Harris-Affine detector [32]. Many different descriptors have been proposed in the literature. It is unclear which descriptors are more appropriate and how their performance depends on the interest region detector. The descriptors should be distinctive and at the same time robust to changes in viewing conditions as well as to errors of the detector. Our evaluation uses as criterion recall with respect to precision and is carried out for different image transformations. We compare shape context [3], steerable filters [12], PCA-SIFT [19], differential invariants [20], spin images [21], SIFT [26], complex filters [37], moment invariants [43], and cross-correlation for different types of interest regions. We also propose an extension of the SIFT descriptor and show that it outperforms the original method. Furthermore, we observe that the ranking of the descriptors is mostly independent of the interest region detector and that the SIFT-based descriptors perform best. Moments and steerable filters show the best performance among the low dimensional descriptors. &copy; 2005 IEEE.},
	keywords={Feature extraction; Edge detection; Pattern matching; Invariance; Mathematical transformations; Correlation methods; Pattern recognition systems},
	isbn={0162-8828},
	url={http://dx.doi.org/10.1109/TPAMI.2005.188}
}
@inproceedings{RefWorks:23,
	author={Krystian Mikolajczyk and Cordelia Schmid},
	year={2003},
	title={A performance evaluation of local descriptors},
	booktitle={2003 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, Jun 18-20 2003},
	series={Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
	publisher={Institute of Electrical and Electronics Engineers Computer Society},
	address={Madison, WI, United States},
	organization={INRIA Rhone-Alpes, GRAVIR-CNRS, 38330 Montbonnot, France},
	volume={2},
	pages={257-263},
	note={Compilation and indexing terms, Copyright 2005 Elsevier Engineering Information, Inc.},
	abstract={In this paper we compare the performance of interest point descriptors. Many different descriptors have been proposed in the literature. However, it is unclear which descriptors are more appropriate and how their performance depends on the interest point detector. The descriptors should be distinctive and at the same time robust to changes in viewing conditions as well as to errors of the point detector. Our evaluation uses as criterion detection rate with respect to false positive rate and is carried out for different image transformations. We compare SIFT descriptors [11], steerable filters [5], differential invariants [10], complex filters [17], moment invariants [21] and cross-correlation for different types of interest points [8, 11, 13, 14]. In this evaluation, we observe that the ranking of the descriptors does not depend on the point detector and that SIFT descriptors perform best. Steerable filters come second; they can be considered a good choice given the low dimensionality.},
	keywords={Object recognition; Performance; Computational complexity; Correlation methods; Pattern matching},
	isbn={1063-6919}
}
@techreport{RefWorks:56,
	author={MINIMAN-Consortium},
	year={2002},
	month=jan,
	title={MINIMAN Miniaturised Robot for Mi\-cro Ma\-ni\-pu\-la\-ti\-on},
	institute={ESPRIT-Project No. 33915},
	url={http://wwwipr.ira.uka.de/\%7Emicrobot/miniman/results/Miniman-PublicFinalReport-screen.pdf},
        annote = {Miniman final report}
}

@misc{RefWorks:46,
  author = 	 {MMVL},
  year = 	 {2005},
  title = 	 {Mimas computer vision library},
  url = {http://www.shu.ac.uk/mmvl/mimas/}
}
@misc{RefWorks:45,
  author = 	 {MMVL/SHU},
  year = 	 {2005},
  title = 	 {Microsystems \& Machine Vision Lab, Sheffield Hallam University},
  url = {http://www.shu.ac.uk/mmvl/}
}
@inproceedings{RefWorks:202,
	author={R. Munassypov and B. Grossmann and B. Magnussen and S. Fatikow},
	year={1996},
	title={Development and control of piezoelectric actuators for a mobile micromanipulation system},
	booktitle={Proceedings of Actuator '96, 26-28 June 1996},
	series={Actuator 96. 5th International Conference on New Actuators. Conference Proceedings},
	publisher={AXON Technologie Consult GmbH},
	address={Bremen, Germany},
	organization={Karlsruhe Univ., Germany},
	pages={213-216},
	note={M1: Copyright 1997, IEE},
	abstract={Mobile microrobots, which are capable of performing microscopic tasks, have become a subject of great interest all over the world. They have the potential to be used for a variety of applications: in industry for microassembly tasks or for the testing of silicon chips, in medicine for handling biological cells, etc. To provide a microrobot with both the transportation and micromanipulation capabilities, various designs of piezoelectric actuators can be used which can perform very fine positioning in the nm-range. This paper presents a view on the problem of the design and control of mobile piezoelectric platforms for microrobots},
	keywords={biocontrol; cellular biophysics; elemental semiconductors; industrial manipulators; microactuators; mobile robots; piezoelectric actuators; position control; silicon}
}
@inproceedings{RefWorks:137,
	author={Muralidhar Krishnaprasad and Z. H. Liu and Anand Manikutty and J. W. Warner and Vikas Arora},
	year={2005},
	title={Towards an industrial strength SQL/XML infrastructure},
	booktitle={Proceedings. 21st International Conference on Data Engineering, 5-8 April 2005},
	series={Proceedings. 21st International Conference on Data Engineering},
	publisher={IEEE Comput. Soc},
	address={Tokoyo, Japan},
	organization={Oracle Corp., Redwood Shores, CA, USA},
	pages={991-1000},
	note={M1: Copyright 2005, IEE},
	abstract={XML has become an attractive data processing model for applications. SQL/XML is a SQL standard that integrates XML with SQL. It introduces the XML datatype as a native SQL datatype and defines XML generation functions in the SQL/XML 2003 standard. The goal for the next version of SQL/XML is integrating XQuery with SQL by supporting XQuery embedded inside SQL functions such as the XMLQuery and XMLTable functions. Starting with the 9i database release, Oracle has supported the XML datatype and various operations on XML instances. In this paper, we present the design and implementation strategies of the SQL/XML standard in Oracle XMLDB. We explore the various critical infrastructures needed in the SQL database kernel to support an efficient native XML datatype implementation and the design approaches for efficient generation, query and update of the XML instances. Furthermore, we also illustrate extensions to SQL/XML that makes Oracle XMLDB a truly industrial strength platform for XML processing},
	keywords={query processing; relational databases; SQL; XML},
	isbn={0 7695 2285 8}
}
@inproceedings{RefWorks:9,
	author={M. Noguchi and S. K. Nayar},
	year={1994},
	title={Microscopic shape from focus using active illumination},
	booktitle={Proceedings of 12th International Conference on Pattern Recognition, 9-13 Oct. 1994},
	series={Proceedings of the 12th IAPR International Conference on Pattern Recognition (Cat. No.94CH3440-5)},
	publisher={IEEE Comput. Soc. Press},
	address={Jerusalem, Israel},
	organization={Dept. of Comput. Sci., Columbia Univ., New York, NY, USA},
	volume={1},
	pages={147-152},
	note={M1: Copyright 1995, IEE},
	abstract={Shape from focus relies on surface texture for the computation of depth. In many real-world applications, surfaces can be smoothly shaded and lacking in detectable texture. In such cases, shape from focus generates inaccurate and sparse depth maps. This paper presents a novel extension to the original shape from focus method. A strong texture is forced on imaged surfaces by the use of active illumination. The exact pattern of the projected illumination is determined through a careful Fourier analysis of all the optical effects involved in focus analysis. When the focus operator used is a 2D Laplacian, the optimal illumination pattern is found to be a checkerboard whose pitch is the same size as the distance between adjacent elements in the discrete Laplacian kernel. This analysis also reveals the exact number of images required for accurate shape recovery. These results are experimentally verified using an optical microscope. Surfaces lacking in texture, such as, three-dimensional structures on silicon substrates and solder joints on circuit boards were used in the experiments. The results show that the derived illumination pattern is in fact optimal, facilitating accurate shape recovery of complex and pertinent industrial samples},
	keywords={active vision; Fourier transform optics; image recognition; optical microscopy},
	isbn={0 8186 6265 4},
	url={http://dx.doi.org/10.1109/ICPR.1994.576247}
}
@article{RefWorks:95,
	author={Abhijit S. Ogale and Yiannis Aloimonos},
	year={2005},
	title={Shape and the stereo correspondence problem},
	journal={International Journal of Computer Vision},
	volume={65},
	number={3},
	pages={147-162},
	note={Compilation and indexing terms, Copyright 2005 Elsevier Engineering Information, Inc.},
	abstract={We examine the implications of shape on the process of finding dense correspondence and half-occlusions for a stereo pair of images. The desired property of the disparity map is that it should be a piecewise continuous function which is consistent with the images and which has the minimum number of discontinuities. To zeroth order, piecewise continuity becomes piecewise constancy. Using this approximation, we first discuss an approach for dealing with such a fronto-parallel shapeless world, and the problems involved therein. We then introduce horizontal and vertical slant to create a first order approximation to piecewise continuity. In particular, we emphasize the following geometric fact: a horizontally slanted surface (i.e., having depth variation in the direction of the separation of the two cameras) will appear horizontally stretched in one image as compared to the other image. Thus, while corresponding two images, N pixels on a scanline in one image may correspond to a different number of pixels M in the other image. This leads to three important modifications to existing stereo algorithms: (a) due to unequal sampling, existing intensity matching metrics must be modified, (b) unequal numbers of pixels in the two images must be allowed to correspond to each other, and (c) the uniqueness constraint, which is often used for detecting occlusions, must be changed to an interval uniqueness constraint. We also discuss the asymmetry between vertical and horizontal slant, and the central role of non-horizontal edges in the context of vertical slant. Using experiments, we discuss cases where existing algorithms fail, and how the incorporation of these new constraints provides correct results. &copy; 2005 Springer Science + Business Media, Inc.},
	keywords={Image analysis; Problem solving; Constraint theory; Cameras; Approximation theory; Functions; Algorithms; Stereo vision},
	isbn={0920-5691},
	url={http://dx.doi.org/10.1007/s11263-005-3672-3}
}
@inproceedings{RefWorks:121,
	author={Kohtaro Ohba and Jesus Carlos Pedraza Ortega and Kazuo Tanie and Gakuyoshi Rin and Ryoichi Dangi and Yoshinori Takei and Takashi Kaneko and Nobuaki Kawahara},
	year={2001},
	title={Micro-observation technique for tele-micro-operation},
	booktitle={2000 IEEE/RSJ International Conference on Intelligent Robots and Systems (Iros 2000), Oct 30-Nov 5 2000},
	series={Advanced Robotics},
	publisher={VSP BV},
	address={Takamatsu City},
	organization={NIAIST, Tsukuba 305-8564, Japan},
	volume={15},
	chapter={8},
	pages={781-798},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={In this paper, an observational sensor system for tele-micro-operation is proposed with a dynamic focusing lens and a smart vision sensor using the 'depth from focus' criteria. Recently, micro-operations, such as for micro-surgery, DNA manipulations, etc., have gained in importance. However, the small depth of focus of the microscope produces poor observability. For example, if the focus is on the object, the actuator cannot be seen with the microscope. On the other hand, if the focus is on the actuator, the object cannot be observed. In this sense, the 'all-in-focus image', which holds the in-focused texture all over the image, is useful to observe the micro-environments with a microscope. One drawback of the all-in-focus image is that there is no information about the depth of objects. It is also important to obtain the depth map and show the three-dimensional (3D) micro virtual environments in real-time to actuate the micro objects intuitively. First, this paper reviews the criteria of 'depth from focus' to achieve the all-in-focus image and the 3D micro environments' simultaneous reconstruction. After evaluating the validity of this criteria with off-line simulation, a real-time virtual reality (VR) micro camera system is proposed to achieved the micro VR environments with the 'depth from focus' criteria. This system is constructed with a dynamic focusing lens, which can change its focal distance at a high frequency, and a smart vision system, which is capable of capturing and processing the image data in high speed with SIMD architecture.},
	keywords={Computer vision; Imaging techniques; Proximity sensors; Observability; Image analysis; Lenses; Cameras; Knowledge based systems; Virtual reality; Real time systems; Image reconstruction; Computer simulation},
	isbn={0169-1864},
	url={http://dx.doi.org/10.1163/156855301317198124}
}
@article{RefWorks:117,
	author={Kohtaro Ohba and Jesus Carlos Pedraza Ortega and Kazuo Tanie and Masataka Tsuji and Shigeru Yamada},
	year={2003},
	title={Microscopic vision system with all-in-focus and depth images},
	journal={Machine Vision and Applications},
	volume={15},
	number={2},
	pages={55-62},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={In this paper, a high-speed digital processed microscopic observational system for telemicrooperation is proposed with a dynamic focusing system and a high-speed digital-processing system using the "depth from focus" criterion. In our previous work [10], we proposed a system that could simultaneously obtain an "all-in-focus image" as well as the "depth" of an object. In reality, in a microoperation, it is not easy to obtain good visibility of objects with a microscope focused at a shallow depth, especially in microsurgery and DNA studies, among other procedures. In this sense, the all-in-focus image, which keeps an in-focus texture over the entire object, is useful for observing microenvironments with the microscope. However, one drawback of the all-in-focus image is that there is no information about the objects' depth. It is also important to obtain a depth map and show the 3D microenvironments at any view angle in real time to actuate the microobjects. Our earlier system with a dynamic focusing lens and a smart sensor could obtain the all-in-focus image and the depth in 2 s. To realize real-time microoperation, a system that could process at least 30 frames per second (60 times faster than the previous system) would be required. This paper briefly reviews the depth from focus criterion to Simultaneously achieve the all-in-focus image and the reconstruction of 3D microenvironments. After discussing the problem inherent in our earlier system, a frame-rate system constructed with a high-speed video camera and FPGA (field programmable gate array) hardware is discussed. To adapt this system for use with the microscope, new criteria to solve the "ghost problem" in reconstructing the all-in-focus image are proposed. Finally, microobservation shows the validity of this system. &copy; Springer-Verlag 2003.},
	keywords={Image analysis; Vision; Microscopic examination; Focusing; Surgery; DNA; Image reconstruction; Field programmable gate arrays; Problem solving; Video cameras},
	isbn={0932-8092},
	url={http://dx.doi.org/10.1007/s00138-003-0125-2}
}
@inproceedings{RefWorks:131,
	author={Kohtaro Ohba and Jesus Carlos Pedraza Ortega and Kazuo Tanie and Masataka Tsuji and Shigeru Yamada},
	year={2001},
	title={High-speed image processing system for tele-micro-operation},
	booktitle={2001 IEEE/RSJ International Conference on Intelligent Robots and Systems, Oct 29-Nov 3 2001},
	series={IEEE International Conference on Intelligent Robots and Systems},
	publisher={Institute of Electrical and Electronics Engineers Inc},
	address={Maui, HI},
	organization={Natl. Inst. Adv. Indust. Sci. Tech., Tsukuba, 305-8564, Japan},
	volume={1},
	pages={349-354},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={In this paper, an observational system for the tele-micro-operation has been proposed with a dynamic focusing system and a high-speed image processing system using the "depth from focus" criteria. In our past work, we had proposed the system which could obtain the "all-in-focus image" and the "depth" of object, simultaneously. Actually, in micro operation, such as for the micro-surgery, DNA operation and etc., the small depth of a focus on the microscope makes bad observability. In this sense, the "all-in-focus image", which holds the in-focused texture all over the image, is useful to observe the micro environments with the microscope. It is also important to obtain the depth map, and to show the 3D micro virtual environments in real-time to actuate the micro objects, intuitively. The past system with dynamic focusing lens and the smart sensor could obtain the "all-in-focus image" and the "depth" in 2sec. To realize the real-time micro operation, at least, 30 frame/sec (60 times faster than the past) system should be required. At first, this paper briefly reviews the criteria of "depth from focus" to achieve the all-in-focus image and the 3D micro environments' reconstruction, simultaneously. After discussing the problem in our past system, a new frame-rate system is constructed with the high-speed video camera and FPGA hardware. To apply this system in the real microscope, new criteria to reconstruct the all-in-focus image is proposed. Finally, the micro observation shows the validity of this system.},
	keywords={Microsensors; Factory automation; Image reconstruction; Microelectronic processing; Virtual reality; Real time systems; Video cameras; Field programmable gate arrays},
	url={http://dx.doi.org/10.1109/IROS.2001.973382}
}
@inproceedings{RefWorks:132,
	author={Kohtaro Ohba and Jesus Carlos Pedraza Ortega and Tamio Tanikawa and Kazuo Tanie and Kenji Tajima and Hiroshi Nagai and Masataka Tsuji and Shigeru Yamada},
	year={2002},
	title={High speed image processing system and its micro optics application},
	booktitle={PROCEEDINGS SPIE - The International Society for Optical Engineering: 25th International Congress on High-Speed Photography and Photonics, Sep 29-Oct 4 2002},
	series={Proceedings of SPIE - The International Society for Optical Engineering},
	publisher={The International Society for Optical Engineering},
	address={Beaune, France},
	organization={NIAIST, Tsukuba 305-8564, Japan},
	volume={4948},
	pages={205-212},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={In this paper, a new application system with high speed photography, i.e. an observational system for the tele-micro-operation, has been proposed with a dynamic focusing system and a high-speed image processing system using the "Depth From Focus (DFF)" criteria. In micro operation, such as for the microsurgery, DNA operation and etc., the small depth of a focus on the microscope makes bad observation. For example, if the focus is on the object, the actuator cannot be seen with the microscope. On the other hand, if the focus is on the actuator, the object cannot be observed. In this sense, the "all-in-focus image", which holds the in-focused texture all over the image, is useful to observe the microenvironments on the microscope. It is also important to obtain the "depth map" which could show the 3D micro virtual environments in real-time to actuate the micro objects, intuitively. To realize the real-time micro operation with DFF criteria, which has to integrate several images to obtain "all-in-focus image" and "depth map", at least, the 240 frames par second based image capture and processing system should be required. At first, this paper briefly reviews the criteria of "depth from focus" to achieve the all-in-focus image and the 3D microenvironments' reconstruction, simultaneously. After discussing the problem in our past system, a new frame-rate system is constructed with the high-speed video camera and FPGA hardware with 240 frames par second. To apply this system in the real microscope, a new criterion "ghost filtering" technique to reconstruct the all-in-focus image is proposed. Finally, the micro observation shows the validity of this system.},
	keywords={High speed photography; Image reconstruction; Microoptics; Three dimensional computer graphics; Virtual reality; Video cameras; Field programmable gate arrays; Microscopes; Focusing},
	isbn={0277-786X},
	url={http://dx.doi.org/10.1117/12.516776}
}
@article{RefWorks:235,
	author={K. Parsa and J. Angeles and A. K. Misra},
	year={2005},
	month=dec,
	title={Control of macro-micro manipulators revisited},
	journal={Transactions of the ASME.Journal of Dynamic Systems, Measurement and Control},
	volume={127},
	number={4},
	pages={688-699},
	note={M1: Copyright 2005, IEE},
	abstract={A full-pose, position and orientation, trajectory-tracking control of kinematically redundant flexible-macro-rigid-micro manipulators is proposed. Redundancy is resolved such that the forces exciting the lowest-frequency "modal coordinates" of the system are minimized, while imposing a proportional damping on the flexural dynamics, rendering it stable under certain conditions. The simulation results show that the initial posture of the manipulator plays an important role in satisfying the foregoing stability conditions},
	keywords={control system synthesis; flexible manipulators; manipulator dynamics; micromanipulators; position control; redundant manipulators; stability},
	isbn={0022-0434},
	url={http://dx.doi.org/10.1115/1.1870039}
}
@inproceedings{RefWorks:247,
	author={B. Parvin and J. Taylor and G. Cong},
	year={1998},
	title={A collaborative framework for distributed microscopy},
	booktitle={Proceedings of Supercomputing '98, 7-13 Nov. 1998},
	series={Proceedings of ACM/IEEE SC98: 10th Anniversary. High Performance Networking and Computing Conference (Cat. No. RS00192)},
	publisher={IEEE Comput. Soc},
	address={Orlando, FL, USA},
	organization={Div. of Inf. \& Comput. Sci., Lawrence Berkeley Lab., CA, USA},
	pages={13},
	note={M1: Copyright 1999, IEE},
	abstract={Outlines a collaborative framework for distributed virtual microscopy.  The requirements are specified in terms of functionality, scalability,  interactivity, and safety and security. To meet these requirements, we  introduce three types of services in the architecture: instrument  services (IS), exchange services (ES) and computational services (CS).  The IS provide an abstraction for manipulating different types of  microscopes; the ES provide common services that are required between  different resources; and the CS provide analytical capabilities for  data analysis and simulation. These services are brought together  through CORBA. Two applications have been introduced into the CS for  analyzing scientific images: in-situ electron microscopy, and recovery  of 3D shape from holographic microscopy. The first application provides  a near-real-time processing of the video-stream for online quantitative  analysis and the use of that information for closed-loop servo control.  The second application reconstructs a 3D representation of an inclusion  from multiple views through holographic electron microscopy. These  applications require steering external stimuli or computational  parameters for a particular result. In a sense,  &ldquo;computational instruments&rdquo; interact closely with  data generated from &ldquo;experimental instruments&rdquo; to  conduct new experiments and bring new functionalities to these  instruments. Both of these features exploit high-performance computing  and low-latency networks to bring novel functionalities to unique  scientific imaging instruments},
	keywords={distributed object management; distributed processing; electron holography; electron microscopy; groupware; image restoration; natural sciences computing; virtual instrumentation}
}
@inproceedings{RefWorks:120,
	author={J. Carlos Pedraza and Kohtaro Ohba and J. Wilfrido Rodriguez and Kazuo Tanie},
	year={2001},
	title={All in focus camera vision system for robot navigation and manipulation based on the DFF criteria},
	booktitle={2001 IEEE/RSJ International Conference on Intelligent Robots and Systems, Oct 29-Nov 3 2001},
	series={IEEE International Conference on Intelligent Robots and Systems},
	publisher={Institute of Electrical and Electronics Engineers Inc},
	address={Maui, HI},
	organization={University of Tsukuba, Tsukuba, Japan},
	volume={2},
	pages={758-763},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={A method to improve the resolution in depth by applying the depth from focus criteria is proposed. The depth from focus is a criteria used to get simultaneously both the all-in-focus image and three-dimensional information with a single camera. But in these criteria there is a well-known drawback; the resolution is good only at short distances. Here, the optical characteristic that describes the limitation of the measurement range is analyzed. Later, a better criterion to improve the resolution in the depth is proposed by considering the "best focal distance". In order to use this new method, it's necessary to modify the focal distance (zoom) in the camera. Then, an accurate control of the camera should be done to acquire a good view of the desired target and later by applying the depth from focus criteria together with the best focal distance, being able to obtain good depth (three-dimensional) information.},
	keywords={Robotics; Computer vision; Cameras; Depth perception; Motion planning; Navigation; Manipulators; Three dimensional; Image reconstruction; Image quality; Algorithms; Object recognition},
	url={http://dx.doi.org/10.1109/IROS.2001.976260}
}
@article{RefWorks:238,
	author={Peng Gao and Shan-Min Swei},
	year={1999},
	month=dec,
	title={A six-degree-of-freedom micro-manipulator based on piezoelectric translators},
	journal={Nanotechnology},
	volume={10},
	number={4},
	pages={447-452},
	note={M1: Copyright 2000, IEE},
	abstract={High-performance actuation is always desirable in a dexterous high-precision manipulation system. In this paper, we first develop a single-degree-of-freedom piezoelectric translator composed of a piezoelectric stack, a monolithic leaf spring and a preload mechanism. The displacement resolution reached by this translator is better than 10 nm, while its natural frequency is over 2 kHz. Based on the developed piezoelectric translator, a micro-manipulator is then designed, which is capable of producing micro-motions in six degrees of freedom. The design characteristics and kinematics of this micro-manipulator are investigated. An effective kinematic model used for the real-time control is presented, and the operation performance of the micro-manipulator is discussed further},
	keywords={dexterous manipulators; frequency response; manipulator kinematics; microactuators; micromanipulators; micropositioning; piezoelectric actuators},
	isbn={0957-4484},
	url={http://dx.doi.org/10.1088/0957-4484/10/4/315}
}
@inproceedings{RefWorks:3,
	author={P. Perner and H. Perner and S. Janichen and A. Buhring},
	year={2004},
	title={Recognition of airborne fungi spores in digital microscopic images},
	booktitle={Proceedings of the 17th International Conference on Pattern Recognition, 23-26 Aug. 2004},
	series={Proceedings of the 17th International Conference on Pattern Recognition},
	publisher={IEEE Comput. Soc},
	address={Cambridge, UK},
	organization={Inst. of Comput. Vision & Appl. Comput. Sci., IBAI, Leipzig, Germany},
	volume={3},
	pages={566-569},
	note={M1: Copyright 2005, IEE},
	abstract={We propose and evaluate a method for the recognition of airborne fungi spores. We use a model-based object recognition method to identify spores in a digital microscopic image. We do not use the gray values of the model, but use the object edges instead. The similarity measure measures the average angle between the vectors of the template and the object. Model generation is done semi-automatically by manually tracing the object, automatic shape alignment, similarity calculation, clustering and prototype calculation},
	keywords={approximation theory; microorganisms; object recognition; optical microscopy; vectors},
	isbn={0 7695 2128 2}
}
@article{RefWorks:245,
	author={V. T. Portman and B. -Z Sandler and E. Zahavi},
	year={2001},
	month=jul,
	title={Rigid 6-DOF parallel platform for precision 3-D micromanipulation},
	journal={International Journal of Machine Tools & Manufacture},
	volume={41},
	number={9},
	pages={1229-1250},
	note={M1: Copyright 2001, IEE},
	abstract={A new type of 6-DOF platform mechanism characterized by very high stiffness and a high degree of accuracy is described. Welded joints connecting the changeable links with the platform and base provide the high stiffness. Hydraulically controlled microactuators use longitudinal elastic deformations for elongation of the legs. Infinitesimal kinematics of a conventional platform, the finite-elements method, and an identification procedure are used for the analysis of the mechanism. Experimental investigations of a pilot set-up of the proposed platform confirmed the predictions concerning the accuracy and stiffness of the proposed device. A practical application of the platform as a secondary table for precise machining on a CNC milling center is described},
	keywords={finite element analysis; hydraulic control equipment; manipulator kinematics; microactuators; micromanipulators},
	isbn={0890-6955},
	url={http://dx.doi.org/10.1016/S0890-6955(01)00027-X}
}
@misc{RefWorks:51,
  author = 	 {Povray},
  year = 	 {2005},
  title = 	 {Persistence Of Vision Raytracer},
  url = {http://www.povray.org/}
}
@inproceedings{RefWorks:156,
	author={Arthur E. Quaid and Ralph L. Hollis},
	year={1998},
	title={3-DOF closed-loop control for planar linear motors},
	booktitle={Proceedings of the 1998 IEEE International Conference on Robotics and Automation. Part 3 (of 4), May 16-20 1998},
	publisher={IEEE, Piscataway, NJ, USA},
	address={Leuven, Belgium},
	organization={Carnegie Mellon Univ, Pittsburgh, PA, USA},
	volume={3},
	pages={2488-2493},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={Planar linear motors (Sawyer motors) have been used in industry as open-loop stepping motors, but their robustness and versatility has been limited. Using a sensor recently integrated into such a motor, a closed-loop 3-DOF controller has been implemented. The software-based control system consists of a commutator for computing amplifier currents from actuator forces, a force resolution function for solving the redundant actuation and saturation problems, and an observer for producing a velocity estimate, together with a PID controller. Experiments are performed using a 2-axis laser interferometer to show that the controller has sub-micron resolution, 2 &micro;m peak-to-peak repeatability, and settling times after trajectories of about 20 ms. Limitations of the PID controller are discussed and ideas for improvements are presented.},
	keywords={Linear motors; Closed loop control systems; Degrees of freedom (mechanics); Sensors; Computer software; Electric commutators; Electric currents; Actuators; Three term control systems; Interferometers; Laser applications},
	isbn={1050-4729},
	url={http://dx.doi.org/10.1109/ROBOT.1998.680715}
}
@inproceedings{RefWorks:158,
	author={Arthur E. Quaid and Ralph L. Hollis},
	year={1996},
	title={Cooperative 2-DOF robots for precision assembly},
	booktitle={Proceedings of the 1996 13th IEEE International Conference on Robotics and Automation. Part 3 (of 4), Apr 22-28 1996},
	publisher={IEEE, Piscataway, NJ, USA},
	address={Minneapolis, MN, USA},
	organization={Carnegie Mellon Univ, Pittsburgh, PA, USA},
	volume={3},
	pages={2188-2193},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={A new configuration of cooperative 2-DOF robots is presented for use in precision assembly applications. This configuration consists of direct drive planar linear motors traveling on a tabletop platen stator surface combined with overhead 2-DOF manipulators. We outline desirable features of a precision assembly system and use them to compare the proposed configuration to typical configurations that use 4-DOF robots. Advantages of the new approach are used to motivate further research needed to fully develop precision assembly systems based on this concept.},
	keywords={Robotic assembly; Degrees of freedom (mechanics); Precision engineering; Linear motors; Stators; Sensors; Actuators; Robotic arms; Manipulators; Laser welding machines},
	isbn={1050-4729},
	url={http://dx.doi.org/10.1109/ROBOT.1996.506193}
}
@article{RefWorks:189,
	author={U. Rembold and S. Fatikow},
	year={1997},
	month=aug,
	title={Autonomous microrobots},
	journal={Journal of Intelligent and Robotic Systems: Theory and Applications},
	volume={19},
	number={4},
	pages={375-391},
	note={M1: Copyright 1997, IEE},
	abstract={In order to make robots more versatile they must be able to operate in a semi-structured work place where unforeseen events occur and where sensor data are incomplete. An entire research community has been working on this problem and many unique autonomous and so-called intelligent robots have been conceived and built. Most of these efforts are concerned with robots that operate in the macroworld where they take on chores that could also be handled by humans. However, there is the microworld in which manipulation and handling tasks are very difficult and for which a human has no tools and where the work area is so small that fine manual manipulation is almost impossible. This paper is concerned with autonomous robots that can operate in a microworld, where microassembly operations, microsurgery or integrated circuit testing and repair is done. For independent operations, these robots need special sensors and an efficient computer architecture that hosts the planner and executor. There are also special drive systems and effectors necessary for micromotions and micromanipulations, respectively. An attempt is made to describe these components and the problems encountered in configuring them to a microrobot. As an example of advanced microrobots, the design and functions of several autonomous microrobots of the University of Karlsruhe are shown; they employ different locomotion and subject handling principles. The paper also includes a discussion of the typical operating problems caused by the microworld and of future research that has to be done to conceive and build efficient microrobots},
	keywords={integrated circuit testing; manipulators; microactuators; microassembling; motion control; piezoelectric actuators},
	isbn={0921-0296},
	url={http://dx.doi.org/10.1023/A:1007987316940}
}
@inproceedings{RefWorks:152,
	author={Carolyn L. Ren and Dongqing Li},
	year={2004},
	title={Sample manipulation in microfluidic devices with electrical conductivity gradients},
	booktitle={Proceedings of the Second International Conference on Microchannels and Minichannels (ICMM2004), Jun 17-19 2004},
	series={Proceedings of the Second International Conference on Microchannels and Minichannels (ICMM2004)},
	publisher={American Society of Mechanical Engineers, New York, NY 10016-5990, United States},
	address={Rochester, NY, United States},
	organization={University of Toronto, Toronto, Ont., Canada},
	pages={857-864},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={A common application in microfluidic devices is on-chip capillary electrophoresis (CE). In this process, sample species are transported by electroosmotic flow and separated based on their electrophoretic mobilities. Separated analytes are typically detected using laser-induced fluorescence. It has been found that the sample shape and size, which is critical to the later detection processes or the quality of other analytical techniques, depends on many parameters, such as the sample diffusion coefficient, the applied voltages, and the electrical conductivity difference between sample and buffer. The conductivity difference can alter the electric field strength, which is the driving force behind both the electroosmotic bulk flow and the electrophoretic velocity of individual species. Therefore, the manipulation technique is required to consider the transport processes with conductivity differences. A numerical model presented in this paper is used to simulate the sample transport process with the consideration of conductivity gradient in order to develop the sample manipulation techniques. There are two situations studied here, which are sample pumping (where bulk transport is increased and analyte separation is delayed using a relatively high conductivity sample), and sample stacking (where bulk transport is decreased and analyte separation is expedited using a relatively low conductivity sample). The effects of applied electrical potential, sample diffusion coefficient and the extent of conductivity difference on the sample control are investigated through the developed model. The simulation results show that the sample transport with the consideration of conductivity gradient differs significantly from that of uniform conductivity case.},
	keywords={Flow of fluids; Electric conductivity; Electrophoresis; Electroosmosis; Fluorescence; Capillary flow; Kinetic theory; Separation; Computer simulation},
	isbn={0791841642}
}
@article{RefWorks:59,
	author={I. Rigoutsos and H. Wolfson},
	year={1997},
	title={Geometric Hashing: An Overview},
	journal={IEEE Computational Science Engineering},
	url={http://citeseer.ist.psu.edu/article/rigoutsos97geometric.html}
}
@inproceedings{RefWorks:157,
	author={Alfred A. Rizzi and Jay Gowdy and Ralph L. Hollis},
	year={1997},
	title={Agile assembly architecture: An agent based approach to modular precision assembly systems},
	booktitle={Proceedings of the 1997 IEEE International Conference on Robotics and Automation, ICRA. Part 2 (of 4), Apr 20-25 1997},
	publisher={IEEE, Piscataway, NJ, USA},
	address={Albuquerque, NM, USA},
	organization={Carnegie Mellon Univ, Pittsburgh, PA, USA},
	volume={2},
	pages={1511-1516},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={This paper serves to present our initial thoughts on the design of an architecture for highly flexible, modular, and distributed precision assembly systems. Through the use of a unified design, simulation, programing, and monitoring environment coupled with self-representing cooperative agents this architecture will significantly simplify the process of factory design and deployment. Our demonstration of this architecture takes the form of a `table top' sized assembly system targeted at the partial assembly of high-density magnetic storage devices.},
	keywords={Robotic assembly; Factory automation; Computer simulation; Magnetic storage; Computer architecture; Modular robots; Precision engineering},
	isbn={1050-4729},
	url={http://dx.doi.org/10.1109/ROBOT.1997.614353}
}
@article{RefWorks:153,
	author={Fred Rothganger and Svetlana Lazebnik and Cordelia Schmid and Jean ER -. Ponce},
	year={2006},
	month=mar,
	title={3D Object Modeling and Recognition Using Local Affine-Invariant Image Descriptors and Multi-View Spatial Constraints},
	journal={International Journal of Computer Vision},
	volume={66},
	number={3},
	pages={231-259}
}
@article{RefWorks:60,
	author={B. RuzgienÃ¨ and W. FÃ¶rstner},
	year={2005},
	title={RANSAC for outlier detection},
	journal={Geodesy and Cartography},
	volume={31},
	number={3},
	pages={83-87}
}
@article{RefWorks:133,
	author={Seok-Moon Ryoo and Tae-Sun Choi},
	year={2001},
	title={New approach to 3-D profilometry for the white light interferometric (WLI)},
	journal={IEICE Transactions on Fundamentals of Electronics, Communications and Computer Sciences},
	volume={E84-A},
	number={1},
	pages={378-382},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={A new approach to 3-D profilometry for the white light interferometric (WLI) is presented. The proposed method is the extended depth from focus (EDFF) that determine the zero optical path difference (OPD) from the quantity of fringe contrast degradation of white light interferometer. In the method, the variance of the mismatch function and the modified local variance function are used as the focus measures. The method has a theoretically unlimited range and can profile with subpixel accuracy both optically rough and smooth surfaces without changing algorithm.},
	keywords={Interferometry; Profilometry; Interferometers; Signal processing; Phase shift; Algorithms; Focusing; Functions},
	isbn={0916-8508}
}
@article{RefWorks:243,
	author={S. Saito and H. T. Miyazaki and T. Sato and K. Takahashi},
	year={2002},
	month={11/01},
	title={Kinematics of mechanical and adhesional micromanipulation under a scanning electron microscope},
	journal={Journal of Applied Physics},
	volume={92},
	number={9},
	pages={5140-5149},
	note={M1: Copyright 2003, IEE},
	abstract={In this paper, the kinematics of mechanical and adhesional micromanipulation using a needle-shaped tool under a scanning electron microscope is analyzed. A mode diagram is derived to indicate the possible micro-object behavior for the specified operational conditions. Based on the diagram, a reasonable method for pick and place operation is proposed. The keys to successful analysis are to introduce adhesional and rolling-resistance factors into the kinematic system consisting of a sphere, a needle-shaped tool, and a substrate, and to consider the time dependence of these factors due to the electron-beam (EB) irradiation. Adhesional force and the lower limit of maximum rolling resistance are evaluated quantitatively in theoretical and experimental ways. This analysis shows that it is possible to control the fracture of either the tool-sphere or substrate-sphere interface of the system selectively by the tool-loading angle and that such a selective fracture of the interfaces enables reliable pick or place operation even under EB irradiation. Although the conventional micromanipulation was not repeatable because the technique was based on an empirically effective method, this analysis should provide us with a guideline to reliable micromanipulation},
	keywords={adhesion; electron beam effects; manipulator kinematics; microassembling; micromanipulators; scanning electron microscopes},
	isbn={0021-8979},
	url={http://dx.doi.org/10.1063/1.1512313}
}
@article{RefWorks:171,
	author={S. E. Salcudean and M. Zhu and W. -H Zhu and K. Hashtrudi-Zaad},
	year={2000},
	title={Transparent bilateral teleoperation under position and rate control},
	journal={International Journal of Robotics Research},
	volume={19},
	number={12},
	pages={1185-1202}
}
@article{RefWorks:93,
	author={David B. Salzman},
	year={1990},
	title={Method of general moments for orienting 2D projections of unknown 3D objects},
	journal={Computer Vision, Graphics, and Image Processing},
	volume={50},
	number={2},
	pages={129-156},
	note={Compilation and indexing terms, Copyright 2005 Elsevier Engineering Information, Inc.},
	abstract={We develop a technique using general moments to find the orientations of 2D planar orthographic projections of 3D objects, even if the 3D object has a completely unknown structure. The technique should open new classes of biological materials for ultrastructural analysis, through molecular scale transmission electron microscopy reconstruction applications where the original 3D object's structure is unknown. In machine vision applications where the full 3D structure is known, the technique provides a fast and computationally efficient way to orient projections. The technique can also be used to orient 1D line projections of 2D unknown objects.},
	keywords={Microscopic Examination--Transmission Electron Microscopy; Vision--Artificial; Mathematical Transformations--Fourier Transforms; Image Processing -- Reconstruction},
	isbn={0734-189X}
}
@article{RefWorks:236,
	author={A. J. Sanchez-Salmeron and R. Lopez-Tarazon and R. Guzman-Diana and C. Ricolfe-Viala},
	year={2005},
	month={08/30},
	title={Recent development in micro-handling systems for micro-manufacturing},
	journal={Journal of Materials Processing Technology},
	volume={167},
	number={2-3},
	pages={499-507},
	note={M1: Copyright 2006, IEE},
	abstract={A review on existing systems for handling micro-parts was carried out recently by the authors. The work was focused on the analysis of the main problems which limit the emergence of automated micro-handling systems. Some of the challenges associated with the handling of micro-parts were also examined. A key problem area limiting the emergence of automated micro-handling technology is lack of flexible and high-precision micro-handling machinery. Another problem is the lack of standardization due to which equipment makers spend an excessive amount of time and resources on custom automation solutions. [All rights reserved Elsevier]},
	keywords={grippers; industrial manipulators; materials handling; micromanipulators},
	isbn={0924-0136},
	url={http://dx.doi.org/10.1016/j.jmatprotec.2005.06.027}
}
@article{RefWorks:193,
	author={K. Santa and S. Fatikow and G. Felso},
	year={1999},
	month=aug,
	title={Control of microassembly-robots by using fuzzy-logic and neural networks},
	journal={Computers in Industry},
	volume={39},
	number={3},
	pages={219-227},
	note={M1: Copyright 1999, IEE},
	abstract={An automated micromanipulation desktop-station that has been developed at the University of Karlsruhe includes several piezoelectric microrobots capable of moving over long distances and manipulating in the range of a few nanometers. In this paper, the control problems of the microrobots and the sensor problems in the micromanipulation station are discussed. The ability of an intelligent microsystem to adapt itself to the process requirements is ver important, especially for assembly robots. The microrobots should be able to operate in a partially defined environment and to guarantee a reasonable behavior in unpredictable situations. Control methods are needed, which do not require an exact system model and which allow a reasonable compromise between the real-time information processing and the amount of input data; they must also make definite decisions based on vague or incomplete information. Two promising methods are fuzzy control and control by a neural network. The paper presents some approaches to improve the robot behaviour by using these advanced control methods},
	keywords={adaptive control; fuzzy control; fuzzy logic; industrial manipulators; intelligent control; microassembling; micromanipulators; neural nets},
	isbn={0166-3615},
	url={http://dx.doi.org/10.1016/S0166-3615(98)00138-9}
}
@article{RefWorks:191,
	author={Karoly Santa and Sergej Fatikow},
	year={2000},
	title={Control system for motion control of a piezoelectric micromanipulation robot},
	journal={Advanced Robotics},
	volume={13},
	number={6},
	pages={577-589},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={Micromanipulation by microrobots has become an issue of primary importance in industry and biomedicine, since human manual capabilities are restricted to certain tolerances. The manipulation of biological cells or the assembly of a microsystem composed of several microcomponents are good examples. An automated microrobot-based micromanipulation desktop station has been developed at the University of Karlsruhe. The process of assembly takes place in the field of view of a light optical microscope. This paper focuses on motion control problems of the piezo-driven microrobots employed by the station. The ability to adapt itself to the process requirements is of great importance for micromanipulation robots. They must be able to operate in a partially defined environment and to ensure reasonable behavior in unpredicted situations. A neural control concept based on a reference model is proposed as a solution. It is shown that the neural controller is able to learn the desired behavior. It considerably outperforms an analytically designed linear controller in the real environment.},
	keywords={End effectors; Motion control; Manipulators; Automation; Robotic assembly; Optical microscopy; Neural networks; Linear control systems},
	isbn={0169-1864}
}
@article{RefWorks:113,
	author={R. Schaublin and P. Stadelmann},
	year={1993},
	title={Method for simulating electron microscope dislocation images},
	journal={Materials Science & Engineering A: Structural Materials: Properties, Microstructure and Processing},
	volume={A164},
	number={1-2},
	pages={313-378},
	note={Compilation and indexing terms, Copyright 2005 Elsevier Engineering Information, Inc.},
	abstract={An image simulation program has been developed to quantitatively evaluate transmission electron microscopy (TEM) images of dislocation configurations. It takes into account many beams, includes linear anisotropic elasticity and uses the column approximation. The program simulates the image of 1 to 4 parallel dislocations and their associated planar faults under bright field, dark field and various weak-beam TEM conditions. Simulations of a variety of dislocations are presented here and it is shown that the use of a many-beam calculation is essential in the case of weak-beam identification of weakly dissociated dislocations.},
	keywords={Dislocations (crystals); Transmission electron microscopy; Image processing; Computer simulation},
	isbn={0921-5093}
}
@article{RefWorks:195,
	author={F. Schmoeckel and S. Fatikow},
	year={2000},
	month=mar,
	title={Smart flexible microrobots for scanning electron microscope (SEM) applications},
	journal={Journal of Intelligent Material Systems and Structures},
	volume={11},
	number={3},
	pages={191-198},
	note={M1: Copyright 2001, IEE},
	abstract={In the scanning electron microscope (SEM), specially designed microrobots can act as a flexible assembly facility for hybrid microsystems, as probing devices for in-situ tests on IC structures or just as a helpful teleoperated tool for the SEM operator when examining samples. Several flexible microrobots of this kind have been developed and tested. Driven by piezoactuators, these few cubic centimeters small mobile robots can perform manipulations with a precision of up to 1O nm and transport the gripped objects at speeds of up to 30 mm/s. In accuracy, flexibility and price they are superior to conventional precision robots. A new SEM-suited microrobot prototype is described. The SEM's vacuum chamber has been equipped with various elements like flanges and CCD cameras to enable the robot to operate. In order to use the SEM image for the automatic real-time control of the robots, the SEM's electron beam is actively controlled by a PC. The latter submits the images to the robots' control computer system. For obtaining three-dimensional information in real time, especially for the closed-loop control of a robot end effector, e.g., microgripper, a triangulation method with the luminescent spot of the SEM's electron beam is being investigated},
	keywords={CCD image sensors; closed loop systems; flexible manipulators; intelligent actuators; micromanipulators; microrobots; motion control; physical instrumentation control; piezoelectric actuators; robot vision; scanning electron microscopes; scanning electron microscopy; telerobotics},
	isbn={1045-389X},
	url={http://dx.doi.org/10.1106/CRW1-96ET-3QVN-YV86}
}
@inproceedings{RefWorks:176,
	author={Ferdinand Schmoeckel and Stephan Fahlbusch and Joerg Seyfried and Axel Buerkle and Sergej Fatikow},
	year={2000},
	title={Development of a microrobot-based micromanipulation cell in a scanning electron microscope (SEM)},
	booktitle={Microrobotics and Microassembly II, Nov 5-Nov 6 2000},
	publisher={Society of Photo-Optical Instrumentation Engineers, Bellingham, WA, USA},
	address={Boston, USA},
	organization={Universitaet Karlsruhe (TH), Karlsruhe, Ger},
	volume={4194},
	pages={129-140},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={In the scanning electron microscope (SEM), specially designed microrobots can act as a flexible assembly facility for prototype microsystems, as probing devices for in-situ tests in various applications or just as a helpful teleoperated tool for the SEM operator when examining samples. Several flexible microrobots of this kind have been developed and tested. Driven by piezoactuators, these few cubic centimeters small mobile robots perform manipulations with a precision of up to 20 nm and transport the gripped objects at speeds of up to 3 cm/s. New microrobot prototypes being employed in the SEM are described in this paper. The SEM's vacuum chamber has been equipped with various elements to enable the robots to operate. In order to use the SEM image for automatic real-time control of the robots, the SEM's electron beam is actively controlled by a PC. The latter submits the images to the robots' control computer system. For obtaining three-dimensional information in real-time, a triangulation method with the luminescent spot of the SEM's electron beam is being investigated. Finally, the strategies of micro force sensing and control methods required for handling techniques with two robots are discussed.},
	keywords={Manipulators; Scanning electron microscopy; Microscopes; Microactuators; Piezoelectric devices; Force control; Robotic assembly; Electron beams; Computer control},
	isbn={0277-786X},
	url={http://dx.doi.org/10.1117/12.403693}
}
@inproceedings{RefWorks:55,
	author={J. Seyfried and R. EstaÃ±a and F. Schmoeckel and M. Thiel and A. BÃ¼rkle and H. Woern},
	editor={Giovanni Muscato and Domenico Longo},
	year={2003},
	title={Controlling cm$^3$ Sized Autonomous Micro Robots Operating in the Micro and Nano World},
	booktitle={Proc. 6th Int. Conf. Climbing and Walking Robots and their Supporting Technologies (CLAWAR 2003)},
	pages={627-634},
	note={annote: Global positioning with MoirÃ© patterns}
}
@inproceedings{RefWorks:208,
	author={J. Seyfried and S. Fatikow},
	year={1998},
	title={Microrobot-based microassembly station and its control using a graphical user interface},
	booktitle={Proceedings of Symposium on Robot Control, 3-5 Sept. 1997},
	series={Robot Control 1997 (SYROCO'97)},
	publisher={Elsevier},
	address={Nantes, France},
	organization={Inst. for Real-Time Comput. Syst. & Robotics, Karlsruhe Univ., Germany},
	volume={2},
	pages={781-786},
	note={M1: Copyright 1999, IEE},
	abstract={In the fields of biology, microelectronics and microsystem technology many operations are today performed by hand which might also be done by micromanipulation robots. Several prototypes of such robots have already been built and tested, but in the field of control systems and user interfaces of such micromanipulation systems, there is still much work to be done. Different applications demand different levels of control and planning: easier, single tasks may be performed by teleoperation, while others require a programmed motion sequence or even task planning to accomplish a complex assembly task a with minimum of human interaction. This paper presents a micromanipulation system consisting of a microassembly robot working under a light-optical microscope, a CCD camera and an XY-stage. Then, the software infrastructure for the microrobot control system is presented and the underlying hardware system is described. It also shows a user interface based on this structures, a semi-automated teleoperation system. The user interface presented here uses the live image of the CCD camera to perform either open or closed loop control of the robot's position. All parameters of the microscope and XY-stage can be controlled with dialog windows. The software infrastructure allows also the development of task planning algorithms by providing an intermediate layer to control the robot},
	keywords={assembly planning; graphical user interfaces; manipulator dynamics; path planning},
	isbn={0 08 043026 0}
}
@inproceedings{RefWorks:186,
	author={J. Seyfried and F. Schmoeckel and A. Burkle and H. Worn},
	year={2001},
	title={Flexible mobile microrobots for various remote-controlled micro-manipulating tasks},
	booktitle={First IFAC-Conference on Telematics Applications in Automation and Robotics TA 2001, 24-26 July 2001},
	series={Telematics Applications in Automation and Robotics 2001 (TA 2001). Proceedings volume from the IFAC Conference},
	publisher={Elsevier Sci},
	address={Weingarten, Germany},
	organization={Inst. for Process Control & Robotics (IPR), Karlsruhe Univ., Germany},
	pages={327-331},
	note={M1: Copyright 2003, IEE},
	abstract={The handling of objects smaller than 1 mm is a great challenge for the robotics research community. Applications are the handling of biological cells, teleoperation under vacuum conditions (e.g. inside a scanning electron microscope - SEM) or the manufacture of prototypes of microsystems. In this paper, some aspects of the control of small mobile microrobots by teleoperation are addressed. The employed 6D-mouse proves satisfactory as an intuitive user interface. A distributed control and planning architecture is presented as well as a closed-loop control approach basing on a sensor system that mainly consists of a standard SEM},
	keywords={assembling; flexible manipulators; microrobots; mobile robots; telerobotics},
	isbn={0 08 043856 3}
}

@article{RefWorks:237,
	author={J. H. Shim and H. S. Cho},
	year={1999},
	title={A new macro/micro robotic probing system for the in-circuit test of PCBs},
	journal={Mechatronics},
	volume={9},
	number={6},
	pages={589-613},
	note={M1: Copyright 1999, IEE},
	abstract={Presents a macro/micro robotic probing system developed for the in-circuit test of printed circuit boards (PCBs). Commercially available robotic probing devices are likely to generate excessive contact force due to their uncontrollability, as a rigid probe makes a contact with a less rigid, plastically deformable solder joint at high speed. Since the conventional probing mechanism has only passive compliance, it cannot effectively control such a large contact force. This uncontrollable excessive contact force often makes some defects on the surface of the solder joint and oscillatory motions of the probe, resulting in unreliable test data. In addition, contact with a steep surface of the solder joint makes slip motion of the probe tip onto the surface. To overcome these problems, we propose a serially connected macro and micro robotic probing device equipped with active compliance capability and sensing ability of surface conditions of the solder joint in real-time. The paper describes its design characteristics and control scheme of the newly proposed device. The effectiveness of the proposed probing system is verified through a series of experiments},
	keywords={force control; industrial manipulators; mechatronics; micromanipulators; printed circuit testing},
	isbn={0957-4158},
	url={http://dx.doi.org/10.1016/S0957-4158(99)00016-1}
}
@article{RefWorks:140,
	author={Ilan Shimshoni and Aviva Sasporta},
	year={2006/2/1},
	title={Object recognition using point uncertainty regions as pose uncertainty regions},
	journal={Image and Vision Computing},
	volume={24},
	number={2},
	pages={192-201},
	keywords={Object recognition; Uncertainty regions; Pose estimation}
}
@article{RefWorks:172,
	author={J. Speich and M. Goldfarb},
	year={2000},
	title={Compliant-mechanism-based three degree-of-freedom manipulator for small-scale manipulation},
	journal={Robotica},
	volume={18},
	number={1},
	pages={95-104}
}
@misc{RefWorks:52,
  author = 	 {SSSA},
  year = 	 {2005},
  title = 	 {Scuola Superiore Sant'Anna, Center of Research In Microengineering, Sant'Anna},
  note = 	 {howpublished: web page; note: \url{http://www-crim.sssup.it/}}
}
@inproceedings{RefWorks:148,
	author={Jason M. Stevens and Gregory D. Buckner},
	year={2003},
	title={Intelligent control of a micro-manipulator actuated with shape memory alloy tendons},
	booktitle={PROCEEDINGS OF SPIE SPIE - The International Society for Optical Engineering: Smart Structures and Materials 2003 Modeling, Signal Processing, and Control, Mar 3-6 2003},
	series={Proceedings of SPIE - The International Society for Optical Engineering},
	publisher={The International Society for Optical Engineering},
	address={San Diego, CA, United States},
	organization={Department of Mechanical Engineering, North Carolina State University, Raleigh, NC 27695-7910, United States},
	volume={5049},
	pages={56-64},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={During the past 20 years, tremendous advancements have been made in the fields of minimally invasive surgery (MIS) and minimally invasive robotic assisted (MIRA) surgery. The technologies associated with these advancements have their own drawbacks, however. The surgical robots used in MIRA procedures are large, costly, and do not offer the miniaturized articulation necessary to facilitate additional advancements. This research tests the hypothesis that miniature actuation can overcome some of the limitations of current robotic systems by demonstrating accurate, repeatable control of a small end-effector. A simple two-link manipulator is designed and fabricated, using antagonistic shape memory alloy (SMA) tendons as actuators, to simulate motions of a surgical end-effector. Artificial neural networks (ANNs) are used in conjunction with real-time visual feedback to "learn" the inverse system dynamics and control the manipulator endpoint trajectory. Experimental results are presented for indirect, on-line learning and control. Manipulator tip trajectories are shown to be accurate and repeatable to within 0.5 mm. These results confirm that SMAs can be effective actuators for miniature surgical robotic systems, and that intelligent control can be used to accurately control the trajectory of these systems.},
	keywords={Microactuators; Shape memory effect; Intelligent control; Feedback control; Micromanipulators; Neural networks; Robotics; End effectors; Fabrication; Real time systems; Diseases; Computer simulation},
	isbn={0277-786X},
	url={http://dx.doi.org/10.1117/12.484045}
}
@article{RefWorks:68,
	author={Erich Stoll},
	year={1986},
	title={IMAGE-PROCESSING AND PATTERN RECOGNITION OF SCANNING TUNNELING MICROSCOPE DATA},
	pages={340-344}
}
@inproceedings{RefWorks:143,
	author={F. Tagliareni and M. Nierlich and O. Steinmetz and T. Velten and J. Brufau and J. Lopez-Sanchez and M. Puig-Vidal and J. Samitier},
	year={2005},
	title={Manipulating biological cells with a micro-robot cluster},
	booktitle={2005 IEEE/RSJ International Conference on Intelligent Robots and Systems, 2-6 Aug. 2005},
	series={2005 IEEE/RSJ International Conference on Intelligent Robots and Systems},
	publisher={IEEE},
	address={Edmonton, Alta., Canada},
	organization={IBMT, Fraunhofer Inst. for Biomed. Eng., St. Ingbert, Germany},
	pages={1414-1419},
	note={M1: Copyright 2006, IEE},
	abstract={Micromanipulation is an appreciated and powerful method to modify biological material. By injecting DNA or specific liquids into a biological cell, designated reactions or behaviors can be provoked. The aim of this paper is to describe three components of a fully automated opticonsisting of a micro-robot cluster with an integrated micro-fluidic SyringeChip. The electronic system, microfluidic Syringe-Chip, and infrared communication are the components that have been built and are ready for integration into a MiCRoN robot. The concept of a biological cell manipulation with the aid of the integrated sub-systems is being presented here. The first injection experiment is done after completion of the MiCRoN robot-cluster},
	keywords={biomedical electronics; cellular biophysics; DNA; microfluidics; micromanipulators; microrobots; optical communication},
	isbn={0 7803 8912 3}
}
@inproceedings{RefWorks:150,
	author={K. Takahashi and Y. An and S. Saito and T. Onzawatadao},
	year={2003},
	title={Introduction of micro-manipulation by adhesional force and dielectric force},
	booktitle={2003 Nanotechnology Conference and Trade Show - Nanotech 2003, Feb 23-27 2003},
	series={2003 Nanotechnology Conference and Trade Show - Nanotech 2003},
	publisher={Computational Publications, Cambridge, MA 02139, United States},
	address={San Francisco, CA, United States},
	organization={International Development Eng, Tokyo Institute of Technology, Ookayama, Meguro-ku, Tokyo 152-8552, Japan},
	volume={1},
	pages={518-521},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={An adhered particle can be detached by dielectric force. The voltage required for the detachment is theoretically evaluated. Calculated results show fairly good agreement with experimental results. A Diagram for micro-manipulation is presented. Because the adhesion force can be evaluated by Johnson- Kendall- Roberts (JKR) approximation, the possibility and the limitation of a micro-manipulation using both the adhesion force and the dielectric force can be expressed in a diagram.},
	keywords={Adhesion; Dielectric materials; Assembly; Boundary element method; Electric potential; Manipulators; Vacuum; Electric discharges; Electron tunneling},
	isbn={0972842209}
}
@inproceedings{RefWorks:128,
	author={Keita Takahashi and Akira Kubota and Takeshi Naemura},
	year={2004},
	title={A focus measure for light field rendering},
	booktitle={2004 International Conference on Image Processing, ICIP 2004, Oct 18-21 2004},
	series={Proceedings - International Conference on Image Processing, ICIP},
	publisher={Institute of Electrical and Electronics Engineers Computer Society, Piscataway, NJ 08855-1331, United States},
	address={Singapore},
	organization={University of Tokyo, Bunkyo-ku, Tokyo 113-8656, Japan},
	volume={4},
	pages={2475-2478},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={Light field rendering is a fundamental method for synthesizing free-viewpoint images from a set of multi-viewpoint images. In the simplest case, the scene structure is approximated by a simple plane: a focal plane. This approximation leads to focus-like effects on synthetic images where the focused depth is determined by the focal plane. A serious problem is that the range of the focused depth is too small in most practical cases. In this paper, we propose a focus measure that is specialized for synthetic images by light field rendering. When a set of differently-focused images is generated at a given viewpoint, the proposed focus measure enables us to obtain a depth map and an all in-focus image. Our approach has some remarkable differences from other related techniques, such as depth-from-stereo and depth-from-focus methods. Experimental results show that the proposed method effectively enhances PSNR of the final synthetic images. &copy;2004 IEEE.},
	keywords={Image analysis; Frequencies; Cameras; Optical resolving power; Signal to noise ratio; Algorithms; Approximation theory; Computational geometry},
	isbn={1522-4880}
}
@article{RefWorks:159,
	author={Russell H. Taylor and Ralph L. Hollis and Mark A. Lavin},
	year={1985},
	title={PRECISE MANIPULATION WITH ENDPOINT SENSING},
	journal={IBM Journal of Research and Development},
	volume={29},
	number={4},
	pages={363-376},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={This paper describes recent work on manipulation strategies that rely on 'coarse-fine' robot hardware and direct sensing of part-workpiece relationships. The experiments reported use an extremely precise, high-bandwidth planar 'wrist' and an industrial vision system to perform accurate alignment of small parts. The system architecture, experimental hardware, and programming methods employed are all discussed.},
	keywords={MATERIALS HANDLING -- Manipulators; ROBOTICS},
	isbn={0018-8646}
}
@inproceedings{RefWorks:29,
	author={A. Thayananthan and B. Stenger and P. H. S. Torr and R. Cipolla},
	year={2003},
	title={Shape context and chamfer matching in cluttered scenes},
	booktitle={2003 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, Jun 18-20 2003},
	series={Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
	publisher={Institute of Electrical and Electronics Engineers Computer Society},
	address={Madison, WI, United States},
	organization={University of Cambridge, Department of Engineering, Cambridge CB2 1PZ, United Kingdom},
	volume={1},
	pages={127-133},
	note={Compilation and indexing terms, Copyright 2005 Elsevier Engineering Information, Inc.},
	abstract={This paper compares two methods for object localization from contours: shape context and chamfer matching of templates. In the light of our experiments, we suggest improvements to the shape context: Shape contexts are used to find corresponding features between model and image. In real images it is shown that the shape context is highly influenced by clutter, furthermore even when the object is correctly localized, the feature correspondence may be poor. We show that the robustness of shape matching can be increased by including a figural continuity constraint. The combined shape and continuity cost is minimized using the Viterbi algorithm on features, resulting in improved localization and correspondence. Our algorithm can be generally applied to any feature based shape matching method. Chamfer matching correlates model templates with the distance transform of the edge image. This can be done efficiently using a coarse-to-fine search over the transformation parameters. The method is robust in clutter, however multiple templates are needed to handle scale, rotation and shape variation. We compare both methods for locating hand shapes in cluttered images, and applied to word recognition in EZ-Gimpy images.},
	keywords={Algorithms; Dynamic programming; Edge detection; Functions; Three dimensional; Object recognition},
	isbn={1063-6919}
}
@article{RefWorks:11,
	author={J. Vitria and J. Llacer},
	year={1996},
	month={12/30},
	title={Reconstructing 3D light microscopic images using the EM algorithm},
	journal={Pattern Recognition Letters},
	volume={17},
	number={14},
	pages={1491-1498},
	note={M1: Copyright 1997, IEE},
	abstract={An iterative method to recover perfectly focused images from a set of light microscopic images is proposed. The method is based on the EM algorithm, and it assumes a prior knowledge about the point spread function of the optical system, as well as about the optical parameter settings of the acquisition system. The method is applied to the visualization of integrated circuit samples through an optical microscope and to the recovery of their depth information},
	keywords={automatic optical inspection; image reconstruction; integrated circuit manufacture; iterative methods; optical microscopes; optical transfer function; stereo image processing},
	isbn={0167-8655},
	url={http://dx.doi.org/10.1016/S0167-8655(96)00104-3}
}
@inproceedings{RefWorks:116,
	author={Chuan-Yang Wang and Han-Xiong Huang and Zhi-Min Xie},
	year={2003},
	title={Application of image processing technique in analyzing microstructure of nanocomposites},
	booktitle={61st Annual Technical Conference ANTEC 2003, May 4-8 2003},
	series={Annual Technical Conference - ANTEC, Conference Proceedings},
	publisher={Society of Plastics Engineers},
	address={Nashville, TN, United States},
	organization={Coll. of Indust. Equip./Contr. Eng., South China University of Technology, Guangzhou, China},
	volume={2},
	pages={2219-2222},
	note={Compilation and indexing terms, Copyright 2005 Elsevier Engineering Information, Inc.},
	abstract={An image processing program suitable for analyzing the microstructure of polymer/organic-montmorillonite (org-MMT) nanocomposites was developed based on the MATLAB software. The TEM photomicrographs of polypropylene/org-MMT were analyzed using the program. It has been revealed that the shape and size of the MMT in nanocomposites can be determined effectively and promptly by using the image processing program.},
	keywords={Microstructure; Organic polymers; Image processing; Computer software; Transmission electron microscopy; Nanostructured materials}
}
@article{RefWorks:173,
	author={W. Wang and T. He},
	year={1996},
	title={A high precision micropositioner with five degrees of freedom based on an electromagnetic driving principle},
	journal={Review of Scientific Instruments},
	volume={67},
	number={1},
	pages={312-317}
}
@article{RefWorks:163,
	author={Masao Washizu},
	year={1990},
	title={Electrostatic manipulation of biological objects},
	journal={Journal of Electrostatics},
	volume={25},
	number={1},
	pages={109-123},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={A novel device called a 'Fluid Integrated Circuit' (FIC) has been developed for the electrostatic manipulation of biological objects. The FIC is made with photolithographic micro-machining techniques used for the production of IC and LSI, by which all components for the manipulations are miniaturized and integrated on one substrate. The advantage of the FIC concept is twofold: firstly, channels, electrodes etc. can be made small to allow the handling of micrometer scale objects, and secondly, the electrodes and insulating walls of arbitrary shape can be made so that a flexible field design is possible. Dielectrophoretic force is used for the actuation cells and biological molecules.},
	keywords={Biological Materials; Materials Handling - Manipulators; Fluidic Devices; Electrophoresis; Electrostatic Devices},
	isbn={0304-3886},
	url={http://dx.doi.org/10.1016/0304-3886(90)90040-3}
}
@article{RefWorks:142,
	author={Masahiro Watanabe and Shree K. Nayar},
	year={1998},
	title={Rational filters for passive depth from defocus},
	journal={International Journal of Computer Vision},
	volume={27},
	number={3},
	pages={203-225},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={A fundamental problem in depth from defocus is the measurement of relative defocus between images. The performance of previously proposed focus operators are inevitably sensitive to the frequency spectra of local scene textures. As a result, focus operators such as the Laplacian of Gaussian result in poor depth estimates. An alternative is to use large filter banks that densely sample the frequency space. Though this approach can result in better depth accuracy, it sacrifices the computational efficiency that depth from defocus offers over stereo and structure from motion. We propose a class of broadband operators that, when used together, provide invariance to scene texture and produce accurate and dense depth maps. Since the operators are broadband, a small number of them are sufficient for depth estimation of scenes with complex textural properties. In addition, a depth confidence measure is derived that can be computed from the outputs of the operators. This confidence measure permits further refinement of computed depth maps. Experiments are conducted on both synthetic and real scenes to evaluate the performance of the proposed operators. The depth detection gain error is less than 1%, irrespective of texture frequency. Depth accuracy is found to be 0.5 approx. 1.2% of the distance of the object from the imaging optics.},
	keywords={Computer vision; Digital filters; Depth perception; Mathematical operators; Computational methods; Textures; Error detection},
	isbn={0920-5691},
	url={http://dx.doi.org/10.1023/A:1007905828438}
}
@inproceedings{RefWorks:43,
	author={Jan Wedekind},
	year={2004},
	month=sep,
	title={Focus set based reconstruction of micro-objects},
	booktitle={International IEEE Conference on Mechatronics \& Robotics (MechRob'04)},
	publisher={IEEE Industrial Electronics Society; APS - European Centre for Mechatronics},
	pages={754-756},
	annote={\url{http://www.shu.ac.uk/mmvl/research/MechRob04-paper.pdf}}
}
@misc{RefWorks:48,
  author = 	 {Eric W. Weisstein},
  year = 	 {1999},
  title = 	 {Homogeneous Coordinates},
  note = 	 {howpublished: From Mathworld -- A Wolfram Web Resource; note: \url{http://mathworld.wolfram.com/HomogeneousCoordinates.html}}
}
@inproceedings{RefWorks:10,
	author={Wernhuar Tarng},
	year={1995},
	title={Virtual reality-a tour of microscopic world},
	booktitle={Proceedings of Second Asian Conference on Computer Vision. ACCV '95, 5-8 Dec. 1995},
	series={ACCV '95. Second Asian Conference on Computer Vision. Proceedings},
	publisher={Nanyang Technol. Univ},
	address={Singapore},
	organization={Dept. of Math. & Sci. Educ., Nat. Hsinchu Teachers Coll., Taiwan},
	volume={2},
	pages={676-678},
	note={M1: Copyright 1996, IEE},
	abstract={A virtual reality system creates an interactive environment to simulate our real world where one can perceive and react to the vivid environmental changes through 3-D visualization, sound effects and body control. In this paper, a virtual reality system for biological and educational applications is developed to provide a tour of microscopic world. The 3-D data structure is obtained by creating a phantom to simulate a cubic specimen containing tissue of different size and density. One can "travel" in the virtual world by wearing a pair of liquid crystal (LC) glasses, earphone, and holding a 3-D mouse. High resolution biological image data can also be obtained by X-ray microtomography or confocal microscopy to provide the observers with more realistic perception and better understanding in biological micro structure},
	keywords={biology computing; computer aided instruction; virtual reality},
	isbn={981 00 7177 9}
}
@inproceedings{RefWorks:199,
	author={H. Woern and J. Seyfried and St Fahlbusch and A. Buerkle and F. Schmoeckel},
	year={2000},
	title={Flexible microrobots for micro assembly tasks},
	booktitle={Proceedings of the 2000 International Symposium on Micromechatronics and Human Science, Oct 22-25 2000},
	publisher={Institute of Electrical and Electronics Engineers Inc},
	address={United States},
	organization={Inst. for Process Control Robotics, Universitat Karlsruhe (TH), D-76128 Karlsruhe, Germany},
	pages={135-143},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={A wide range of microcomponents can today be produced using various microfabrication techniques. The assembly of complex microsystems consisting of several single components (i. e. hybrid microsystems) is, however, a difficult task that is seen to be a real challenge for the robotic research community. It is necessary to conceive flexible, highly precise and fast microassembly methods. In this paper, the development of a microrobot-based microassembly station is presented. Mobile piezoelectric microrobots with dimensions of some cm0RW1S34RfeSDcfkexd09rT331RW1S34RfeSDcfkexd09rT3 and with at least 5 DOF can perform various manipulations either under a light microscope or inside the vacuum chamber of a scanning electron microscope. The components of the station developed and its control system are described. The latter comprises a vision-based sensor system for automatic robot control and a user interfaces for semi-automated control and teleoperation. First results of the SEM-based micro assembly, handling of biological cells and integration of force micro-sensors into our microrobots are presented as well.},
	keywords={Robotic assembly; Mobile robots; Microelectromechanical devices; Microelectronic processing; Microsensors; User interfaces; Motion control; Remote control; Scanning electron microscopy; Object recognition; Manipulators; Degrees of freedom (mechanics); Grippers},
	url={http://dx.doi.org/10.1109/MHS.2000.903303}
}
@inproceedings{RefWorks:20,
	author={H. Worn and R. Munassypov and S. Fatikow},
	year={1998},
	title={Actuation principle and motion control of a three-leg piezoelectric micromanipulation robot},
	booktitle={Proceedings of Actuator 98 6th International Conference on New Actuators, 17-19 June 1998},
	series={ACTUATOR 98. 6th International Conference on New Actuators with Accompanying Exhibition. Conference Proceedings},
	publisher={Messe Bremen GmbH},
	address={Bremen, Germany},
	organization={Inst. of Process Control & Robotics, Karlsruhe Univ., Germany;},
	pages={203-206},
	note={M1: Copyright 1999, IEE},
	abstract={The microrobots, capable of performing microscopic tasks, have become a subject of great interest all over the world. To provide a microrobot with both the transportation and micromanipulation capabilities, various designs of piezoelectric actuators can be used, which can perform very fine positioning in the nm-range. Other qualities of piezoelectric actuators are very fast time of reaction and high forces. This paper is dealing with the motion control of a microrobot, which can be used in different micromanipulation tasks. The robot has three triangularly arranged piezoelectric legs having a tube shape. The paper presents the actuation principle and the motion control approach of the microrobot. The control approach is based on the geometric description of the robot and aims at the following the optimal motion trajectory to minimize the time of movement and to keep the robot endeffector under microscope supervision},
	keywords={legged locomotion; microactuators; micromanipulators; micropositioning; microrobots; motion control; piezoelectric actuators},
	isbn={3 933339 00 6}
}
@article{RefWorks:14,
	author={H. Worn and F. Schmoeckel and A. Buerkle and J. Samitier and M. Puig-Vidal and S. Johansson and U. Simu and J. -U Meyer and M. Biehl},
	year={2001},
	title={From decimeter- to centimeter-sized mobile microrobots the development of the MINIMAN system},
	journal={Proceedings of the SPIE - The International Society for Optical Engineering},
	volume={4568},
	pages={175-186},
	note={M1: Copyright 2002, IEE},
	abstract={Based on small mobile robots the presented MINIMAN system provides a platform for micro-manipulation tasks in very different kinds of applications. Three applications demonstrate the capabilities of the system. Both the high precision assembly of an optical system consisting of three millimeter-sized parts and the positioning of single 20 mu m-cells under a light microscope as well as the handling of tiny samples inside the scanning electron microscope are done by the same kind of robot. For different tasks, the robot is equipped with appropriate tools such as micropipettes or grippers with force and tactile sensors. For the extension to a multi-robot system, it is necessary to further reduce the size of the robots. For the above mentioned robot prototypes a slip-stick driving principle is employed. While this design proves to work very well for the described decimeter-sized robots, it is not suitable for further miniaturized robots because of their reduced inertia. Therefore, the developed centimeter-sized robot is driven by multilayered piezoactuators performing defined steps without a slipping phase. To reduce the number of connecting wires the microrobot has integrated circuits on board. They include high voltage drivers and a serial communication interface for a minimized number of wires},
	keywords={materials handling; micromanipulators; micropositioning; mobile robots},
	isbn={0277-786X},
	url={http://dx.doi.org/10.1117/12.444124}
}
@inproceedings{RefWorks:124,
	author={Arimitsu Yokota and Takashi Yoshida and Hideki Kashiyama and Takayuki Hamamoto},
	year={2004},
	title={High speed depth estimation by smart image sensor system},
	booktitle={IEEE International Symposium on Communications and Information Technologies: Smart Info-Media Systems, ISCIT 2004, Oct 26-29 2004},
	series={IEEE International Symposium on Communications and Information Technologies: ISCIT 2004},
	publisher={Institute of Electrical and Electronics Engineers Inc., New York, NY 10016-5997, United States},
	address={Sapporo, Japan},
	organization={Department of Electrical Engineering, Faculty of Engineering, Tokyo University of Science, Tokyo 162-8601, Japan},
	volume={2},
	pages={963-968},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={This paper proposes a novel smart image sensor system for depth estimation by searching for the most in-focus position over multi-focus images (a sequence of images taken by changing a camera parameter "focus" little by little). On the smart sensor, in-focus position is detected pixel by pixel and all-in-focus image can be output in real time. A prototype sensor of 64&times;64 pixels has been designed and fabricated. It can be expected that the smart imaging system is able to generate depth map and all-in-focus images at video rate (30 Hz) or faster because the proposed sensor can operate at more than 1500 fps. This paper also proposes the method of removal and interpolation for depth map to improve accuracy of the depth map. Some experimental results are shown to verify the proposed method of the in-focus detection and the interpolation. And we show design of the proposed sensor.},
	keywords={Image sensors; Real time systems; Imaging systems; Field programmable gate arrays; Synchronization; Random processes; Digital circuits; Interpolation; Personal computers; Algorithms},
	isbn={0780385934}
}
@article{RefWorks:242,
	author={Yongjun Lai and M. Kujath and T. Hubbard},
	year={2005},
	title={Modal Simulation and testing of a micro-manipulator},
	journal={Transactions of the ASME.Journal of Dynamic Systems, Measurement and Control},
	volume={127},
	number={3},
	pages={515-519},
	note={M1: Copyright 2005, IEE},
	abstract={A micro-machined manipulator with three kinematic degrees-of-freedom (DOF): x, y, and &phi; is presented. The manipulator is driven by three thermal actuators. A six DOF discrete spring-mass model of the compliant mechanism is developed which manifests the dynamic properties of the device. Numerical simulations are compared with experimental results},
	keywords={actuators; design engineering; manipulator kinematics; mechanical testing; micromanipulators; numerical analysis},
	isbn={0022-0434},
	url={http://dx.doi.org/10.1115/1.1978907}
}
@inproceedings{RefWorks:119,
	author={Thierry Zamofing and Heinz Hugli},
	year={2004},
	title={Applied multifocus 3D microscopy},
	booktitle={Two - and Three-Dimensional Vision Systems for Inspection, Control, and Metrology, Oct 29-30 2003},
	series={Proceedings of SPIE - The International Society for Optical Engineering},
	publisher={International Society for Optical Engineering, Bellingham, WA 98227-0010, United States},
	address={Providence, RI., United States},
	organization={Institute of Microtechnology, University of Neuchatel, CH-2000 Neuchatel, Switzerland},
	volume={5265},
	pages={134-144},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={The depth from focus measurement principle relies on the detection of the optimal focusing distance for measuring the depth map of an object and finding its 3D shape. The principle is most effective at microscopic ranges where it is usually found implemented around a z-controlled microscope and sometimes named multifocus 3D microscopy. As such, the method competes with many other 3D measurement methods showing both advantages and disadvantages. Multifocus 3D microscopy is presented and compared to chromatic aberation, confocal microscopy, white light interferometry. Then, this paper discusses two applications of multifocus 3D microscopy for measuring wood respectively metallic parts in the sub-millimeter range. The first application aims at measuring the topography of wood samples for surface quality control. The wood samples surface topography is evaluated with data obtained from both confocal microscopy and multifocus 3D microscopy. The profiles and a standard roughness factor are compared. The second application concerns the measurement of burrs on metallic parts. Possibilities and limits of multifocus 3D microscopy are presented and discussed.},
	keywords={Microscopic examination; Surface topography; Depth perception; Quality control; Intelligent control; Aberrations; Automation; Image analysis},
	isbn={0277-786X},
	url={http://dx.doi.org/10.1117/12.518827}
}
@inproceedings{RefWorks:129,
	author={Thierry Zamofing and Heinz Hugli},
	year={2004},
	title={Multiresolution reliability scheme for range image filtering},
	booktitle={Two- and Three-Dimensional Vision Systems for Inspection, Control, and Metrology II, Oct 26-27 2004},
	series={Proceedings of SPIE - The International Society for Optical Engineering},
	publisher={International Society for Optical Engineering, Bellingham, WA 98227-0010, United States},
	address={Philadelphia, PA, United States},
	organization={University of Neuchatel, Institute of Microtechnology, 2000 Neuchatel, Switzerland},
	volume={5606},
	pages={98-105},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={A large number of 3D cameras suffer from so-called holes in the data, i.e. the measurement lattice is affected by invalid measurements and the range image has undefined values. Conventional image filters used for removing the holes perform not well in presence of holes with large varying hole sizes. The novel hole-filling method presented in this paper operates on reliability attributed range images featuring unwanted holes with wide varying sizes. The method operates according to a multi resolution scheme where the image resolution is decreased at the same time as the range reliability is successively increased until sufficient confidence is reached. It builds on three main components. First, the described process performs a weighted local neighbourhood filter where the contribution of each pixel stands for its reliability. Second, the filtering combines filters with different kernel sizes and implements therefore the multi resolution schema. Third, the processing requires a complete travel from high resolution down to the resolution of satisfactory confidence and back again to the highest resolution. The algorithm for the described method was implemented in a efficient way and was widely applied in the hole-filling of range images from a depth from focus process where reliability is obtainable non-linearly from the local sharpness measurement. The method is valid in a very general way for all range imagers providing reliability information. It seems therefore well suited to depth cameras like time-of-flight, stereo and other similar rangers.},
	keywords={Image analysis; Optical filters; Reliability; Cameras; Interpolation; Algorithms; Estimation; Computational methods},
	isbn={0277-786X},
	url={http://dx.doi.org/10.1117/12.580476}
}
@inproceedings{RefWorks:25,
	author={Hao Zhang and Jitendra Malik},
	year=2003,
	title={Learning a discriminative classifier using shape context distances},
	booktitle={2003 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, Jun 18-20 2003},
	series={Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
	publisher={Institute of Electrical and Electronics Engineers Computer Society},
	address={Madison, WI, United States},
	organization={Computer Science Division, Univ. of California, at Berkeley, Berkeley, CA 94720-1776, United States},
	volume={1},
	pages={242-247},
	note={Compilation and indexing terms, Copyright 2005 Elsevier Engineering Information, Inc.},
	abstract={For purpose of object recognition, we learn one discriminative classifier based on one prototype, using shape context distances as the feature vector. From multiple prototypes, the outputs of the classifiers are combined using the method called "error correcting output codes". The overall classifier is tested on benchmark dataset and is shown to outperform existing methods with far fewer prototypes.},
	keywords={Learning systems; Feature extraction; Vectors; Error correction; Benchmarking; Principal component analysis; Object recognition},
	isbn={1063-6919}
}
@article{RefWorks:244,
	author={W. J. Zhang and J. Zou and L. G. Watson and W. Zhao and G. H. Zong and S. S. Bi},
	year={2002},
	month=feb,
	title={The constant-Jacobian method for kinematics of a three-DOF planar micro-motion stage},
	journal={Journal of Robotic Systems},
	volume={19},
	number={2},
	pages={63-72},
	note={M1: Copyright 2002, IEE},
	abstract={The paper concerns the development of a class of devices that generate end-effector motion in the range of less than 100 &mu;m and with sub-nanometer resolution; in particular, a parallel manipulator configuration that generates a planar x-y-&gamma; motion is considered. The parallel manipulator is implemented as a compliant mechanism. A problem with parallel manipulators is that the forward kinematics is usually too complex, which can hinder the implementation of advanced control algorithms. The contribution of the paper is that a simple method, called the constant-Jacobian (CJ) method, is developed based on the pseudo-rigid body approach to compliant mechanisms. An experiment validates the CJ method},
	keywords={Jacobian matrices; manipulator kinematics; micromanipulators},
	isbn={0741-2223},
	url={http://dx.doi.org/10.1002/rob.1070}
}
@article{RefWorks:250,
	author={Xiaopeng Zhao and Harry Dankowicz and Chevva K. Reddy and Ali H. Nayfeh},
	year={2004},
	title={Modeling and simulation methodology for impact microactuators},
	journal={Journal of Micromechanics and Microengineering},
	volume={14},
	number={6},
	pages={775-784},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={Micro or nano distance manipulations are of prime importance in the MEMS industry. Microdevices are ideal for micropositioning systems due to their small size. Microactuators used to produce small displacements would need large actuation forces and a long driving distance. This would require large voltages to produce the desired forces. Actuators based on impulsive forces provide a solution to this problem. Many impact microactuators have been designed and fabricated in the past decade. Impacts are a source of nonlinearity and a careful study of the dynamics is essential in order to ensure consistent performance of the device. Currently, the state of the art lacks a robust design tool for such devices. The primary goal of this paper is to present a comprehensive modeling and simulation methodology for impact microactuators. The present study will aid in a more robust and consistent impact microactuator design.},
	keywords={Microactuators; Microelectromechanical devices; Interferometers; Electric converters; Electric motors; Van der Waals forces; Electrostatics; Friction; Optimization; Perturbation techniques; Mathematical models; Computer simulation},
	isbn={0960-1317},
	url={http://dx.doi.org/10.1088/0960-1317/14/6/003}
}

@article{RefWorks:253,
	author={Kristian Molhave and Ole Hansen},
	year={2005},
	title={Electro-thermally actuated microgrippers with integrated force-feedback},
	journal={Journal of Micromechanics and Microengineering},
	volume={15},
	number={6},
	pages={1265-1270},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={Microfabricated grippers and tweezers are promising tools for manipulation of micro- and nanoscale objects. As with ordinary macroscale grippers, the ability to sense the forces involved in grabbing would be advantageous for controlling the operation as well as for measuring the mechanical properties of the grabbed object. A simple design is presented for an electro-thermally actuated microfabricated gripper capable of providing a piezoresistive read-out of the gripper deflection, which can be used to measure the forces applied to the grabbed object. Measurements of actuation of test devices are presented and found to be in reasonable agreement with expected values. Finally, piezoresistive measurements of the gripper deflection are demonstrated. &copy; 2005 IOP Publishing Ltd.},
	keywords={Grippers; Nanotechnology; Carbon nanotubes; Actuators; Electrostatics; Atomic force microscopy; Optimization; Algorithms},
	isbn={0960-1317},
	url={http://dx.doi.org/10.1088/0960-1317/15/6/018}
}

@inproceedings{RefWorks:255,
	author={M. Nakajima and F. Arai and L. Dong and M. Nagai and T. Fukuda},
	year={2004},
	title={Hybrid nanorobotic manipulation system inside scanning electron microscope and transmission electron microscope},
	booktitle={2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 28 Sept.-2 Oct. 2004},
	series={2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566)},
	publisher={IEEE},
	address={Sendai, Japan},
	organization={Dept. of Micro-Nano Syst. Eng., Nagoya Univ., Japan},
	volume={1},
	pages={589-94},
	note={M1: Copyright 2005, IEE},
	abstract={A hybrid nanorobotic manipulation system, which is integrated with a nanorobotic manipulator inside a transmission electron microscope (TEM) and nanorobotic manipulators inside a scanning electron microscope (SEM), is presented. The new type of nanomanipulation system has high enough resolution to identify nano-scale objects due to the adoption of a TEM, and efficient and rapid nanomanipulations are realized with wide enough working space of the SEM nanomanipulators. The TEM nanomanipulator has been constructed with 4 multi-layer piezoelectric actuators for driving in 3 translational degrees of freedom (DOFs) and a passively driven 3-DOF sample stage through SEM nanorobotic manipulators to perform relatively complex manipulations whereas to keep compact volume to be installed inside the narrow vacuum chamber of a TEM. To show the effectiveness of the system, the interlayer resistance of a destructively fabricated multi-walled carbon nanotube has been measured inside a SEM whereas the telescoping structure formed by pulling out inner layers from outer layers of the tube is observed inside a TEM},
	keywords={carbon nanotubes; micromanipulators; piezoelectric actuators; scanning electron microscopy; transmission electron microscopy},
	isbn={0 7803 8463 6}
}

@article{RefWorks:256,
	author={M. van Heel and E. V. Orlova and G. Harauz and H. Stark and P. Dube and F. Zemlin and M. Schatz},
	year={1997},
	title={Angular Reconstitution in Three-Dimensional Electron Microscopy: Historical and Theoretical Aspects0RW1S34RfeSDcfkexd09rT0  1RW1S34RfeSDcfkexd09rT0},
	journal={Scanning Microscopy},
	volume={11},
	pages={195-210},
	note={annote: \url{http://www.aber.ac.uk/~ecmwww/journal/smi/pdf/smi97-15.pdf}}
}

@article{RefWorks:257,
	author={M. Schatz and E. V. Orlova and P. Dube and H. Stark and F. Zemlin and M. van Heel},
	year={1997},
	title={Angular Reconstitution in Three-Dimensional Electron Microscopy: Practical and Technical Aspects},
	journal={Scanning Microscopy},
	volume={11},
	pages={97-111},
	note={annote: \url{http://www.aber.ac.uk/~ecmwww/journal/smi/pdf/smi97-14.pdf}}
}

@article{RefWorks:258,
	author={N. Bonnet and M. Herbin and P. Vautrot},
	year={1997},
	title={Multivariate Image Analysis and Segmentation in Microanalysis},
	journal={Scanning Microscopy},
	volume={11},
	pages={1-21},
	note={annote: \url{http://www.aber.ac.uk/~ecmwww/journal/smi/pdf/smi97-01.pdf}}
}

@article{RefWorks:259,
	author={M. J. HÃ¿tch},
	year={1997},
	title={Geometric Phase Analysis of High Resolution Electron Microscope Images},
	journal={Scanning Microscopy},
	pages={53-14},
	note={annote: \url{http://www.aber.ac.uk/~ecmwww/journal/smi/pdf/smi97-05.pdf}}
}

@article{RefWorks:260,
	author={M. Troyon and H. N. Lei and Z. Wang and G. Shang},
	year={1998},
	title={A Scanning Force Microscope Combined With a Scanning Electron Microscope for Multidimensional Data Analysis},
	journal={Scanning Microscopy},
	volume={12},
	pages={139-138},
	note={annote: \url{http://www.aber.ac.uk/~ecmwww/journal/smi/pdf/smi98-15.pdf}}
}

@article{RefWorks:261,
	author={T. Gaugel and M. Bengel and D. Malthan},
	year={2004},
	title={Building a mini-assembly system from a technology construction kit},
	journal={Assembly Automation},
	volume={24},
	number={1},
	pages={43-50},
	note={M1: Copyright 2004, IEE},
	abstract={As part of this paper, extracts are presented from the results of the joint project "MiniProd", which is carried out by the Fraunhofer IPA together with industrial partners and sponsored by the BMBF (Federal Ministry for Education and Research/02PD2370). The aim of the research project is to develop a marketable, miniaturized highly-flexible micro-assembly system capable of reproducing the correct size proportions between a product and its production environment and also able to intelligently integrate processes which had earlier run separately},
	keywords={intelligent control; microassembling; microsensors; semiconductor lasers},
	isbn={0144-5154},
	url={http://dx.doi.org/10.1108/01445150410517174}
}

@inproceedings{RefWorks:262,
	author={J. -M Breguet and A. Bergander},
	year={2001},
	title={Toward the personal factory?},
	booktitle={Microrobotics and Microassembly III, 29-30 Oct. 2001},
	series={Proc. SPIE - Int. Soc. Opt. Eng. (USA)},
	publisher={SPIE-Int. Soc. Opt. Eng},
	address={Newton, MA, USA},
	organization={Swiss Fed. Inst. of Technol., Lausanne, Switzerland},
	volume={4568},
	pages={293-303},
	note={M1: Copyright 2002, IEE},
	abstract={Production tools undergo a constant process of miniaturization. Technical, economical, as well as environmental reasons motivate this process. The research in the field of the microfactory and nanofactory addresses these issues. The question is how far and how fast will this miniaturization go? Does it make sense to have a "factory" so small that you can put it on your desk, next to you computer, and start to produce whatever you can imagine? Will personal factories (PF) ever exist? We first present different scenarios of PF. One approach, which is generally favored by physicists, chemists and biologists, is the assembly of atoms or molecules, like LEGO0RW1S34RfeSDcfkexd09rT3(R)1RW1S34RfeSDcfkexd09rT3-bricks, to build up complex devices (bottom up). We will not follow this approach in this paper. The second approach consists of the 3D microstructuring of the parts and their assembly (top down). We briefly present different structuring technologies that could apply in PF. We then briefly present the micro-positioning systems developed at EPFL that can be used for assembly in PF},
	keywords={microassembling; nanotechnology; position control; rapid prototyping (industrial)},
	isbn={0277-786X},
	url={http://dx.doi.org/10.1117/12.444138}
}

@article{RefWorks:263,
	author={Xiaochun Li and H. Choi and Yong Yang},
	year={2002},
	month={12/02},
	title={Micro rapid prototyping system for micro components},
	journal={Thin Solid Films},
	volume={420-421},
	pages={515-523},
	note={M1: Copyright 2003, IEE},
	abstract={Similarities between silicon-based micro-electro-mechanical systems (MEMS) and Shape Deposition Manufacturing (SDM) processes are obvious: both integrate additive and subtractive processes and use part and sacrificial materials to obtain functional structures. These MEMS techniques are two-dimensional (2-D) processes for a limited number of materials while SDM enables the building of parts that have traditionally been impossible to fabricate because of their complex shapes or of their variety in materials. This work presents initial results on the development of a micro rapid prototyping system that adapts SDM methodology to micro-fabrication. This system is designed to incorporate microdeposition and laser micromachining. In the hope of obtaining a precise microdeposition, an ultrasonic-based micro powder-feeding mechanism was developed in order to form thin patterns of dry powders that can be cladded or sintered onto a substrate by a micro-sized laser beam. Furthermore, experimental results on laser micromachining using a laser beam with a wavelength of 355 nm are also presented. After further improvement, the developed micro manufacturing system could take computer-aided design (CAD) output to reproduce 3-D heterogeneous microcomponents from a wide selection of materials},
	keywords={claddings; laser beam machining; laser materials processing; micromachining; micromechanical devices; powders; rapid prototyping (industrial); semiconductor device manufacture; sintering},
	isbn={0040-6090}
}

@article{RefWorks:264,
	author={D. T. Pham and R. S. Gault},
	year={1998},
	title={Comparison of rapid prototyping technologies},
	journal={International Journal of Machine Tools & Manufacture},
	volume={38},
	number={10-11},
	pages={1257-1287},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={Until recently, prototypes had to be constructed by skilled model makers from 2D engineering drawings. This is a time-consuming and expensive process. With the advent of new layer manufacturing and CAD/CAM technologies, prototypes may now be rapidly produced from 3D computer models. There are many different rapid prototyping (RP) technologies available. This paper presents an overview of the current technologies and comments on their strengths and weaknesses. Data are given for common process parameters such as layer thickness, system accuracy and speed of operation. A taxonomy is also suggested, along with a preliminary guide to process selection based on the end use of the prototype.},
	keywords={Rapid prototyping; Computer simulation; Computer aided design; Computer aided manufacturing; Three dimensional computer graphics},
	isbn={0890-6955},
	url={http://dx.doi.org/10.1016/S0890-6955(97)00137-5}
}

@article{RefWorks:265,
	author={A. Shokoufandeh and I. Marsic and S. J. Dickinson},
	year=1999,
	month=apr,
	title={View-based object recognition using saliency maps},
	journal={Image and Vision Computing},
	volume={17},
	number={5-6},
	pages={445-460},
	note={M1: Copyright 1999, IEE},
	abstract={We introduce a novel view-based object representation, called the saliency map graph (SMG), which captures the salient regions of an object view at multiple scales using a wavelet transform. This compact representation is highly invariant to translation, rotation (image and depth), and scaling, and offers the locality of representation required for occluded object recognition. To compare two saliency map graphs, we introduce two graph similarity algorithms. The first computes the topological similarity between two SMGs, providing a coarse-level matching of two graphs. The second computes the geometrical similarity between two SMGs, providing a fine-level matching of two graphs. We test and compare these two algorithms on a large database of model object views},
	keywords={image reconstruction; image representation; object recognition},
	isbn={0262-8856},
	url={http://dx.doi.org/10.1016/S0262-8856(98)00124-3}
}

@article{RefWorks:266,
	author={Eduardo Bayro-Corrochano},
	year={2006},
	title={The theory and use of the quaternion wavelet transform},
	journal={Journal of Mathematical Imaging and Vision},
	volume={24},
	number={1},
	pages={19-35},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={This paper presents the theory and practicalities of the quaternion wavelet transform (QWT). The major contribution of this work is that it generalizes the real and complex wavelet transforms and derives a quaternionic wavelet pyramid for multi-resolution analysis using the quaternionic phase concept. As a illustration we present an application of the discrete QWT for optical flow estimation. For the estimation of motion through different resolution levels we use a similarity distance evaluated by means of the quaternionic phase concept and a confidence mask. We show that this linear approach is amenable to be extended to a kind of quadratic interpolation. &copy; 2006 Springer Science + Business Media, Inc.},
	keywords={Wavelet transforms; Image analysis; Linear systems; Interpolation; Theorem proving},
	isbn={0924-9907},
	url={http://dx.doi.org/10.1007/s10851-005-3605-3}
}

@article{RefWorks:267,
	author={J. Condell and B. Scotney and P. Morrow},
	year={2005},
	month=jan,
	title={Adaptive grid refinement procedures for efficient optical flow computation},
	journal={International Journal of Computer Vision},
	volume={61},
	number={1},
	pages={31-54},
	note={M1: Copyright 2005, IEE},
	abstract={Two approaches are described that improve the efficiency of optical flow computation without incurring loss of accuracy. The first approach segments images into regions of moving objects. The method is based on a previously defined Galerkin finite element method on a triangular mesh combined with a multiresolution segmentation approach for object flow computation. Images are automatically segmented into subdomains of moving objects by an algorithm that employs a hierarchy of mesh coarseness for the flow computation, and these subdomains are reconstructed over a finer mesh on which to recompute flow more accurately. The second approach uses an adaptive mesh in which the resolution increases where motion is found to occur. Optical flow is computed over a reasonably coarse mesh, and this is used to construct an optimal adaptive mesh in a way that is different from the gradient methods reported in the literature. The finite element mesh facilitates a reduction in computational effort by enabling processing to focus on particular objects of interest in a scene (i.e. those areas where motion is detected). The proposed methods were tested on real and synthetic image sequences, and promising results are reported},
	keywords={Galerkin method; image motion analysis; image segmentation; image sequences; mesh generation},
	isbn={0920-5691},
	url={http://dx.doi.org/10.1023/B:VISI.0000042933.07192.26}
}


@article{RefWorks:268,
	author={I. Cohen and I. Herlin},
	year={1999},
	title={Non uniform multiresolution method for optical flow and phase portrait models: environmental applications},
	journal={International Journal of Computer Vision},
	volume={33},
	number={1},
	pages={29-49},
	note={M1: Copyright 1999, IEE},
	abstract={In this paper we define a complete framework for processing large image sequences for a global monitoring of short range oceanographic and atmospheric processes. This framework is based on the use of a non quadratic regularization technique for optical flow computation that preserves flow discontinuities. We also show that using an appropriate tessellation of the image according to an estimate of the motion field can improve optical flow accuracy and yields more reliable flows. This method defines a non uniform multiresolution approach for coarse to fine grid generation. It allows to locally increase the resolution of the grid according to the studied problem. Each added node refines the grid in a region of interest and increases the numerical accuracy of the solution in this region. We make use of such a method for solving the optical flow equation with a non quadratic regularization scheme allowing the computation of optical flow field while preserving its discontinuities. The second part of the paper deals with the interpretation of the obtained displacement field. For this purpose a phase portrait model used along with a new formulation of the approximation of an oriented flow field allowing to consider arbitrary polynomial phase portrait models for characterizing salient flow features. This new framework is used for processing oceanographic and atmospheric image sequences and presents an alternative to complex physical modeling techniques},
	keywords={atmospheric movements; finite element analysis; image sequences; oceanographic techniques; pattern classification},
	isbn={0920-5691},
	url={http://dx.doi.org/10.1023/A:1008161130332}
}

@article{RefWorks:269,
	author={L. Meister and H. Schaeben},
	year={2005},
	title={A concise quaternion geometry of rotations},
	journal={Mathematical Methods in the Applied Sciences},
	volume={28},
	number={1},
	pages={101-26},
	note={M1: Copyright 2005, IEE},
	abstract={This communication compiles propositions concerning the spherical geometry of rotations when represented by unit quaternions. The propositions are thought to establish a two-way correspondence between geometrical objects in the space of real unit quaternions representing rotations and geometrical objects constituted by directions in the three-dimensional space subjected to these rotations. In this way a purely geometrical proof of the spherical Asgeirsson's mean value theorem and a geometrical interpretation of integrals related to the spherical Radon transform of a probability density functions of unit quaternions are accomplished},
	keywords={crystal orientation; density functional theory; probability; Radon transforms; texture},
	isbn={0170-4214},
	url={http://dx.doi.org/10.1002/mma.560}
}

@PhdThesis{RefWorks:270,
        author={T. BÃ¼low},
        title={Hypercomplex Spectral Signal Representations for Image Processing and Analysis},
        school={Christian-Albrechts-UniversitÃ¤t},
        address={Kiel, Germany},
        year={1999},
	url={http://www.ks.informatik.uni-kiel.de/{~}vision/doc/Dissertationen/Thomas_Buelow/diss.ps.gz},
        annote={PhD thesis on Quaternion-Wavelet transform. Instead of transforming to complex numbers, quaternions are used ($2^n$ components for $n$ dimensions)}
}

@book{RefWorks:271,
	author={William Rowan Hamilton},
	year={1899},
	title={Elements of Quaternions},
	publisher={London, New York, ... : Longmans, Green},
	volume={1},
	url={http://www.archive.org/details/117770258_001}
}

@book{RefWorks:272,
	author={William Rowan Hamilton},
	year={1901},
	title={Elements of Quaternions},
	publisher={London, New York, ... : Longmans, Green},
	volume={2},
	url={http://www.archive.org/details/117770258_002}
}

@inproceedings{RefWorks:273,
	author={M. Felsberg and G. Sommer},
	year={2002},
	title={Image features based on a new approach to 2D rotation invariant quadrature filters},
	booktitle={Computer Vision - ECCV 2002. 7th European Conference on Computer Vision. Proceedings, 28-31 May 2002},
	series={Computer Vision - ECCV 2002. 7th European Conference on Computer Vision. Proceedings, Part I (Lecture Notes in Computer Science Vol.2350)},
	publisher={Springer-Verlag},
	address={Copenhagen, Denmark},
	organization={Linkoping Univ., Sweden},
	pages={369-383},
	note={M1: Copyright 2002, IEE},
	abstract={Quadrature filters are a well known method of low-level computer vision for estimating certain properties of the signal, as there are local amplitude and local phase. However, 2D quadrature filters suffer from being not rotation invariant. Furthermore, they do not allow to detect truly 2D features as corners and junctions unless they are combined to form the structure tensor. This paper deals with a new 2D generalization of quadrature filters which is rotation invariant and allows to analyze intrinsically 2D signals. Hence, the new approach can be considered as the union of properties of quadrature filters and of the structure tensor. The proposed method first estimates the local orientation of the signal which is then used for steering some basic filter responses. Certain linear combination of these filter responses are derived which allow to estimate the local isotropy and two perpendicular phases of the signal. The phase model is based on the assumption of an angular band-limitation in the signal. As an application, a simple and efficient point-of-interest operator is presented and it is compared to the Plessey detector},
	keywords={computer vision; feature extraction; quadrature mirror filters},
	isbn={3 540 43745 2}
}

@inproceedings{RefWorks:274,
	author={Markus Michaelis and Rainer Herpers and Lars Witta and Gerald Sommer},
	year={1997},
	title={Hierarchical filtering scheme for the detection of facial keypoints},
	booktitle={Proceedings of the 1997 IEEE International Conference on Acoustics, Speech, and Signal Processing, ICASSP. Part 4 (of 5), Apr 21-24 1997},
	series={ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
	publisher={IEEE, Piscataway, NJ, USA},
	address={Munich, Ger},
	organization={GSF - Inst of Medical Informatics and Health Services Research, Neuherberg, Ger},
	volume={4},
	pages={2541-2544},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={Usually, the first processing step in computer vision systems consists of a spatial convolution with only a few simple filters. Therefore, information is lost or it is not represented explicitly for the following processing steps. This paper proposes a new hierarchical filter scheme that can efficiently synthesize the responses for a large number of specific filters. The scheme is based on steerable filters. It also allows for an efficient on-line adjustment of the trade off between the speed and the accuracy of the filters. We apply this method to the detection of facial keypoints, especially the eye corners. These anatomically defined keypoints exhibit a large variability in their corresponding image structures so that a flexible low level feature extraction is required.},
	keywords={Computer vision; Feature extraction; Edge detection; Electric filters; Spatial variables measurement},
	isbn={0736-7791},
	url={http://dx.doi.org/10.1109/ICASSP.1997.595306}
}

@article{RefWorks:275,
	author={Hong Oh Kim and Rae Young Kim and Yong Hoon Lee and Jae Kun Lim},
	year={2002},
	title={On Riesz wavelets associated with multiresolution analyses},
	journal={Applied and Computational Harmonic Analysis},
	volume={13},
	number={2},
	pages={138-150},
	note={M1: Copyright 2003, IEE},
	abstract={We obtain some properties that Riesz wavelets and the corresponding scaling functions should satisfy in order that the Riesz wavelets be associated with multiresolution analyses (MRAs). They are given in terms of the low/high-pass filters and in terms of the Fourier transform by using the newly obtained necessary and sufficient condition for the sum of two principal shift-invariant subspaces to be closed. The properties are used to improve the characterizations of Riesz wavelets associated with MRAs previously obtained by some of the authors},
	keywords={filtering theory; Fourier transforms; high-pass filters; low-pass filters; signal resolution; wavelet transforms},
	isbn={1063-5203},
	url={http://dx.doi.org/10.1016/S1063-5203(02)00500-6}
}

@article{RefWorks:276,
	author={W. T. Freeman and E. H. Adelson},
	year={1991},
	title={The design and use of steerable filters},
	journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
	volume={13},
	number={9},
	pages={891-906},
	note={M1: Copyright 1992, IEE},
	abstract={The authors present an efficient architecture to synthesize filters of arbitrary orientations from linear combinations of basis filters, allowing one to adaptively steer a filter to any orientation, and to determine analytically the filter output as a function of orientation. Steerable filters may be designed in quadrature pairs to allow adaptive control over phase as well as orientation. The authors show how to design and steer the filters and present examples of their use in the analysis of orientation and phase, angularly adaptive filtering, edge detection, and shape from shading. One can also build a self-similar steerable pyramid representation. The same concepts can be generalized to the design of 3-D steerable filters},
	keywords={adaptive filters; filtering and prediction theory; picture processing},
	isbn={0162-8828},
	url={http://dx.doi.org/10.1109/34.93808}
}

@inproceedings{RefWorks:277,
	author={M. Felsberg and G. Sommer},
	year={2001},
	title={Scale adaptive filtering derived from the Laplace equation},
	booktitle={Pattern Recognition. 23rd DAGM Symposium. Proceedings, 12-14 Sept. 2001},
	series={Pattern Recognition. 23rd DAGM Symposium. Proceedings (Lecture Notes in Computer Science Vol.2191)},
	publisher={Springer-Verlag},
	address={Munich, Germany},
	pages={124-131},
	note={M1: Copyright 2002, IEE},
	abstract={We present a new approach to scale-space which is derived from the 3D Laplace equation instead of the heat equation. The resulting low-pass and band-pass filters are discussed and they are related to the monogenic signal. As an application, we present a scale adaptive filtering which is used for denoising images. The adaptivity is based on the local energy of spherical quadrature filters and can also be used for sparse representation of images},
	keywords={adaptive filters; band-pass filters; filtering theory; image processing; image representation; Laplace equations; low-pass filters},
	isbn={3 540 42596 9}
}

@inproceedings{RefWorks:278,
	author={C. Massot and J. Herault},
	year={2005},
	title={Recovering the Shape from Texture Using Lognormal Filters},
	edition={Antwerp, Belgium}
}

@article{RefWorks:279,
	author={M. S. Bobji and J. B. Pethica and B. J. Inkson},
	year={2005},
	month=oct,
	title={Indentation mechanics of Cu-Be quantified by an in situ transmission electron microscopy mechanical probe},
	journal={Journal of Materials Research},
	volume={20},
	number={10},
	pages={2726-2732},
	abstract={In situ transmission electron microscopy was used to study, in real time, the sub-surface deformation taking place in Cu-Be alloy during nanoindentation. A twinned region of the material was indented with a sharp tungsten tip in a specially developed transmission electron microscopy (TEM) holder. A flexible hinge-based force sensor was used to measure the force on the indenter, and the force-displacement curve for the tip was obtained by tracking the tip in the sequential images of a TEM video of the indentation process. Step-like structures ~50 nm in size resulting from the tip surface roughness were observed to generate clusters of dislocations in the sample when they come in contact with the softer Cu-Be. With this setup, the forces and the mean pressure associated with such an individual deformation event in a nanostructured TEM sample were measured},
	keywords={beryllium alloys; copper alloys; deformation; dislocations; indentation; nanostructured materials; transmission electron microscopy},
	isbn={0884-2914},
	url={http://dx.doi.org/10.1557/JMR.2005.0332}
}

@inproceedings{RefWorks:280,
	author={H. Knutsson},
	year={1989},
	title={Representing local structure using tensors},
	booktitle={Proceedings of 6th Scandinavian Conference on Image Analysis, 19-22 June 1989},
	series={Proceedings of 6th Scandinavian Conference on Image Analysis},
	publisher={Pattern Recognition Soc. Finland},
	address={Oulu, Finland},
	organization={Comput. Vision Lab., Linkoping Univ., Sweden},
	pages={244-251},
	abstract={The fundamental problem of finding a suitable representation of the orientation of 3D surfaces is considered. A representation is regarded suitable if it meets three basic requirements: uniqueness, uniformity and polar separability. A suitable tensor representation is given},
	keywords={picture processing}
}

@article{RefWorks:281,
	author={K. G. Larkin},
	year={2005},
	month={10/03},
	title={Uniform estimation of orientation using local and nonlocal 2-D energy operators},
	journal={Optics Express},
	volume={13},
	number={20},
	abstract={Two new two dimensional (2-D) complex operators for estimating the energy and orientation of 2-D oriented patterns are proposed. The starting point for our work is a new 2-D extension of the Teager-Kaiser energy operator incorporating orientation estimation. The first new energy operator is based on partial derivatives and can be considered a local (point-based) estimator. Using a nonlocal (pseudo-differential) operator we derive a second and more general energy operator. A scale invariant nonlocal operator is derived from the recently proposed spiral phase quadrature (or Riesz) transform. The Teager-Kaiser energy operator and the phase congruency local energy are unified in a single equation for both 1-D and 2-D. Robust orientation estimation, important for isotropic demodulation of fringe patterns is demonstrated. Theoretical error analysis of the local operator is greatly simplified by a logarithmic formulation. Experimental results using the operators on noisy images are shown. In the presence of Gaussian additive noise both the local and nonlocal operators give improved performance when compared with a simple gradient based estimator},
	keywords={demodulation; error analysis; estimation theory; Gaussian noise; image processing; mathematical operators},
	isbn={1094-4087}
}

@misc{RefWorks:282,
	author={C. -F Westin},
	year={1994},
	title={A Tensor Framework for Multidimensional Signal Processing},
	note={Dissertation No 348},
	isbn={91-7871-421-4},
	url={http://www.imt.liu.se/mi/Publications/Papers/CF_Westin_thesis.pdf}
}

@article{RefWorks:283,
	author={G. H. Granlund},
	year={1978},
	month=oct,
	title={In search of a general picture processing operator},
	journal={Computer Graphics and Image Processing},
	volume={8},
	number={2},
	pages={155-173},
	abstract={The problem of finding a general, parallel, and hierarchical operator  for picture processing is considered. An operator is defined which at  different levels can detect and describe structure as opposed to  uniformity within local regions, whatever structure and uniformity may  imply at a particular level. The operator performs a mapping from one  complex field to another. The important characteristic of this approach  is the use of complex fields which allows a global-to-local feedback.  In the transformation process the image is simplified. A Fourier  implementation of the operator is described and a new transform is  defined. A hierarchical structure of such transformations gives a  sequential description of structure over increasingly larger regions of  the image. The processed information at different levels can be used as  input to a classifier. Examples are given of processing results},
	keywords={Fourier transforms; pattern recognition; picture processing},
	isbn={0146-664X},
	url={http://citeseer.ist.psu.edu/granlund78search.html}
}

@article{RefWorks:284,
	author={A. K. Jain and F. Farrokhnia},
	year={1991},
	title={Unsupervised texture segmentation using Gabor filters},
	journal={Pattern Recognition},
	volume={24},
	number={12},
	pages={1167-1186},
	abstract={This paper presents a texture segmentation algorithm inspired by the multichannel filtering theory for visual information processing in the early stages of the human visual system. The channels are characterized by a bank of Gabor filters that nearly uniformly covers the spatial-frequency domain, and a systematic filter selection scheme is proposed, which is based on reconstruction of the input image from the filtered images. Texture features are obtained by subjecting each (selected) filtered image to a nonlinear transformation and computing a measure of energy in a window around each pixel. A square-error clustering algorithm is then used to integrate the feature images and produce a segmentation. A simple procedure to incorporate spatial information in the clustering process is proposed. A relative index is used to estimate the `true' number of texture categories},
	keywords={filtering and prediction theory; pattern recognition; picture processing},
	isbn={0031-3203},
	url={http://dx.doi.org/10.1016/0031-3203(91)90143-S}
}

@article{RefWorks:285,
	author={Junqiu Wang and Hongbin Zha and Roberto Cipolla},
	year={2006},
	title={Coarse-to-fine vision-based localization by indexing scale-invariant features},
	journal={IEEE Transactions on Systems, Man, and Cybernetics, Part B: Cybernetics},
	volume={36},
	number={2},
	pages={413-422},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={This paper presents a novel coarse-to-fine global localization approach inspired by object recognition and text retrieval techniques. Harris-Laplace interest points characterized by scale-invariant transformation feature descriptors are used as natural landmarks. They are indexed into two databases: a location vector space model (LVSM) and a location database. The localization process consists of two stages: coarse localization and fine localization. Coarse localization from the LVSM is fast, but not accurate enough, whereas localization from the location database using a voting algorithm is relatively slow, but more accurate. The integration of coarse and fine stages makes fast and reliable localization possible. If necessary, the localization result can be verified by epipolar geometry between the representative view in the database and the view to be localized. In addition, the localization system recovers the position of the camera by essential matrix decomposition. The localization system has been tested in indoor and outdoor environments. The results show that our approach is efficient and reliable. &copy; 2006 IEEE.},
	keywords={Mobile robots; Robotics; Object recognition; Tracking (position); Computer vision; Mathematical models; Vectors; Matrix algebra; Algorithms},
	isbn={1083-4419},
	url={http://dx.doi.org/10.1109/TSMCB.2005.859085}
}

@article{RefWorks:286,
	author={Miguel Ribo and Markus Brandner and Axel Pinz},
	year={2004},
	title={A flexible software architecture for hybrid tracking},
	journal={Journal of Robotic Systems},
	volume={21},
	number={2},
	pages={53-62},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={Fusion of vision-based and inertial pose estimation has many high-potential applications in navigation, robotics, and augmented reality. Our research aims at the development of a fully mobile, completely self-contained tracking system, that is able to estimate sensor motion from known 3D scene structure. This requires a highly modular and scalable software architecture for algorithm design and testing. As the main contribution of this paper, we discuss the design of our hybrid tracker and emphasize important features: scalability, code reusability, and testing facilities. In addition, we present a mobile augmented reality application, and several first experiments with a fully mobile vision-inertial sensor head. Our hybrid tracking system is not only capable of real-time performance, but can also be used for offline analysis of tracker performance, comparison with ground truth, and evaluation of several pose estimation and information fusion algorithms. &copy; 2004 Wiley Periodicals, Inc.},
	keywords={Motion planning; Computer software; Motion estimation; Image sensors; Algorithms; Virtual reality; Computer vision; Sensor data fusion},
	isbn={0741-2223},
	url={http://dx.doi.org/10.1002/rob.10124}
}

@article{RefWorks:287,
	author={J. B. Zhang and R. H. Weston},
	year={1994},
	title={Reference architecture for open and integrated automatic optical inspection systems},
	journal={International Journal of Production Research},
	volume={32},
	number={7},
	pages={1521-1543},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={We examine the role and potential application areas of machine vision inspection systems in the printed circuit board (PCB) manufacturing industry. Available automatic optical inspection (AOI) techniques are reviewed, this revealing limitations which stem mainly from the stand-alone operational nature of the present-generation AOI systems. As a result the authors argue that, fuelled by the need to achieve integration and information sharing between AOI systems and other components of computerized manufacturing systems, it is necessary to define architectural guidelines that structure the way in which next generation AOI systems should be organized in order to enable them to share information of a common interest and cooperate on an enterprise-wide basis. We also examine typical applications of AOI in PCB manufacture. Upon extracting common features of these applications, a model of AOI task decomposition is proposed, which characterizes the main features of the two major subtasks that an AOI system needs to perform; so that it can benefit from information sharing and improve its performance in terms of providing more valuable and reusable inspection information to other computerized systems and processes. These two subtasks are (1) an initial local inspection subtask, and (2) a global inspection, analysis and inspection information generation subtask. The importance of the second subtask relates to the general requirement for AOI systems not only simply to automate PCB inspection processes, but also to provide readily reusable inspection information that can be utilized to support other relevant manufacturing processes. Based on the AOI task decomposition model, we propose a hierarchical architecture which can structure the design, implementation and re-organisation of AOI software algorithms and routines, in such a way that typical AOI operations can be enhanced, this through making use of available global information, and that more widespread, efficient and timely use of AOI-generated inspection information can be made by other manufacturing processes. Finally, a proof-of-concept implementation of the AOI reference architecture is described.},
	keywords={Inspection; Optical systems; Automation; Computer vision; Printed circuit manufacture; Computer integrated manufacturing; Mathematical models; Hierarchical systems; Systems analysis; Algorithms; Computer software; Competition; Quality assurance},
	isbn={0020-7543}
}

@inproceedings{RefWorks:288,
	author={Stefan Schiffer and Joachim Hans Frohlich},
	year={1994},
	title={Concepts and architecture of Vista - A multiparadigm programming environment},
	booktitle={Proceedings of the IEEE Symposium on Visual Languages, Oct 4-7 1994},
	series={IEEE Symposium on Visual Languages, Proceedings},
	publisher={IEEE, Los Alamitos, CA, USA},
	address={St. Louis, MO, USA},
	organization={Johannes Kepler Universitat Linz, Linz, Austria},
	pages={40-47},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={This paper describes Vista, a visual multiparadigm programming environment. We introduce the notion of processors and networks and discuss their application in the construction of event-driven and data-transformation systems. Further, we give an overview of Vista's object-oriented architecture.},
	keywords={Data structures; Computer architecture; Computer programming languages; Computer simulation; Object oriented programming; Computer vision; Computer graphics; Program processors; Software engineering},
	isbn={1049-2615},
	url={http://dx.doi.org/10.1109/VL.1994.363642}
}

@techreport{RefWorks:290,
	author={Thor List and Jose Carlos Bins and Roberts Fisher and David Tweed and Kristinn R. Thrisson},
	year={2005},
	month={July 10},
	title={Two approaches to a plug-and-play vision architecture - CAVIAR and Psyclone},
	institute={AAAI},
	number={WS-05-08},
	pages={16-23}
}

@inproceedings{RefWorks:291,
	author={Wolfgang Ponweiser and Gerald Umgeher and Markus Vincze},
	year={2003},
	title={A Reusable Dynamic Framework for Cognitive Vision Systems},
	booktitle={Workshop on Computer Vision System Control Architectures (VSCA 2003)},
	edition={Graz}
}

@article{RefWorks:292,
	author={D. W. Eggert and A. Lorusso and R. B. Fisher},
	year={1997},
	title={Estimating 3-D rigid body transformations: a comparison of four major algorithms},
	journal={Machine Vision and Applications},
	volume={9},
	number={5-6},
	pages={272-290},
	abstract={A common need in machine vision is to compute the 3-D rigid body transformation that aligns two sets of points for which correspondence is known. A comparative analysis is presented here of four popular and efficient algorithms, each of which computes the translational and rotational components of the transform in closed form, as the solution to a least squares formulation of the problem. They differ in terms of the transformation representation used and the mathematical derivation of the solution, using respectively singular value decomposition or eigensystem computation based on the standard [R,T] representation, and the eigensystem analysis of matrices derived from unit and dual quaternion forms of the transform. This comparison presents both qualitative and quantitative results of several experiments designed to determine (1) the accuracy and robustness of each algorithm in the presence of different levels of noise, (2) the stability with respect to degenerate data sets, and (3) relative computation time of each approach under different conditions. The results indicate that under &ldquo;ideal&rdquo; data conditions (no noise) certain distinctions in accuracy and stability can be seen. But for &ldquo;typical, real-world&rdquo; noise levels, there is no difference in the robustness of the final solutions (contrary to certain previously published results). Efficiency, in terms of execution time, is found to be highly dependent on the computer system setup},
	keywords={computer vision; motion estimation; singular value decomposition},
	isbn={0932-8092},
	url={http://dx.doi.org/10.1007/s001380050048}
}

@inproceedings{RefWorks:293,
	author={T. BÃ¼low and G. Sommer},
	year={1997},
        month=sep,
	title={Multi-dimensional signal processing using an algebraically extended signal representation},
	booktitle={Algebraic Frames for the Perception-Action Cycle. International Workshop, AFPAC '97 Proceedings, 8-9 Sept. 1997},
	series={Algebraic Frames for the Perception-Action Cycle. International Workshop, AFPAC'97. Proceedings},
	publisher={Springer-Verlag},
	address={Kiel, Germany},
	organization={Inst. of Comput. Sci., Kiel Univ., Germany},
	pages={148-163},
	abstract={Many concepts that are used in multi-dimensional signal processing are derived from one-dimensional signal processing. As a consequence, they are only suited to multi-dimensional signals which are intrinsically one-dimensional. We claim that this restriction is due to the restricted algebraic frame used in signal processing, especially to the use of the complex numbers in the frequency domain. We propose a generalization of the two-dimensional Fourier transform which yields a quaternionic signal representation. We call this transform the quaternionic Fourier transform (QFT). Based on the QFT, we generalize the conceptions of the analytic signal, Gabor filters, instantaneous and local phase to two dimensions in a novel way which is intrinsically two-dimensional. Experimental results are presented},
	keywords={algebra; computer vision; filtering theory; Fourier transforms; signal representation},
	isbn={3 540 63517 3}
}

@article{RefWorks:294,
	author={E. Bayro-Corrochano and R. Vallejo and N. Arana-Daniel},
	year={2005},
	month=aug,
	title={Geometric preprocessing, geometric feedforward neural networks and Clifford support vector machines for visual learning},
	journal={Neurocomputing},
	volume={67},
	pages={54-105},
	abstract={This paper shows the design and use of feed-forward neural networks and the support vector machines (SVM) in the coordinate-free mathematical system of the Clifford geometric algebra. We compare the McCulloch-Pitts neuron and the geometric neuron. An interesting case of the geometric neuron is the conformal neuron which can be used for RBF networks and SVM. The paper presents the generalization of the real- and complex-valued multilayer perceptron (MLP) to the Clifford valued multilayer perceptron. The paper studies also the multivector support vector machines (MSVM) which are SVMs for processing multivectors. For that we design kernels involving Clifford products. The resultant kernel resembles a sort of polynomial kernel using a multivector representation. In the context of SVMs an important contribution of the paper is the generalization of the real- and complex-valued SVM classifiers over the hyper-complex numbers. This Clifford valued SVM accepts multiple multivector inputs and it is a multi-class classifier. For the preprocessing the authors introduce a promising geometric method utilizing Clifford moments. This method is applied together with geometric MLPs for tasks of 2D pattern recognition. The experimental part shows applications of SVM using the conformal neuron and Clifford kernels. We include challenging applications of the Clifford SVM classifier for nonlinear separable problems. The authors believe that the use of the MLPs and SVMs in the geometric algebra framework expands their sphere of applicability for multivector learning in graded spaces. [All rights reserved Elsevier]},
	keywords={algebra; feedforward neural nets; geometry; learning (artificial intelligence); multilayer perceptrons; pattern recognition; support vector machines},
	isbn={0925-2312},
	url={http://dx.doi.org/10.1016/j.neucom.2004.11.041}
}

@article{RefWorks:295,
	author={D. Berton},
	year={2004},
	title={The Qt Designer IDE},
	journal={Dr.Dobb's Journal},
	volume={29},
	number={9},
	pages={57-60},
	abstract={Among the many GUI programming libraries available, both free and licensed, the Qt C++ Library from Trolltech has a strong following. And with the advent of Qt designer 3.3-1, Qt developers now have a feature-rich IDE with which to design and code GUI applications. Designer works with Qt project files (.pro) directly so that it can be used on an as-needed basis to design and implement the GUI portions of your application. Designer's project management gives you control over application include paths, linking with other libraries, and platform-specific settings},
	keywords={C++ language; graphical user interfaces; program compilers; programming environments; visual languages; visual programming},
	isbn={1044-789X},
        url={http://www.ddj.com/184405813}
}

@article{RefWorks:296,
	author={D. Berton},
	year={2004},
	month=jul,
	title={Qt designer: code generation and GUI design},
	journal={C/C++ Users Journal},
	volume={22},
	number={7},
	pages={34-40},
	abstract={The designer IDE, which comes with the latest Qt C++ library by Trolltech, has filled a gaping hole in the world of application development with Qt, namely the lack of a visual IDE. The latest designer provides a modern GUI development environment complete with code generation, code editing, and project management},
	keywords={C++ language; graphical user interfaces; object-oriented programming; program compilers; software libraries; user interface management systems},
	isbn={1075-2838},
        url={http://www.ddj.com/184401821}
}

@misc{RefWorks:297,
	author={Eskil Abrahamsen Blomfeldt},
	title={Qt-Quarterly: Dynamic Signals and Slots},
	note={\url{http://doc.trolltech.com/qq/qq16-dynamicqobject.html}}
}
@misc{RefWorks:298,
	author={Reginald Stadlbauer},
	title={Qt Quarterly: Scripting Qt},
	note={\url{http://doc.trolltech.com/qq/qq10-scripting-qt.html}}
}

@article{RefWorks:299,
	author={T. Jansen and T. Dreiseidler and N. Hanssen and L. Ritter and B. von Rymon-Lipinski and E. Keeve},
	year={2005},
	title={JuliusâA Software Framework for Rapid Application Development in Computer-Aided Surgery},
	journal={Proceeding 39th Annual Conference of the German Society for Miomedical Engineering BMTâ05}
}

@inproceedings{RefWorks:301,
	author={J. M. Neighbors},
	year={1994},
	title={An assessment of reuse technology after ten years},
	booktitle={Proceedings of 1994 3rd International Conference on Software Reuse, 1-4 Nov. 1994},
	series={Proceedings. Third International Conference on Software Reuse: Advances in Software Reusability (Cat. No.94TH06940)},
	publisher={IEEE Comput. Soc. Press},
	address={Rio de Janeiro, Brazil},
	organization={SADA, Costa Mesa, CA, USA},
	pages={6-13},
	abstract={More than ten years ago the first major workshop on &ldquo;Reusability in Programming&rdquo; was held. Since that time some technologies have advanced and come into successful commercial use while others have gone unused. New management and abstraction techniques have aided reuse. Interfacing to huge abstractions, now in common use, has made reuse more difficult. This paper is not a formal survey of reuse technology but instead discusses the evolution of early concepts and the issues they raise. Much of the research of the original workshop participants is just now becoming relevant. In some cases the research of the past points to problems and solutions for the present. As part of this examination the activities in reuse for the next ten years are forecast and a guide of hard questions to ask purveyors of reuse technology is provided},
	keywords={software reusability; technological forecasting},
	isbn={0 8186 6632 3},
	url={http://dx.doi.org/10.1109/ICSR.1994.365816}
}

@article{RefWorks:302,
	author={Seungyun Lee and Oh-Cheon Kwon and Gyu-Sang Shin},
	year={2003},
	title={Visual component assembly and tool support based on system architecture},
	journal={ETRI Journal},
	volume={25},
	number={6},
	pages={464-474},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={Component-based development leverages software reusability and reduces development costs. Enterprise JavaBeans (EJB) is a component model developed to reduce the complexity of software development and to facilitate reuse of components. However, EJB does not support component assembly by a plug-and-play technique due to the hard-wired composition at the code level. To cope with this problem, an architecture for EJB component assembly is defined at the abstract level and the inconsistency between the system architecture and its implementation must be eliminated at the implementation level. We propose a component-based application development tool named the COBALT assembler that supports the design and implementation of EJB component assembly by a plug-and-play technique based on the architecture style. The system architecture is first defined by the Architecture Description Language (ADL). The wrapper code and glue code are then generated for the assembly. After the consistency between the architecture and its implementation is checked, the assembled EJB components are deployed in an application server as a new composite component. We use the COBALT assembler for a shopping mall system and demonstrate that it can promote component reuse and leverage the system maintainability.},
	keywords={Computer aided software engineering; Program assemblers; Java programming language; Computer hardware description languages; Codes (symbols); Computer software reusability; Computer software maintenance; Computational complexity},
	isbn={1225-6463}
}

@inproceedings{RefWorks:303,
	author={David B. Stewart and P. K. Khosla},
	year={1995},
	title={Chimera methodology: designing dynamically reconfigurable real-time software using port-based objects},
	booktitle={Proceedings of the the 1994 1st Workshop on Object-Oriented Real-Time Dependable Systems (WORDS'94), Oct 24-25 1994},
	series={Proceedings of the Workshop on Object-Oriented Real-Time Dependable Systems (WORDS)},
	publisher={IEEE, Piscataway, NJ, USA},
	address={Dana Point, CA, USA},
	organization={Univ of Maryland, College Park, MD, USA},
	pages={46-53},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={The Chimera Methodology is a new software engineering paradigm which addresses the problem of developing dynamically reconfigurable and reusable real-time software. The foundation of the Chimera methodology is the port-based object model of a reusable software component. The model is obtained by applying the port-automaton formal computational model to object-based design. Global state variable table real-time communication is used to integrate port-based objects, which eliminates the need for writing and debugging glue code. The Chimera real-time operating system provides tools to support the software models defined by the Chimera methodology, so that real-time software can be executed predictably using common real-time scheduling algorithms. A hypermedia user interface has been designed to allow users to easily assemble the real-time software components that are designed based on the Chimera methodology. Use of the methodology can result in a significant decrease the development time and cost of real-time applications.},
	keywords={Software engineering; Real time systems; Computer software; Mathematical models; Automata theory; Computational methods; Object oriented programming; Program debugging; Computer operating systems; Algorithms; User interfaces; Codes (symbols)},
	url={http://dx.doi.org/10.1109/WORDS.1994.518670}
}

@article{RefWorks:304,
	author={Raz Koren and Yitzhak Yitzhaky},
	year={2006},
	title={Automatic selection of edge detector parameters based on spatial and statistical measures},
	journal={Computer Vision and Image Understanding},
	volume={102},
	number={2},
	pages={204-213},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={The basic and widely used edge detection operation in an image usually requires a prior step of setting the edge detector parameters (thresholds, blurring extent etc.). Finding the best detector parameters automatically in real-world images is a difficult challenge because no absolute ground truth exists. However, the advantage of automatic processing over manual operations done by humans motivates the development of automatic detector parameter selection. In this work, we propose an automatic detector parameter selection which considers both, statistical correspondence of detection results produced from different detector parameters, and spatial correspondence between detected edge points, represented as saliency values. The method improves a recently developed technique that employs only statistical correspondence of detection results and depends on the initial parameter range by incorporating saliency values in the statistical analysis. Automatic edge detection results show considerable improvement of the purely statistical method when a wrong initial parameter range is selected. &copy; 2006 Elsevier Inc. All rights reserved.},
	keywords={Edge detection; Detectors; Statistical methods; Image analysis; Parameter estimation},
	isbn={1077-3142},
	url={http://dx.doi.org/10.1016/j.cviu.2006.01.005}
}

@article{RefWorks:305,
	author={Andreas Opelt and Axel Pinz and Michael Fussenegger and Peter Auer},
	year={2006},
	title={Generic object recognition with boosting},
	journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
	volume={28},
	number={3},
	pages={416-431},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={This paper explores the power and the limitations of weakly supervised categorization. We present a complete framework that starts with the extraction of various local regions of either discontinuity or homogeneity. A variety of local descriptors can be applied to form a set of feature vectors for each local region. Boosting is used to learn a subset of such feature vectors (weak hypotheses) and to combine them into one final hypothesis for each visual category. This combination of individual extractors and descriptors leads to recognition rates that are superior to other approaches which use only one specific extractor/ descriptor setting. To explore the limitation of our system, we had to set up new, highly complex image databases that show the objects of interest at varying scales and poses, in cluttered background, and under considerable occlusion. We obtain classification results up to 81 percent ROC-equal error rate on the most complex of our databases. Our approach outperforms all comparable solutions on common databases. &copy; 2006 IEEE.},
	keywords={Object recognition; Computer vision; Database systems; Image segmentation; Learning algorithms; Error analysis; Mathematical models; Learning systems},
	isbn={0162-8828}
}

@article{RefWorks:306,
	author={Zhigang Zhu and Guangyou Xu and E. M. Riseman and A. R. Hanson},
	year={2006},
	month={01/01},
	title={Fast construction of dynamic and multi-resolution 360&deg; panoramas from video sequences},
	journal={Image and Vision Computing},
	volume={24},
	number={1},
	pages={13-26},
	abstract={This paper presents a unified approach to automatically build dynamic and multi-resolution 360&deg; panoramic (DMP) representations from image sequences captured by hand-held cameras mainly undertaking rotation and zooming for natural scenes with moving targets. A simple (yet stable) rigid motion model and a closed-loop-based mosaicing algorithm are proposed to generate cylindrical mosaics automatically. Multi-resolution representations are built for interesting areas by separating zooming sub-sequences from a pan/zoom sequence. Moving objects are detected and separated from images based on motion information, and then more accurate contours are extracted using a modified active contour algorithm. The DMP construction method is fast, robust, and automatic, achieving five frames per second for image sequences with 384&times;288 color images on a Pentium III 800MHz PC. The construction of the DMP representation can be used in virtual reality, video surveillance, and very low bit-rate video coding. [All rights reserved Elsevier]},
	keywords={feature extraction; image representation; image resolution; image segmentation; image sequences; motion estimation; video signal processing},
	isbn={0262-8856},
	url={http://dx.doi.org/10.1016/j.imavis.2005.09.006}
}

@article{RefWorks:307,
	author={Irina Popovici and William Douglas Withers},
	year={2006},
	title={Custom-built moments for edge location},
	journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
	volume={28},
	number={4},
	pages={637-642},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={We present a general construction of functions whose moments serve to locate and parametrize step edges within an image. Previous use of moments to locate edges was limited to functions supported on a circular region, but our method allows the use of "custom-designed" functions supported on circles, rectangles, or any desired shape, and with graphs whose shape may be chosen with great freedom. We present analyses of the sensitivity of our method to pixelization errors or discrepancy between the image and an idealized edge model. The parametric edge description yielded by our method makes it especially suitable as a component of wedgelet image coding. &copy; 2006 IEEE.},
	keywords={Edge detection; Image coding; Image analysis; Method of moments; Graphic methods; Error analysis; Mathematical models; Mathematical transformations},
	isbn={0162-8828}
}

@article{RefWorks:308,
	author={Ying Shan and Harpreet S. Sawhney and Bogdan Matei and Rakesh Kumar},
	year={2006},
	title={Shapeme histogram projection and matching for partial object recognition},
	journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
	volume={28},
	number={4},
	pages={568-577},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={Histograms of shape signature or prototypical shapes, called shapemes, have been used effectively in previous work for 2D/3D shape matching and recognition. We extend the idea of shapeme histogram to recognize partially observed query objects from a database of complete model objects. We propose representing each model object as a collection of shapeme histograms and match the query histogram to this representation in two steps: 1) compute a constrained projection of the query histogram onto the subspace spanned by all the shapeme histograms of the model and 2) compute a match measure between the query histogram and the projection. The first step is formulated as a constrained optimization problem that is solved by a sampling algorithm. The second step is formulated under a Bayesian framework, where an implicit feature selection process is conducted to improve the discrimination capability of shapeme histograms. Results of matching partially viewed range objects with a 243 model database demonstrate better performance than the original shapeme histogram matching algorithm and other approaches. &copy; 2006 IEEE.},
	keywords={Object recognition; Pattern matching; Feature extraction; Image analysis; Database systems; Query languages; Mathematical models; Optimization; Algorithms},
	isbn={0162-8828}
}

@article{RefWorks:309,
	author={Thang V. Pham and Arnold W. M. Smeulders},
	year={2006},
	title={Sparse representation for coarse and fine object recognition},
	journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
	volume={28},
	number={4},
	pages={555-567},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={This paper offers a sparse, multiscale representation of objects. It captures the object appearance by selection from a very large dictionary of Gaussian differential basis functions. The learning procedure results from the matching pursuit algorithm, while the recognition is based on polynomial approximation to the bases, turning image matching into a problem of polynomial evaluation. The method is suited for coarse recognition between objects and, by adding more bases, also for fine recognition of the object pose. The advantages over the common representation using PCA include storing sampled points for recognition is not required, adding new objects to an existing data set is trivial because retraining other object models is not needed, and significantly in the important case where one has to scan an image over multiple locations in search for an object, the new representation is readily available as opposed to PCA projection at each location. The experimental result on the COIL-100 data set demonstrates high recognition accuracy with real-time performance. &copy; 2006 IEEE.},
	keywords={Object recognition; Pattern matching; Learning algorithms; Polynomial approximation; Principal component analysis; Data structures},
	isbn={0162-8828}
}

@article{RefWorks:310,
	author={Y. Caspi and D. Simakov and M. Irani},
	title={Feature-based sequence-to-sequence matching},
	journal={Proc.VAMODS (Vision and Modelling of Dynamic Scenes) workshop, with ECCVâ02}
}

@inproceedings{RefWorks:311,
	author={O. Nierstrasz and A. Bergel and M. Denker and S. Ducasse and M. Galli and R. Wuyts},
	year={2005},
	title={On the revival of dynamic languages},
	booktitle={Software Composition. 4th International Workshop, SC 2005. Revised Selected Papers, 9 April 2005},
	series={Software Composition. 4th International Workshop, SC 2005. Revised Selected Papers (Lecture Notes in Computer Science Vol. 3628)},
	publisher={Springer-Verlag},
	address={Edinburgh, UK},
	organization={Software Composition Group, Bern Univ., Switzerland},
	pages={1-13},
	abstract={The programming languages of today are stuck in a deep rut that has developed over the past 50 years. Although we are faced with new challenges posed by enormous advances in hardware and Internet technology, we continue to struggle with old-fashioned languages based on rigid, static, closed-world file-based views of programming. We argue the need for a new class of dynamic languages that support a view of programming as constant evolution of living and open software models. Such languages would require features such as dynamic first-class namespaces, explicit meta-models, optional, pluggable type systems, and incremental compilation of running software systems},
	keywords={high level languages; open systems},
	isbn={3 540 28748 5}
}

@inproceedings{RefWorks:312,
	author={Yehezkel Lamdan and Haim J. Wolfson},
	year={1988},
	title={Geometric hashing: A general and efficient model-based recognition scheme},
	booktitle={Second International Conference on Computer Vision, Dec 5-8 1988},
	publisher={Publ by IEEE, New York, NY, USA},
	address={Tampa, FL, USA},
	organization={New York Univ, New York, NY, USA},
	pages={238-249},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={A general method for model-based object recognition in occluded scenes is presented that is based on geometric hashing. The method stands out for its efficiency. The general framework of the method is described and its applications illustrated for various recognition problems both in 3-D and 2-D. Special attention is given to the recognition of 3-D objects in occluded scenes from 2-D gray-scale images. Experimental results are included for this important case.},
	keywords={Vision -- Artificial; Pattern Recognition; Image Processing},
	isbn={0-8186-0883-8}
}

@article{RefWorks:313,
	author={A. E. Johnson and M. Hebert},
	year={1998},
	month=jul,
	title={Surface matching for object recognition in complex three-dimensional scenes},
	journal={Image and Vision Computing},
	volume={16},
	number={9-10},
	pages={635-651},
	abstract={We present an approach to recognition of complex objects in cluttered three-dimensional (3D) scenes that does not require feature extraction or segmentation. Our object representation comprises descriptive images associated with oriented points on the surface of an object. Using a single point basis constructed from an oriented point, the position of other points on the surface of the object can be described by two parameters. The accumulation of these parameters for many points on the surface of the object results in an image at each oriented point. These images, localized descriptions of the global shape of the object, are invariant to rigid transformations. Through correlation of images, point correspondences between a model and scene data are established. Geometric consistency is used to group the correspondences from which plausible rigid transformations that align the model with the scene are calculated. The transformations are then refined and verified using a modified iterative closest point algorithm. The effectiveness of our representation comes from its ability to combine the descriptive nature of global object properties with the robustness to partial views and clutter of local shape descriptions. The wide applicability of our algorithm is demonstrated with results showing recognition of complex objects in cluttered scenes with occlusion},
	keywords={image matching; image representation; object recognition},
	isbn={0262-8856},
	url={http://dx.doi.org/10.1016/S0262-8856(98)00074-2}
}

@article{RefWorks:314,
	author={Chu-Song Chen and Yi-Ping Hung and Jen-Bo Cheng},
	year={1999},
	month=nov,
	title={RANSAC-based DARCES: a new approach to fast automatic registration of partially overlapping range images},
	journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
	volume={21},
	number={11},
	pages={1229-1234},
	abstract={In this paper, we propose a new method, the RANSAC-based DARCES method (data-aligned rigidity-constrained exhaustive search based on random sample consensus), which can solve the partially overlapping 3D registration problem without any initial estimation. For the noiseless case, the basic algorithm of our method can guarantee that the solution it finds is the true one, and its time complexity can be shown to be relatively low. An extra characteristic is that our method can be used even for the case that there are no local features in the 3D data sets},
	keywords={computational complexity; distance measurement; image registration; random processes; search problems},
	isbn={0162-8828},
	url={http://dx.doi.org/10.1109/34.809117}
}

@inproceedings{RefWorks:315,
	author={D. Nister},
	year={2003},
	title={Preemptive RANSAC for live structure and motion estimation},
	booktitle={ICCV 2003: 9th International Conference on Computer Vision, 13-16 Oct. 2003},
	series={Proceedings Ninth IEEE International Conference on Computer Vision},
	publisher={IEEE Comput. Soc},
	address={Nice, France},
	organization={Sarnoff Corp., Princeton, NJ, USA},
	volume={1},
	pages={199-206},
	abstract={A system capable of performing robust live ego-motion estimation for perspective cameras is presented. The system is powered by random sample consensus with preemptive scoring of the motion hypotheses. A general statement of the problem of efficient preemptive scoring is given. Then a theoretical investigation of preemptive scoring under a simple inlier-outlier model is performed. A practical preemption scheme is proposed and it is shown that the preemption is powerful enough to enable robust live structure and motion estimation},
	keywords={computer vision; motion estimation; random processes; video cameras},
	isbn={0 7695 1950 4}
}

@inproceedings{RefWorks:316,
	author={A. Gionis and P. Indyk and R. Motwani},
	year={1999},
	title={Similarity search in high dimensions via hashing},
	booktitle={Proceedings of 25th International Conference on Very Large Databases, 7-10 Sept. 1999},
	series={Very Large Data Bases. Proceedings of the Twenty-Fifth International Conference on Very Large Data Bases},
	publisher={Morgan Kaufmann Publishers},
	address={Edinburgh, UK},
	organization={Dept. of Comput. Sci., Stanford Univ., CA, USA},
	pages={518-529},
	note={\url{http://vldb.org/conf/1999/P49.pdf}},
	abstract={The nearest- or near-neighbor query problems arise in a large variety  of database applications, usually in the context of similarity  searching. Of Late, there has been increasing interest in building  search/index structures for performing similarity search over  high-dimensional data, e.g., image databases, document collections,  time-series databases, and genome databases. Unfortunately, all known  techniques for solving this problem fall prey to the &ldquo;curse  of dimensionality&rdquo;. That is, the data structures scale poorly  with data dimensionality; in fact, if the number of dimensions exceeds  10 to 20, searching in k-d trees and related structures involves the  inspection of a large fraction of the database, thereby doing no better  than brute-force linear search. It has been suggested that since the  selection of features and the choice of a distance metric in typical  applications is rather heuristic, determining an approximate nearest  neighbor should suffice for most practical purposes. We examine a novel  scheme for approximate similarity search based on hashing. The basic  idea is to hash the points from the database so as to ensure that the  probability of collision is much higher for objects that are close to  each other than for those that are far apart. We provide experimental  evidence that our method gives significant improvement in running time  over other methods for searching in high-dimensional spaces based on  hierarchical tree decomposition. Experimental results also indicate  that our scheme scales well even for a relatively large number of  dimensions (more than 50)},
	keywords={content-based retrieval; database indexing; database theory; probability; query formulation; tree data structures; visual databases}
}

@inproceedings{RefWorks:317,
	author={Bogdan Georgescu and Ilan Shimshoni and Peter Meer},
	year={2003},
	title={Mean shift based clustering in high dimensions: A texture classification example},
	booktitle={Proceedings: Ninth IEEE International Conference on Computer Vision, Oct 13-16 2003},
	series={Proceedings of the IEEE International Conference on Computer Vision},
	publisher={Institute of Electrical and Electronics Engineers Inc},
	address={Nice, France},
	organization={Computer Science, Electrical and Computer Engineering, Rutgers University, Piscataway, NJ 08854, United States},
	volume={1},
	pages={456-463},
	note={\url{http://www.caip.rutgers.edu/riul/research/papers/pdf/hims.pdf}},
	abstract={Feature space analysis is the main module in many computer vision tasks. The most popular technique, k-means clustering, however, has two inherent limitations: the clusters are constrained to be spherically symmetric and their number has to be known a priori. In nonparametric clustering methods, like the orfe based on mean shift, these limitations are eliminated but the amount of computation becomes prohibitively large as the dimension of the space increases. We exploit a recently proposed approximation technique, locality-sensitive hashing (LSH), to reduce the computational complexity of adaptive mean shift. In our implementation of LSH the optimal parameters of the data structure are determined by a pilot learning procedure, and the partitions are data driven. As an application, the performance of mode and k-means based textons are compared in a texture classification study.},
	keywords={Computer vision; Image analysis; Algorithms; Computational complexity; Approximation theory; Optimization; Data structures}
}

@article{RefWorks:323,
	author={Le Lu and Xiangtian Dai and Gregory Hager},
	year={2006},
	title={Efficient particle filtering using RANSAC with application to 3D face tracking},
	journal={Image and Vision Computing},
	volume={24},
	number={6},
	pages={581-592},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={Particle filtering is a very popular technique for sequential state estimation. However, in high-dimensional cases where the state dynamics are complex or poorly modeled, thousands of particles are usually required for real applications. This paper presents a hybrid sampling solution that combines RANSAC and particle filtering. In this approach, RANSAC provides proposal particles that, with high probability, represent the observation likelihood. Both conditionally independent RANSAC sampling and boosting-like conditionally dependent RANSAC sampling are explored. We show that the use of RANSAC-guided sampling reduces the necessary number of particles to dozens for a full 3D tracking problem. This method is particularly advantageous when state dynamics are poorly modeled. We show empirically that the sampling efficiency (in terms of likelihood) is much higher with the use of RANSAC. The algorithm has been applied to the problem of 3D face pose tracking with changing expression. We demonstrate the validity of our approach with several video sequences acquired in an unstructured environment. &copy; 2005 Elsevier B.V. All rights reserved.},
	keywords={Face recognition; Large scale systems; Dynamics; Probability; Algorithms; Image processing; Problem solving},
	isbn={0262-8856},
	url={http://dx.doi.org/10.1016/j.imavis.2005.08.003}
}

@article{RefWorks:324,
	author={Ido Leichter and Michael Lindenbaum and Ehud Rivlin},
	year={2006},
	title={A general framework for combining visual trackers - The "black boxes" approach},
	journal={International Journal of Computer Vision},
	volume={67},
	number={3},
	pages={343-363},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={Over the past few years researchers have been investigating the enhancement of visual tracking performance by devising trackers that simultaneously make use of several different features. In this paper we investigate the combination of synchronous visual trackers that use different features while treating the trackers as "black boxes". That is, instead of fusing the usage of the different types of data as has been performed in previous work, the combination here is allowed to use only the trackers' output estimates, which may be modified before their propagation to the next time step. We propose a probabilistic framework for combining multiple synchronous trackers, where each separate tracker outputs a probability density function of the tracked state, sequentially for each image. The trackers may output either an explicit probability density function, or a sample-set of it via CONDENSATION. Unlike previous tracker combinations, the proposed framework is fairly general and allows the combination of any set of trackers of this kind, even in different state-spaces of different dimensionality, under a few reasonable assumptions. The combination may consist of different trackers that track a common object, as well as trackers that track separate, albeit related objects, thus improving the tracking performance of each object. The benefits of merely using the final estimates of the separate trackers in the combination are twofold. Firstly, the framework for the combination is fairly general and may be easily used from the software aspects. Secondly, the combination may be performed in a distributed setting, where each separate tracker runs on a different site and uses different data, while avoiding the need to share the data. The suggested framework was successfully tested using various state-spaces and datasets, demonstrating that fusing the trackers' final distribution estimates may indeed be applicable. &copy; 2006 Springer-Science + Business Media, Inc.},
	keywords={Computer vision; Tracking (position); Research; Probabilistic logics; Probability density function; Data reduction; Kalman filtering; Condensation},
	isbn={0920-5691},
	url={http://dx.doi.org/10.1007/s11263-006-5568-2}
}

@article{RefWorks:325,
	author={Theodore Pachidis and John Lygouras and Vasilios Petridis},
	year={2002},
	title={A novel corner detection algorithm for camera calibration and calibration facilities},
	journal={Recent Advances in Circuits, Systems and Signal Processing},
	pages={338-343},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={A novel corner detection algorithm is presented which can be used to camera calibration methods where square comers are used as control points. Corners are detected with sub-pixel accuracy, using a segmentation method for separation of each square, based on seeds. These are pixels with a predefined color or gray value. An 11&times;11 proper developed template, including pixels of the predefined color or gray value, convoluted with the corresponding square gives pixels related with a corner. The mean value of this cluster of pixels provides with sub-pixel accuracy the co-ordinates of the specified corner. Corners co-ordinates are calculated with the specified sequence of the camera calibration method. Corners are found even in cases where the square slope is big or the barrel phenomenon distorts too much the image. The software interface was made in visual C++. Some of its features are the possibility to change the scanning area making the algorithm faster or more reliable, saving facilities for the converted binary image and for the final corners file, model file creation. This program is part of a software application where images can be easily captured using a camera mounted on the end effector of PUMA 761 robotic manipulator and calibration is made through Z. Zhang method using a novel easy selectable data files method which is provided with the same program.},
	keywords={Cameras; Calibration; Image processing; Interfaces (computer); Computer software; Scanning; Robot applications; Manipulators; Pattern matching; Computational geometry; Algorithms},
	isbn={9608052645}
}

@techreport{RefWorks:326,
	author={Chang Shu and Alan Brunton and Mark Fiala},
	title={CAMcal: A Program for Camera Calibration Using Checkerboard Patterns},
	institute={Institute for Information Technology, National Research Counsil Canada},
	note={\url{http://lear.inrialpes.fr/people/triggs/events/iccv03/cdrom/demos/shu.pdf}}
}

@article{RefWorks:327,
	author={Eduardo Bayro-Corrochano and Refugio Vallejo},
	year={2003},
	title={Geometric preprocessing and neurocomputing for pattern recognition and pose estimation},
	journal={Pattern Recognition},
	volume={36},
	number={12},
	pages={2909-2926},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={This paper shows the analysis and design of feed-forward neural networks using the coordinate-free system of Clifford or geometric algebra. It is shown that real-, complex- and quaternion-valued neural networks are simply particular cases of the geometric algebra multidimensional neural networks and that they can be generated using Support Multi-Vector Machines. Particularly, the generation of RBF for neurocomputing in geometric algebra is easier using the SMVM that allows to find the optimal parameters automatically. The use of SVM in the geometric algebra framework expands its sphere of applicability for multidimensional learning. We introduce a novel method of geometric preprocessing utilizing hypercomplex or Clifford moments. This method is applied together with geometric MLPs for tasks of 2D pattern recognition. Interesting examples of non-linear problems like the grasping of an object along a non-linear curve and the 3D pose recognition show the effect of the use of adequate Clifford or geometric algebras that alleviate the training of neural networks and that of Support Multi-Vector Machines. &copy; 2003 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.},
	keywords={Pattern recognition; Feedforward neural networks; Parameter estimation; Geometry},
	isbn={0031-3203},
	url={http://dx.doi.org/10.1016/S0031-3203(03)00179-1}
}

@inproceedings{RefWorks:328,
	author={Heinz Worn and Ferdinand Schmoeckel and Axel Buerkle and Josep Samitier and Manel Puig-Vidal and Stefan Johansson and Urban Simu and Jorg-Uwe Meyer and Margit Biehl},
	year={2001},
	title={From decimeter- to centimeter-sized mobile microrobots - The development of the MINIMAN system},
	booktitle={Microrobotics and Microassembly III, Oct 29-30 2001},
	series={Proceedings of SPIE - The International Society for Optical Engineering},
	publisher={The International Society for Optical Engineering},
	address={Newton, MA, United States},
	organization={Inst. for Proc. Control and Robotics, Universitat Karlsruhe (TH), 76128 Karlsruhe, Germany},
	volume={4568},
	pages={175-186},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={Based on small mobile robots the presented MINIMAN system provides a platform for micro-manipulation tasks in very different kinds of applications. Three exemplary applications demonstrate the capabilities of the system. Both the high precision assembly of an optical system consisting of three millimeter-sized parts and the positioning of single 20-&mu;m-cells under the light microscope as well as the handling of tiny samples inside the scanning electron microscope are done by the same kind of robot. For the different tasks, the robot is equipped with appropriate tools such as micropipettes or grippers with force and tactile sensors. For the extension to a multi-robot system, it is necessary to further reduce the size of robots. For the above mentioned robot prototypes a slip-stick driving principle is employed. While this design proves to work very well for the described decimeter-sized robots, it is not suitable for further miniaturized robots because of their reduced inertia. Therefore, the developed centimeter-sized robot is driven by multilayered piezoactuators performing defined steps without a slipping phase. To reduce the number of connecting wires the microrobot has integrated circuits on board. They include high voltage drivers and a serial communication interface for a minimized number of wires.},
	keywords={Mobile robots; Micromanipulators; Robotic assembly; Optical systems; Grippers; Microsensors; Scanning electron microscopy; User interfaces},
	isbn={0277-786X},
	url={http://dx.doi.org/10.1117/12.444124}
}

@article{RefWorks:329,
	author={H. WÃ¶rn and A. BÃ¼rkle},
	year={1999},
	title={Kamera-basiertes Sensorsystem eines mobilen Mikroroboters},
	journal={Informatik Aktuell},
	pages={88-97}
}

@article{RefWorks:330,
	author={J. Buhler},
	year={2001},
	title={Efficient large-scale sequence comparison by locality-sensitive hashing},
	journal={Bioinformatics},
	volume={17},
	number={5},
	pages={419-428}
}

@article{RefWorks:333,
	author={Mauricio Orozco-Alzate and Cesar German Castellanos-Dominguez},
	year={2006},
	title={Comparison of the nearest feature classifiers for face recognition},
	journal={Machine Vision and Applications},
	volume={17},
	number={5},
	pages={279-285},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={This paper presents an experimental comparison of the nearest feature classifiers, using an approach based on binomial tests in order to evaluate their strengths and weaknesses. In addition, classification accuracies and the accuracy-dimensionality tradeoff have been considered as comparison criteria. We extend two of the nearest feature classifiers to label the query point by a majority vote of the samples. Comparisons were carried out for face recognition using ORL database. We apply the eigenface representation for feature extraction. Experimental results showed that even though the classification accuracy of k-NFP outperforms k-NFL in some dimensions, these rate differences do not have statistical significance.},
	keywords={Face recognition; Computer vision; Classification (of information); Feature extraction; Query languages; Database systems; Statistical methods},
	isbn={0932-8092},
	url={http://dx.doi.org/10.1007/s00138-006-0037-z}
}

@article{RefWorks:335,
	author={M. Kass and A. Witkin and D. Terzopoulos},
	year={1987},
	title={Snakes: active contour models},
	journal={International Journal of Computer Vision},
	volume={1},
	number={4},
	pages={321-331},
	abstract={A snake is an energy-minimizing spline guided by external constraint forces and influenced by image forces that pull it toward features such as lines and edges. Snakes are active contour models: they lock onto nearby edges, localizing them accurately. Scale-space continuation can be used to enlarge the capture region surrounding a feature. Snakes provide a unified account of a number of visual problems, including detection of edges, lines, and subjective contours; motion tracking; and stereo matching},
	keywords={computer vision},
	isbn={0920-5691}
}

@inproceedings{RefWorks:336,
	author={Demetri Terzopoulos and John Platt and Alan Barr and Kurt Fleischer},
	year={1987},
	month=jul,
	title={Elastically Deformable Models},
	volume={21},
	chapter={4},
	pages={205-210}
}

@inproceedings{RefWorks:337,
	author={M. Brown and D. G. Lowe},
	year={2003},
	title={Recognising panoramas},
	booktitle={NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, Oct 13-16 2003},
	series={Proceedings of the IEEE International Conference on Computer Vision},
	publisher={Institute of Electrical and Electronics Engineers Inc},
	address={Nice, France},
	organization={Department of Computer Science, University of British Columbia, Vancouver, BC, Canada},
	volume={2},
	pages={1218-1225},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={The problem considered in this paper is the fully automatic construction of panoramas. Fundamentally, this problem requires recognition, as we need to know which parts of the panorama join up. Previous approaches have used human input or restrictions on the image sequence for the matching step. In this work we use object recognition techniques based on invariant local features to select matching images, and a probabilistic model for verification. Because of this our method is insensitive to the ordering, orientation, scale and illumination of the images. It is also insensitive to 'noise' images which are not part of the panorama at all, that is, it recognises panoramas. This suggests a useful application for photographers: the system takes as input the images on an entire flash card or film, recognises images that form part of a panorama, and stitches them with no user input whatsoever.},
	keywords={Object recognition; Pattern matching; Probability; Mathematical models; Image analysis; Computational geometry; Cameras; Feature extraction; Computational complexity; Algorithms},
	url={http://dx.doi.org/10.1109/ICCV.2003.1238630}
}

@article{RefWorks:338,
	author={Jaime Ortegon-Aguilar and Eduardo Bayro-Corrochano},
	year={2006},
	title={Lie algebra and system identification techniques for 3D rigid motion estimation and monocular tracking},
	journal={Journal of Mathematical Imaging and Vision},
	volume={25},
	number={2},
	pages={173-185},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={This paper addresses the parameters' estimation of 2D and 3D transformations. For the estimation we present a method based on system identification theory, we named it the "A-method". The transformations are considered as elements of the Lie group GL(n) or one of its subgroups. We represent the transformations in terms of their Lie Algebra elements. The Lie algebra approach assures to follow the shortest path or geodesic in the involved Lie group. To prove the potencial of our method, two experiments are presented. The first one is a monocular estimation of 3D rigid motion of an object in the visual space. With this aim, the six parameters of the rigid motion are estimated based on measurements of the six parameters of the affine transformation in the image. Secondly, we present the estimation of the affine or projective transformations involved in monocular region tracking. &copy; Springer Science + Business Media, LLC 2006.},
	keywords={Motion estimation; Identification (control systems); Tracking (position); Object recognition; Algebra},
	isbn={0924-9907},
	url={http://dx.doi.org/10.1007/s10851-006-9697-6}
}

@article{RefWorks:339,
	author={Ishita De and Bhabatosh Chanda and Buddhajyoti Chattopadhyay},
	year={2006},
	title={Enhancing effective depth-of-field by image fusion using mathematical morphology},
	journal={Image and Vision Computing},
	volume={24},
	number={12},
	pages={1278-1287},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={Reduced depth-of-field (DOF) poses a problem in the light optical imaging system, since the objects present outside this zone appear blurry in the recorded image. The effective DOF of the sensor may be enhanced considerably without compromising the quality of the image by fusing images captured with different focused regions. This paper presents an image fusion technique suitable for combining multifocus images of a scene. The method employs morphological filters to select sharply focused regions from various images and then combines them together to reconstruct the image in which all the regions are properly focused. A performance measure based on image gradients is used to compare the results obtained by the proposed method with those obtained by other image fusion techniques. &copy; 2006 Elsevier B.V. All rights reserved.},
	keywords={Image processing; Mathematical morphology; Problem solving; Optical sensors; Adaptive filtering; Image reconstruction; Correlation methods},
	isbn={0262-8856},
	url={http://dx.doi.org/10.1016/j.imavis.2006.04.005}
}

@article{RefWorks:340,
	author={Thomas B. Moeslund and Adrian Hilton and Volker Kruger},
	year={2006},
	title={A survey of advances in vision-based human motion capture and analysis},
	journal={Computer Vision and Image Understanding},
	volume={104},
	number={2-3 SPEC ISS},
	pages={90-126},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={This survey reviews advances in human motion capture and analysis from 2000 to 2006, following a previous survey of papers up to 2000 [T.B. Moeslund, E. Granum, A survey of computer vision-based human motion capture, Computer Vision and Image Understanding, 81(3) (2001) 231-268.]. Human motion capture continues to be an increasingly active research area in computer vision with over 350 publications over this period. A number of significant research advances are identified together with novel methodologies for automatic initialization, tracking, pose estimation, and movement recognition. Recent research has addressed reliable tracking and pose estimation in natural scenes. Progress has also been made towards automatic understanding of human actions and behavior. This survey reviews recent trends in video-based human capture and analysis, as well as discussing open problems for future research to achieve automatic visual analysis of human movement. &copy; 2006 Elsevier Inc. All rights reserved.},
	keywords={Man machine systems; Surveying; Vision; Data acquisition; Computer vision; Visualization},
	isbn={1077-3142},
	url={http://dx.doi.org/10.1016/j.cviu.2006.08.002}
}

@article{RefWorks:341,
	author={R. Fergus and P. Perona and A. Zisserman},
	year={2007},
	title={Weakly Supervised Scale-Invariant Learning of Models for Visual Recognition},
	journal={International Journal of Computer Vision},
	volume={71},
	number={3},
	pages={273-231},
	abstract={We investigate a method for learning object categories in a weakly  supervised manner. Given a set of images known to contain the target  category from a similar viewpoint, learning is translation and  scale-invariant; does not require alignment or correspondence between  the training images, and is robust to clutter and occlusion. Category  models are probabilistic constellations of parts, and their parameters  are estimated by maximizing the likelihood of the training data. The  appearance of the parts, as well as their mutual position, relative  scale and probability of detection are explicitly described in the  model. Recognition takes place in two stages. First, a feature-finder  identifies promising locations for the modelâs parts. Second, the  category model is used to compare the likelihood that the observed  features are generated by the category model, or are generated by  background clutter. The flexible nature of the model is demonstrated by  results over six diverse object categories including geometrically  constrained categories (e.g. faces, cars) and flexible objects (such as  animals).}
}

@inproceedings{RefWorks:342,
	author={A. D. Jepson and D. J. Fleet and T. R. El-Maraghi},
	year={2001},
	title={Robust online appearance models for visual tracking},
	booktitle={Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001, 8-14 Dec. 2001},
	series={Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001},
	publisher={IEEE Comput. Soc},
	address={Kauai, HI, USA},
	organization={Dept. of Comput. Sci., Toronto Univ., Ont., Canada},
	volume={1},
	pages={415-422},
	abstract={We propose a framework for learning robust, adaptive appearance models to be used for motion-based tracking of natural objects. The approach involves a mixture of stable image structure, learned over long time courses, along with 2-frame motion information and an outlier process. An online EM-algorithm is used to adapt the appearance model parameters over time. An implementation of this approach is developed for an appearance model based on the filter responses from a steerable pyramid. This model is used in a motion-based tracking algorithm to provide robustness in the face of image outliers, such as those caused by occlusions. It also provides the ability to adapt to natural changes in appearance, such as those due to facial expressions or variations in 3D pose. We show experimental results on a variety of natural image sequences of people moving within cluttered environments},
	keywords={image sequences; motion estimation; optimisation; target tracking},
	isbn={0 7695 1272 0},
	url={http://dx.doi.org/10.1109/CVPR.2001.990505}
}

@article{RefWorks:343,
	author={T. F. Cootes and G. V. Wheeler and K. N. Walker and C. J. Taylor},
	year={2002},
	title={View-based active appearance models},
	journal={Image and Vision Computing},
	volume={20},
	number={9-10},
	pages={657-664},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={We demonstrate that a small number of 2D linear statistical models are sufficient to capture the shape and appearance of a face from a wide range of viewpoints. Such models can be used to estimate head orientation and track faces through large angles. Given multiple images of the same face we can learn a coupled model describing the relationship between the frontal appearance and the profile of a face. This relationship can be used to predict new views of a face seen from one view and to constrain search algorithms which seek to locate a face in multiple views simultaneously. &copy; 2002 Elsevier Science B.V. All rights reserved.},
	keywords={Face recognition; Image analysis; Statistical methods; Algorithms; Mathematical models},
	isbn={0262-8856},
	url={http://dx.doi.org/10.1016/S0262-8856(02)00055-0}
}

@article{RefWorks:344,
	author={Tom Drummond and Roberto Cipolla},
	year={2000},
	title={Application of lie algebras to visual servoing},
	journal={International Journal of Computer Vision},
	volume={37},
	number={1},
	pages={21-41},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={A novel approach to visual servoing is presented, which takes advantage of the structure of the Lie algebra of affine transformations. The aim of this project is to use feedback from a visual sensor to guide a robot arm to a target position. The target position is learned using the principle of 'teaching by showing' in which the supervisor places the robot in the correct target position and the system captures the necessary information to be able to return to that position. The sensor is placed in the end effector of the robot, the 'camera-in-hand' approach, and thus provides direct feedback of the robot motion relative to the target scene via observed transformations of the scene. These scene transformations are obtained by measuring the affine deformations of a target planar contour (under the weak perspective assumption), captured by use of an active contour, or snake. Deformations of the snake are constrained using the Lie groups of affine and projective transformations. Properties of the Lie algebra of affine transformations are exploited to provide a novel method for integrating observed deformations of the target contour. These can be compensated with appropriate robot motion using a non-linear control structure. The local differential representation of contour deformations is extended to allow accurate integration of an extended series of small perturbations. This differs from existing approaches by virtue of the properties of the Lie algebra representation which implicity embeds knowledge of the three-dimensional world within a two-dimensional image-based system. These techniques have been implemented using a video camera to control a 5 DoF robot arm. Experiments with this implementation are presented, together with a discussion of the results.},
	keywords={Computer vision; Matrix algebra; Mathematical transformations; Feedback; Sensors; Robotic arms; Tracking (position); End effectors; Nonlinear control systems; Perturbation techniques; Video cameras; Algorithms; Runge Kutta methods},
	isbn={0920-5691},
	url={http://dx.doi.org/10.1023/A:1008125412549}
}

@article{RefWorks:345,
	author={Gabriele Guidi and Bernard Frischer and Michele Russo and Alessandro Spinetti and Luca Carosso and Laura Loredana Micoli},
	year={2005},
	month={December, 2005},
	title={Three-dimensional acquisition of large and detailed cultural heritage objects},
	journal={Machine Vision and Applications},
	volume={17},
	number={6},
	pages={349-360},
	abstract={Cultural heritage digitization is  becoming more common every day, but the applications discussed in the  literature address mainly the digitization of objects at a resolution  proportional to the object size, using low resolution for large  artifacts such as buildings or large statues, and high resolution for  small detailed objects. The case studied in this paper concerns a huge  physical model of imperial Rome (16 Ã  17.5 m) whose extremely small  details forced the use of high resolution and low noise scanning, in  contrast with the long range needed. This paper gives an account of the  procedures and the technologies used for solving this âcontradictionâ.}
}

@article{RefWorks:346,
	author={De Angelis, Gregory C. and Izumi Ohzawa and Ralph D. Freeman},
	year={1995},
	title={Receptive-field dynamics in the central visual pathways},
	journal={Trends Neuroscience},
	volume={18},
	pages={451-458},
	abstract={Neurons in the central visual pathways process visual images within a  localized region of space and a restricted epoch of time. Although the  receptive field (RF) of a visually-responsive neuron is inherently a  spatiotemporal entity, most studies have focused exclusively on spatial  aspects of RF structure. Recently, however, the application of  sophisticated RF mapping techniques has enabled neurophysiologists to  characterize RFs in the joint domain of space and time. Studies  employing these techniques have revealed that neurons in the  geniculostriate pathway exhibit striking RF dynamics. For a majority of  cells, the spatial structure of the RF changes as a function of time;  thus, these RFs can be adequately characterized only in the space-time  domain. In this review, we focus on the spatiotemporal RF structure of  neurons in the lateral geniculate nucleus and primary visual cortex,  highlighting some of the implications of recent findings for  understanding early visual processing.}
}

@inproceedings{RefWorks:347,
	author={M. Brown and R. Szeliski and S. Winder},
	year=2005,
	month=jun,
	title={Multi-image matching using multi-scale oriented patches},
	booktitle={Proceedings. 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 20-25 June 2005},
	series={Proceedings. 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
	publisher={IEEE Comput. Soc},
	address={San Diego, CA, USA},
	organization={Dept. of Comput. Sci., British Columbia Univ., Canada},
	volume=1,
	pages={510-517},
	abstract={This paper describes a novel multi-view matching framework based on a new type of invariant feature. Our features are located at Harris corners in discrete scale-space and oriented using a blurred local gradient. This defines a rotationally invariant frame in which we sample a feature descriptor, which consists of an 8 &times; 8 patch of bias/gain normalised intensity values. The density of features in the image is controlled using a novel adaptive non-maximal suppression algorithm, which gives a better spatial distribution of features than previous approaches. Matching is achieved using a fast nearest neighbour algorithm that indexes features based on their low frequency Haar wavelet coefficients. We also introduce a novel outlier rejection procedure that verifies a pairwise feature match based on a background distribution of incorrect feature matches. Feature matches are refined using RANSAC and used in an automatic 2D panorama stitcher that has been extensively tested on hundreds of sample inputs},
	keywords={feature extraction; Haar transforms; image matching; wavelet transforms},
	isbn={0 7695 2372 2}
}

@article{RefWorks:348,
	author={C. G. Harris and M. Stephens},
	year={1988},
	title={A combined corner and edge detector},
	journal={Proceedings 4th Alvey Vision Conference},
	pages={147-151},
        url={http://www.csse.uwa.edu.au/~pk/Research/MatlabFns/Spatial/Docs/Harris/}
}

@techreport{RefWorks:349,
	author={Konstantinos G. Derpanis},
	year={2004},
	month={October 27},
	title={The Harris Corner Detector}
}

@article{RefWorks:350,
	author={P. Kovesi},
	year={1999},
	title={Image features from phase congruency},
	journal={Videre},
	volume={1},
	number={3},
	abstract={Image features such as step edges, lines, and Mach bands all give rise to points where the Fourier components of the image are maximally in phase. The use of phase congruency for marking features has significant advantages over gradient-based methods. Phase congruency is a dimensionless quantity that is invariant to changes in image brightness or contrast; hence, it provides an absolute measure of the significance of feature points, thus allowing the use of universal threshold values that can be applied over wide classes of images. This paper presents a new measure of phase congruency and shows how it can be calculated through the use of wavelets. The existing theory that has been developed for l-D signals is extended to allow the calculation of phase congruency in 2-D images. It is shown that, for good localization, it is important to consider the spread of frequencies present at a point of phase congruency. An effective method for identifying and compensating for the level of noise in an image is presented. Finally, it is argued that high-pass filtering should be used to obtain image information at different scales. With this approach, the choice of scale affects only the relative significance of features without degrading their localization},
	keywords={feature extraction; wavelet transforms},
	isbn={1089-2788}
}

@inproceedings{RefWorks:351,
	author={Peter Kovesi},
	year={2003},
	title={Phase Congruency Detects Corners and Edges},
	booktitle={DICTA},
	pages={309-318}
}

@article{RefWorks:352,
	author={F. Chabat and G. Z. Yang and D. M. Hansell},
	year={1999},
	month=aug,
	title={A corner orientation detector},
	journal={Image and Vision Computing},
	volume={17},
	number={10},
	pages={761-9},
	abstract={The paper introduces an operator for the detection of the true location and orientation of corners. Its strength in dealing with junctions as well as corners is demonstrated. With this method, corner points are detected as intensity patterns that are anisotropic along several directions. Pixels belonging to the arms of the detected corners are analysed, and a histogram search provides a measure of their dominant orientations. Based on a single derivative scheme proposed by G.Z. Yang et al. (1996), the approach has proved to be insensitive to noise and has been applied to both synthetic and real life images},
	keywords={edge detection; object detection; search problems},
	isbn={0262-8856},
	url={http://dx.doi.org/10.1016/S0262-8856(98)00150-4}
}

@inproceedings{RefWorks:353,
	author={Bruce D. Lucas and Takeo Kanade},
	year={1981},
	month=apr,
	title={An Iterative Image Registration Technique with an Application to Stereo Vision (IJCAI)},
	booktitle={Proceedings of the 7th International Joint Conference on Artificial Intelligence (IJCAI '81)},
	pages={674-679},
	note={note: A more complete version is available as Proceedings DARPA Image Understanding Workshop, April 1981, pp.121-130. When you refer to this work, please refer to the IJCAI paper.}
}

@article{RefWorks:354,
	author={C. Tomasi and T. Kanade},
	year={1992},
	month=nov,
	title={Shape and motion from image streams under orthography: a factorization method},
	journal={International Journal of Computer Vision},
	volume={9},
	number={2},
	pages={137-54},
	abstract={Inferring scene geometry and camera motion from a stream of images is possible in principle, but is an ill-conditioned problem when the objects are distant with respect to their size. The authors have developed a factorization method that can overcome this difficulty by recovering shape and motion under orthography without computing depth as an intermediate step. An image stream can be represented by the measurement matrix of the image coordinates of points tracked through frames. The authors show that under orthographic projection this matrix is of rank 3. Based on this observation, the factorization method uses the singular-value decomposition technique to factor the measurement matrix into two matrices which represent object shape and camera rotation respectively. Two of the three translation components are computed in a preprocessing stage. The method can also handle and obtain a full solution from a partially filled-in measurement matrix that may result from occlusions or tracking failures. The method gives accurate results, and does not introduce smoothing in either shape or motion. The authors demonstrate this with a series of experiments on laboratory and outdoor image streams, with and without occlusions},
	keywords={computer vision; image recognition; image sequences; matrix algebra; motion estimation; tracking},
	isbn={0920-5691}
}

@inproceedings{RefWorks:355,
	author={Jianbo Shi and Carlo Tomasi},
	year={1994},
	title={Good features to track},
	booktitle={Proceedings of the 1994 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, Jun 21-23 1994},
	series={Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
	publisher={Publ by IEEE, Los Alamitos, CA, USA},
	address={Seattle, WA, USA},
	organization={Cornell Univ, Ithaca, NY, USA},
	pages={593-600},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={No feature-based vision system can work unless good features can be identified and tracked from frame to frame. Although tracking itself is by and large a solved problem, selecting features that can be tracked well and correspond to physical points in the world is still hard. We propose a feature selection criterion that is optimal by construction because it is based on how the tracker works, and a feature monitoring method that can detect occlusions, disocclusions, and features that do not correspond to points in the world. These methods are based on a new tracking algorithm that extends previous Newton-Raphson style search methods to work under affine image transformations. We test performance with several simulations and experiments.},
	keywords={Computer vision; Algorithms; Image quality; Monitoring; Mathematical models; Optimization; Mathematical transformations; Image processing; Cameras; Approximation theory},
	isbn={1063-6919; 0-8186-5827-4}
}

@article{RefWorks:356,
	author={A. Huertas and G. Medioni},
	year={1986},
	title={Detection of intensity changes with subpixel accuracy using Laplacian-Gaussian masks},
	journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
	volume={PAMI-8},
	number={5},
	pages={651-64},
	abstract={A system is presented that takes a gray level image as input, locates edges with subpixel accuracy, and links them into lines. Edges are detected by finding zero-crossings in the convolution of the image with Laplacian-of-Gaussian (LoG) masks. The masks are decomposed exactly into a sum of two separate filters instead of the usual approximation by a difference of two Gaussians. Subpixel accuracy is obtained through the use of the facet model. It is noted that while the zero-crossings obtained from the full resolution image using a space constant &sigma; for the Gaussian are very similar to those obtained from the resol
ution image with pixel accuracy and a space constant of for the Gaussian, the processing times are very different. Finally, these edges are grouped into lines using the technique described by R. Nevatia and K.R. Babu (Comput. Graphics Image Proc., vol.13, p.257-69, 1980)},
	keywords={computerised pattern recognition; computerised picture processing; filtering and prediction theory},
	isbn={0162-8828},
        annote={Non-linear filter (set of masks) to detect zero-crossings}
}

@article{RefWorks:357,
	author={C. Bauer and A. Frink and R. Kreckel},
	year={2002},
	month=jan,
	title={Introduction to the GiNaC framework for symbolic computation within the C++ programming language},
	journal={Journal of Symbolic Computation},
	volume={33},
	number={1},
	pages={1-12},
	abstract={The traditional split into a low level language and a high level language in the design of computer algebra systems may become obsolete with the advent of more versatile computer languages. We describe GiNaC, a special-purpose system that deliberately denies the need for such a distinction. It is entirely written in C++ and the user can interact with it directly in that language. It was designed to provide efficient handling of multivariate polynomials, algebras and special functions that are needed for loop calculations in theoretical quantum field theory. It also bears some potential to become a more general purpose symbolic package},
	keywords={mathematics computing; symbol manipulation},
	isbn={0747-7171},
	url={http://dx.doi.org/10.1006/jsco.2001.0494}
}

@article{RefWorks:358,
	author={Stefan Weinzierl},
	year={2004},
	title={gTybalt - A free computer algebra system},
	journal={Computer Physics Communications},
	volume={156},
	number={2},
	pages={180-198},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={This article documents the free computer algebra system "gTybalt". The program is build on top of other packages, among others GiNaC, TeXmacs and Root. It offers the possibility of interactive symbolic calculations within the C++ programming language. Mathematical formulae are visualized using T0RW1S34RfeSDcfkexd09rT4E1RW1S34RfeSDcfkexd09rT4X fonts. &copy; 2003 Elsevier B.V. All rights reserved.},
	keywords={Computer science; Computer program listings; C (programming language); Websites; Object oriented programming; Computer software; Algebra; Perturbation techniques; Algorithms},
	isbn={0010-4655},
	url={http://dx.doi.org/10.1016/S0010-4655(03)00468-5}
}

@article{RefWorks:359,
	author={J. Vollinga},
	year={2006},
	title={GiNaC - Symbolic computation with C++},
	journal={Nuclear Instruments and Methods in Physics Research, Section A: Accelerators, Spectrometers, Detectors and Associated Equipment},
	volume={559},
	number={1 SPEC ISS},
	pages={282-284},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={We give an introduction to the C++ library GiNaC, which extends the C++ language by new objects and methods for the representation and manipulation of arbitrary symbolic expressions. &copy; 2005 Elsevier B.V. All rights reserved.},
	keywords={Computation theory; Computer programming languages; Codes (symbols); Computational methods},
	isbn={0168-9002},
	url={http://dx.doi.org/10.1016/j.nima.2005.11.155}
}

@article{RefWorks:360,
	author={Stefan Weinzierl},
	year={2002},
	title={Symbolic expansion of transcendental functions},
	journal={Computer Physics Communications},
	volume={145},
	number={3},
	pages={357-370},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={Higher transcendental function occur frequently in the calculation of Feynman integrals in quantum field theory. Their expansion in a small parameter is a non-trivial task. We report on a computer program which allows the systematic expansion of certain classes of functions. The algorithms are based on the Hopf algebra of nested sums. The program is written in C++ and uses the GiNaC library. &copy; 2002 Elsevier Science B.V. All rights reserved.},
	keywords={Quantum theory; Computer programming; Random access storage; Algorithms; Matrix algebra},
	isbn={0010-4655},
	url={http://dx.doi.org/10.1016/S0010-4655(02)00261-8}
}

@article{RefWorks:361,
	author={B. M. ter Haar Romeny},
	year={2002},
	title={Computer vision and Mathematica},
	journal={Computing and Visualization in Science},
	volume={5},
	number={1},
	pages={53-65},
	abstract={Computer vision algorithms are strongly based on advanced mathematical methods. Tools to efficiently develop new methods are increasingly based on computer algebra systems, such as Matlab, Maple and Mathematica. For rapid prototyping both symbolic as numerical capability is required. However, application to large datasets such as images has always been frustrated by the expensive use of memory or long computing times. Such programs have improved substantially in numerical data handling, making them an ideal tool for rapid prototyping in computer vision. This paper gives a short variety of examples of the use of Mathematica in computer vision research},
	keywords={computer vision; symbol manipulation},
	isbn={1432-9360},
	url={http://dx.doi.org/10.1007/s00791-002-0087-3}
}

@article{RefWorks:362,
	author={A. Dall'Osso},
	year={2006},
	month=feb,
	title={Computer algebra systems as mathematical optimizing compilers},
	journal={Science of Computer Programming},
	volume={59},
	number={3},
	pages={250-73},
	abstract={The role of computer algebra systems (CASs) is not limited to analyzing and solving mathematical and physical problems. They have also been used as tools in the development process of computer programs, starting from the specification and ending with the coding and testing phases. In this way one can exploit their powerful mathematical capacity during the development phases and, by the other way, take advantage of the speed performance of languages such as FORTRAN or C in the implementation. Among the mathematical features of CASs there are transformations allowing one to optimize the final code instructions. In this paper we show some kind of optimizations that can be done on new or existing algorithms, by extending some techniques that compilers apply currently to optimize the machine code. The results show that the CPU time taken by the optimized code is reduced by a factor that can reach 5. The optimizations are performed with a package built on a well known CAS: Mathematica. [All rights reserved Elsevier]},
	keywords={mathematics computing; optimising compilers; process algebra},
	isbn={0167-6423},
	url={http://dx.doi.org/10.1016/j.scico.2005.06.003}
}

@inproceedings{RefWorks:363,
	author={A. Z. Pinkus and S. Winitzki},
	year={2002},
	title={YACAS: a do-it-yourself symbolic algebra environment},
	booktitle={Artificial Intelligence, Automated Reasoning, and Symbolic Computation. Joint International Conferences AISC 2002 and Calculemus 2002. Proceedings, 1-5 July 2002},
	series={Artificial Intelligence, Automated Reasoning, and Symbolic Computation. Joint International Conferences AISC 2002 and Calculemus 2002. Proceedings (Lecture Notes in Computer Science Vol.2385)},
	publisher={Springer-Verlag},
	address={Marseille, France},
	pages={332-6},
	abstract={We describe the design and implementation of YACAS, a free computer algebra system under development. The system consists of a core interpreter and a library of scripts that implement symbolic algebra functionality. The interpreter provides a high-level weakly typed functional language designed for quick prototyping of computer algebra algorithms, but the language is suitable for all kinds of symbolic manipulation. It supports conditional term rewriting of symbolic expression trees, closures (pure functions) and delayed evaluation, dynamic creation of transformation rules, arbitrary-precision numerical calculations, and flexible user-defined syntax using infix notation. The library of scripts currently provides basic numerical and symbolic functionality. The main advantages of YACAS are: free (GPL) software; a flexible and easy-to-use programming language with a comfortable and adjustable syntax; cross-platform portability and small resource requirements; and extensibility},
	keywords={functional languages; functional programming; mathematics computing; program interpreters; public domain software; rewriting systems; symbol manipulation},
	isbn={3 540 43865 3}
}

@article{RefWorks:364,
	author={Richard J. Fateman},
	title={On the Design and Construction of Algebraic Manipulation Systems}
}

@inproceedings{RefWorks:365,
	author={R. J. Fateman},
	year={1996},
	title={Symbolic mathematics system evaluators},
	booktitle={Proceedings ISSAC '96: International Symposium on Symbolic and Algebraic Computation, 24-26 July 1996},
	series={ISSAC 96. Proceedings of the 1996 International Symposium on Symbolic and Algebraic Computation},
	publisher={ACM},
	address={Zurich, Switzerland},
	organization={Comput. Sci. Div., California Univ., Berkeley, CA, USA},
	pages={86-94},
	abstract={&ldquo;Evaluation&rdquo; of expressions and programs in a computer algebra system is central to every system, but inevitably fails to provide complete satisfaction. We explain the conflicting requirements, describe some solutions from current systems, and propose alternatives that might be preferable sometimes. The extended abstract introduces material from a more complete paper (Fateman, 1995) and survey of Axiom, Macsyma, Maple, Mathematica, with passing mention of other systems},
	keywords={mathematics computing; software packages; symbol manipulation},
	isbn={0 89791 796 0}
}

@article{RefWorks:366,
	author={A. C. Hearn and E. Schrufer},
	year={1995},
	month=jan,
	title={A computer algebra system based on order-sorted algebra},
	journal={Journal of Symbolic Computation},
	volume={19},
	number={1-3},
	pages={65-77},
	abstract={This paper presents the prototype design of an algebraic computation system that manipulates algebraic quantities as generic objects using order-sorted algebra as the underlying model. The resulting programs have a form that is closely related to the algorithmic description of a problem, but with the security of full type checking in a compact, natural style},
	keywords={mathematics computing; symbol manipulation},
	isbn={0747-7171},
	url={http://dx.doi.org/10.1006/jsco.1995.1005}
}

@article{RefWorks:367,
	author={R. J. Fateman},
	year={1972},
	title={Essays in Algebraic Simplification}
}

@article{RefWorks:368,
	author={B. Buchberger},
	year={1976},
	title={A theoretical basis for the reduction of polynomials to canonical forms},
	journal={SIGSAM Bull.},
	volume={10},
	number={3},
	pages={19-29},
	isbn={0163-5824},
	url={http://doi.acm.org/10.1145/1088216.1088219}
}

@book{RefWorks:369,
	author={Jacques Calmet},
	year={1996},
	title={Computer Algebra},
        url={http://iaks-www.ira.uka.de/iaks-calmet/vorlesungen/compalg00/ca96-1.ps.gz}
}

@article{RefWorks:370,
	author={G. Z. Yang and P. Burger and D. N. Firmin and S. R. Underwood},
	year={1996},
	month=mar,
	title={Structure adaptive anisotropic image filtering},
	journal={Image and Vision Computing},
	volume={14},
	number={2},
	pages={135-45},
	abstract={Noise filtering of images is essentially a smoothing process, and it is an issue that has been addressed for many years. The most commonly used low-pass filtering methods blur important image structures such as edges and lines, and thus reduce image contrast and damage image fidelity. This paper presents a structure adaptive anisotropic filtering technique with its application to processing magnetic resonance images. It differs from other techniques in that, instead of using local gradients as a means of controlling the anisotropism of filters, it uses both a local intensity orientation, and an anisotropic measure of level contours to control the shape and extent of the filter kernel. This ensures that corners and junctions are well preserved throughout the filtering process. The following two aspects of the proposed technique demonstrate the advantage of using this filtering method. Firstly, the use of local orientation detection provides a robust and convenient way for shaping the filter kernel. Secondly, the structural adaptiveness of the filtering process ensures that salient image features are non-symmetrically enhanced},
	keywords={adaptive filters; biomedical NMR; low-pass filters},
	isbn={0262-8856},
	url={http://dx.doi.org/10.1016/0262-8856(95)01047-5}
}

@article{RefWorks:371,
	author={Rene Vidal and Yi Ma},
	year={2006},
	title={A unified algebraic approach to 2-D and 3-D motion segmentation and estimation},
	journal={Journal of Mathematical Imaging and Vision},
	volume={25},
	number={3},
	pages={403-421},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={In this paper, we present an analytic solution to the problem of estimating an unknown number of 2-D and 3-D motion models from two-view point correspondences or optical flow. The key to our approach is to view the estimation of multiple motion models as the estimation of a single multibody motion model. This is possible thanks to two important algebraic facts. First, we show that all the image measurements, regardless of their associated motion model, can be fit with a single real or complex polynomial. Second, we show that the parameters of the individual motion model associated with an image measurement can be obtained from the derivatives of the polynomial at that measurement. This leads to an algebraic motion segmentation and estimation algorithm that applies to most of the two-view motion models that have been adopted in computer vision. Our experiments show that the proposed algorithm out-performs existing algebraic and factorization-based methods in terms of efficiency and robustness, and provides a good initialization for iterative techniques, such as Expectation Maximization, whose performance strongly depends on good initialization. &copy; 2006 Springer Science + Business Media, LLC.},
	keywords={Motion estimation; Image analysis; Algebra; Mathematical models; Polynomial approximation; Principal component analysis},
	isbn={0924-9907},
	url={http://dx.doi.org/10.1007/s10851-006-8286-z}
}

@inbook{RefWorks:372,
	author={F. Baader and W. Snyder},
	editor={Robinson,John A. and Voronkov,Andrei},
	year={2001},
	title={Unification Theory},
	series={Handbook of Automated Reasoning},
	publisher={Elsevier Science Publishers},
	pages={447-533}
}

@article{RefWorks:373,
	author={J. A. Robinson},
	year={1965},
	title={A Machine-Oriented Logic Based on the Resolution Principle},
	journal={Journal of the ACM},
	volume={12},
	number={1},
	pages={23-41}
}

@inbook{RefWorks:374,
	author={Volker Diekert},
	editor={Lothaire,M.},
	year={2002},
	title={Makanin's Algorithm},
	series={Algebraic Combinatorics on Words},
	publisher={Cambridge University Press},
	pages={387-442}
}

@misc{RefWorks:375,
  author = 	 {H.-G. GrÃ¤be},
  year = 	 {2006},
  title = 	 {EinfÃ¼hrung in das Symbolische Rechnen, Skript zum Kurs},
  note = 	 {\url{http://www.informatik.uni-leipzig.de/~graebe/skripte/esr06.pdf}}
}

@inproceedings{RefWorks:376,
	author={Manuel Bronstein},
	year={2000},
	title={Symbolic Integration Tutorial}
}

@article{RefWorks:377,
	author={W. S. Brown},
	year={1978},
	title={SUBRESULTANT PRS ALGORITHM},
	journal={ACM Transactions on Mathematical Software},
	volume={4},
	number={3},
	pages={237-249},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={Two earlier papers described the generalization of Euclid's algorithm to deal with the problem of computing the greatest common divisor (GCD) or the resultant of a pair of polynomials. A sequel to those two papers is presented here. First, notation is established and the fundamental theorem of resultant is restated without proof. A new formulation of the subresultant PRS algorithm is presented and illustrated with a familiar example. An improved PRS algorithm is reviewed and two further improvements are presented. Finally, the computing time of the algorithm is analyzed and compared with a determinant method.},
	keywords={COMPUTER PROGRAMMING},
	url={http://dx.doi.org/10.1145/355791.355795}
}


@article{RefWorks:378,
	author={M. Frigo and S. G. Johnson},
	year={2005},
	month=feb,
	title={The design and implementation of FFTW3},
	journal={Proceedings of the IEEE},
	volume={93},
	number={2},
	pages={216-31},
	abstract={FFTW is an implementation of the discrete Fourier transform (DFT) that adapts to the hardware in order to maximize performance. This paper shows that such an approach can yield an implementation that is competitive with hand-optimized libraries, and describes the software structure that makes our current FFTW3 version flexible and adaptive. We further discuss a new algorithm for real-data DFTs of prime size, a new way of implementing DFTs by means of machine-specific single-instruction, multiple-data (SIMD) instructions, and how a special-purpose compiler can derive optimized implementations of the discrete cosine and sine transforms automatically from a DFT algorithm},
	keywords={discrete cosine transforms; discrete Fourier transforms; mathematics computing; optimising compilers; parallel programming; software libraries},
	isbn={0018-9219},
	url={http://dx.doi.org/10.1109/JPROC.2004.840301}
}

@article{RefWorks:379,
	author={Christel-Loic Tisse and Hugh Durrant-Whyte and R. Andrew Hicks},
	year={2007},
	title={An optical navigation sensor for micro aerial vehicles},
	journal={Computer Vision and Image Understanding},
	volume={105},
	number={1},
	pages={21-29},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={This paper describes a catadioptric microsensor for multidirectional imaging and 3D egomotion computation. Inspired by the wide viewing angle of insects' compound eyes, we show how to extract egomotion information from spherical images. We demonstrate how reflective surfaces can be used for building a compact, multidirectional eye that enables to collect video from 60% of the full sphere. Some experiments performed on synthetic images (using a ray-tracing environment) are presented to validate the concept. We have called the resulting imaging system SICONS (SIngle Chip Optical Navigation Sensor). SICONS is intended for application in micro unmanned aerial vehicles (micro-UAVs) to develop their perceptive, visual guidance and motive abilities to move within the real world in the same way an insect does. &copy; 2006 Elsevier Inc. All rights reserved.},
	keywords={Optical sensors; Unmanned vehicles; Imaging techniques; Computation theory; Ray tracing; Information analysis},
	isbn={1077-3142},
	url={http://dx.doi.org/10.1016/j.cviu.2006.07.004}
}

@misc{RefWorks:380,
	author={MarÃ­a Cristina Pereyra and Martin J. Mohlenkamp},
	year={2004},
	month=jun,
	title={Wavelets, their friends, and what they can do for you},
        url={http://www.math.ohiou.edu/~mjm/20044/PASIII/}
}

@inproceedings{RefWorks:381,
	author={T. BÃ¼low and G. Sommer},
	year={1998},
        month=aug,
	title={Quaternionic gabor filters for local structure classification},
	booktitle={Proceedings Fourteenth International Conference on Pattern Recognition, 16-20 Aug. 1998},
	series={Proceedings. Fourteenth International Conference on Pattern Recognition (Cat. No.98EX170)},
	publisher={IEEE Comput. Soc},
	address={Brisbane, Qld., Australia},
	organization={Kiel Univ., Germany},
	volume={1},
	pages={808-10},
	abstract={We introduce quaternionic Gabor filters for the classification of local image structure. These filters are constructed as windowed basis functions of the quaternionic Fourier transform. We show that-in contrast to the 2D complex Gabor filters-the quaternionic Gabor filters are intrinsically 2D filters. A generalized phase concept is introduced and compared to the classical one. It is shown how local image structure can be classified by the value of the local quaternionic phase},
	keywords={algebra; filtering theory; Fourier transforms; image classification; signal representation},
	isbn={0 8186 8512 3},
	url={http://dx.doi.org/10.1109/ICPR.1998.711271}
}

@inproceedings{RefWorks:382,
	author={Wai Lam Chan and Hyeokho Choi and Richard Baraniuk},
	year={2004},
        month=oct,
	title={Quaternion wavelets for image analysis and processing},
	booktitle={2004 International Conference on Image Processing, ICIP 2004, Oct 18-21 2004},
	series={Proceedings - International Conference on Image Processing, ICIP},
	publisher={Institute of Electrical and Electronics Engineers Computer Society, Piscataway, NJ 08855-1331, United States},
	address={Singapore},
	organization={Department of Electrical and Computer Engineering, Rice University, Houston, TX, United States},
	volume={2},
	pages={3057-3060},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={Using the concepts of two-dimensional Hilbert transform and analytic signal, we construct a new quaternion wavelet transform (QWT). The QWT forms a tight frame and can be efficiently computed using a 2-D dual-tree filter bank. The QWT and the 2-D complex wavelet transform (CWT) are related by a unitary transformation, but the former inherits the quaternion Fourier transform (QFT) phase properties, which are desirable for image analysis. The quaternion magnitude-phase representation of the QWT directly leads to near shift-invariance and the ability to encode phase shifts in an absolute xy-coordinate system, which we can use for applications such as edge estimation and statistical image modeling. &copy;2004 IEEE.},
	keywords={Image analysis; Signal processing; Edge detection; Wavelet transforms; Trees (mathematics); Statistical methods; Mathematical models},
	isbn={1522-4880}
}

@inproceedings{RefWorks:384,
	author={Wai Lam Chan and Hyeokho Choi and Richard G. Baraniuk},
	year={2004},
        month=may,
	title={Directional hypercomplex wavelets for multidimensional signal analysis and processing},
	booktitle={Proceedings - IEEE International Conference on Acoustics, Speech, and Signal Processing, May 17-21 2004},
	series={ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
	publisher={Institute of Electrical and Electronics Engineers Inc., Piscataway, NJ 08855-1331, United States},
	address={Montreal, Que, Canada},
	organization={Department of Electrical Engineering, Rice University, Houston, TX, United States},
	volume={3},
	pages={996-999},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={We extend the wavelet transform to handle multidimensional signals that are smooth save for singularities along lower-dimensional manifolds. We first generalize the complex wavelet transform to higher dimensions using a multidimensional Hilbert transform. Then, using the resulting hypercomplex wavelet transform (HWT) as a building block, we construct new classes of nearly shift-invariant wavelet frames that are oriented along lower-dimensional subspaces. The HWT can be computed efficiently using a 1-D dual-tree complex wavelet transform along each signal axis. We demonstrate how the HWT can be used for fast line detection in 3-D.},
	keywords={Signal processing; Natural frequencies; Wavelet transforms; Fourier transforms; Computational complexity; Tensors; Algorithms},
	isbn={1520-6149},
	url={http://dx.doi.org/10.1109/ICASSP.2004.1326715}
}

@article{RefWorks:385,
	author={N. Kingsbury},
	year={1999},
	title={Image processing with complex wavelets},
	journal={Philosophical Transactions of the Royal Society London, Series A (Mathematical, Physical and Engineering Sciences)},
	volume={357},
	number={1760},
	pages={2543-60},
	abstract={We first review how wavelets may be used for multi-resolution image processing, describing the filter-bank implementation of the discrete wavelet transform (DWT) and how it may be extended via separable filtering for processing images and other multi-dimensional signals. We then show that the condition for inversion of the DWT (perfect reconstruction) forces many commonly used wavelets to be similar in shape, and that this shape produces severe shift dependence (variation of DWT coefficient energy at any given scale with shift of the input signal). It is also shown that separable filtering with the DWT prevents the transform from providing directionally selective filters for diagonal image features. Complex wavelets can provide both shift invariance and good directional selectivity, with only modest increases in signal redundancy and computation load. However, development of a complex wavelet transform (CWT) with perfect reconstruction and good filter characteristics has proved difficult until recently. We now propose the dual-tree CWT as a solution to this problem, yielding a transform with attractive properties for a range of signal and image processing applications, including motion estimation, denoising, texture analysis and synthesis, and object segmentation},
	keywords={discrete wavelet transforms; image processing},
	isbn={1364-503X},
	url={http://dx.doi.org/10.1098/rsta.1999.0447}
}

@article{RefWorks:386,
	author={N. Kingsbury},
	year={2001},
	title={Complex wavelets for shift invariant analysis and filtering of signals},
	journal={Applied and Computational Harmonic Analysis},
	volume={10},
	number={3},
	pages={234-253},
	note={Journal, Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={This paper describes a form of discrete wavelet transform, which generates complex coefficients by using a dual tree of wavelet filters to obtain their real and imaginary parts. This introduces limited redundancy (20RW1S34RfeSDcfkexd09rT3m1RW1S34RfeSDcfkexd09rT3 : 1 for m-dimensional signals) and allows the transform to provide approximate shift invariance and directionally selective filters (properties lacking in the traditional wavelet transform) while preserving the usual properties of perfect reconstruction and computational efficiency with good well-balanced frequency responses. Here we analyze why the new transform can be designed to be shift invariant and describe how to estimate the accuracy of this approximation and design suitable filters to achieve this. We discuss two different variants of the new transform, based on odd/even and quarter-sample shift (Q-shift) filters, respectively. We then describe briefly how the dual tree may be extended for images and other multi-dimensional signals, and finally summarize a range of applications of the transform that take advantage of its unique properties. &copy; 2001 Academic Press.},
	isbn={1063-5203},
	url={http://dx.doi.org/10.1006/acha.2000.0343}
}

@article{RefWorks:387,
	author={S. G. Mallat},
	year={1989},
	month=jul,
	title={A theory for multiresolution signal decomposition: the wavelet representation},
	journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
	volume={11},
	number={7},
	pages={674-93},
	abstract={Multiresolution representations are effective for analyzing the information content of images. The properties of the operator which approximates a signal at a given resolution were studied. It is shown that the difference of information between the approximation of a signal at the resolutions 20RW1S34RfeSDcfkexd09rT3j+11RW1S34RfeSDcfkexd09rT3 and 20RW1S34RfeSDcfkexd09rT3j1RW1S34RfeSDcfkexd09rT3 (where j is an integer) can be extracted by decomposing this signal on a wavelet orthonormal basis of 0RW1S34RfeSDcfkexd09rT2L1RW1S34RfeSDcfkexd09rT20RW1S34RfeSDcfkexd09rT321RW1S34RfeSDcfkexd09rT3(0RW1S34RfeSDcfkexd09rT2R1RW1S34RfeSDcfkexd09rT20RW1S34RfeSDcfkexd09rT3n1RW1S34RfeSDcfkexd09rT3), the vector space of measurable, square-integrable 0RW1S34RfeSDcfkexd09rT2n1RW1S34RfeSDcfkexd09rT2-dimensional functions. In 0RW1S34RfeSDcfkexd09rT2L1RW1S34RfeSDcfkexd09rT20RW1S34RfeSDcfkexd09rT321RW1S34RfeSDcfkexd09rT3(0RW1S34RfeSDcfkexd09rT2R1RW1S34RfeSDcfkexd09rT2), a wavelet orthonormal basis is a family of functions which is built by dilating and translating a unique function &psi;(0RW1S34RfeSDcfkexd09rT2x1RW1S34RfeSDcfkexd09rT2). This decomposition defines an orthogonal multiresolution representation called a wavelet representation. It is computed with a pyramidal algorithm based on convolutions with quadrature mirror filters. Wavelet representation lies between the spatial and Fourier domains. For images, the wavelet representation differentiates several spatial orientations. The application of this representation to data compression in image coding, texture discrimination and fractal analysis is discussed},
	keywords={data compression; encoding; pattern recognition; picture processing},
	isbn={0162-8828},
	url={http://dx.doi.org/10.1109/34.192463}
}

@article{RefWorks:388,
	author={E. Bayro-Corrochano},
	year={2005},
	title={Multi-resolution image analysis using the quaternion wavelet transform},
	journal={Numerical Algorithms},
	volume={39},
	number={1-3},
	pages={35-55},
	abstract={This paper presents the theory and practicalities of the quaternion wavelet transform. The contribution of this work is to generalize the real and complex wavelet transforms and to derive for the first time a quaternionic wavelet pyramid for multi-resolution analysis using the quaternion phase concept. The three quaternion phase components of the detail wavelet filters together with a confidence mask are used for the computation of a denser image velocity field which is updated through various levels of a multi-resolution pyramid. Our local model computes the motion by the linear evaluation of the disparity equations involving the three phases of the quaternion detail high-pass filters. A confidence measure singles out those regions where horizontal and vertical displacement can reliably be estimated simultaneously. The paper is useful for researchers and practitioners interested in the theory and applications of the quaternion wavelet transform},
	keywords={filtering theory; image motion analysis; image resolution; image sequences; wavelet transforms},
	isbn={1017-1398},
	url={http://dx.doi.org/10.1007/s11075-004-3619-8}
}

@inproceedings{RefWorks:389,
	author={Chunyan Xie and Marios Savvides and B. V. K. Vijaya Kumar},
	year={2005},
        month=mar,
	title={Quaternion correlation filters for face recognition in wavelet domain},
	booktitle={2005 IEEE International Conference on Acoustics, Speech, and Signal Processing, ICASSP '05, Mar 18-23 2005},
	series={ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
	publisher={Institute of Electrical and Electronics Engineers Inc., Piscataway, NJ 08855-1331, United States},
	address={Philadelphia, PA, United States},
	organization={Carnegie Mellon University, Department of Electrical and Computer Engineering, Pittsburgh, PA 15213, United States},
	volume={II},
	pages={85-88},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={In this paper, a new frequency domain face recognition method using wavelet decomposition and quaternion correlation filters is proposed. The wavelet decomposition of the face image leads to a wavelet subband representation, which contains four subband images corresponding to four orthogonal channels. These four subbands can be encoded into a 2-D quaternion number array. The quaternion correlation filter method is developed for performing pattern recognition on multichannel 2-D signal jointly. The proposed method has been shown to achieve significant improvement in face recognition results compared to traditional advanced correlation filter method for handling illumination variations of face images. We experimented with the CMU PIE database consisting of 65 people with 21 illumination variations per person, showing that our method can achieve close to 100\% recognition accuracy using just a single training image of a person under neutral frontal lighting and testing on all other un-seen harsh illuminations. &copy; 2005 IEEE.},
	keywords={Image analysis; Pattern recognition; Arrays; Wavelet transforms; Face recognition; Database systems; Lighting},
	isbn={1520-6149}
}

@inproceedings{RefWorks:390,
	author={Yi Xu and Jun Zhou and Guangtao Zhai},
	year={2006},
	title={2D phase-based matching in uncalibrated images},
	booktitle={2005 IEEE Workshop on Signal Processing Systems-Design and Implementation, 2-4 Nov. 2005},
	series={2005 IEEE Workshop on Signal Processing Systems-Design and Implementation (IEEE Cat. No.05TH8830C)},
	publisher={IEEE},
	address={Athens, Greece},
	organization={Inst. of Image Commun. \& Inf. Process., Shanghai Jiao Tong Univ., China},
	pages={325-30},
	abstract={A novel 2D phase-based matching approach is proposed to resolve the general stereo image matching problem. It is different from the current uncalibrated matching techniques, most of which obtain 2D dense disparity map after the epipolar geometry has been recovered. In this paper, the disparity is directly estimated by simply establishing correspondences between quaternionic phase structures of two QWF (quaternion wavelet filtered) images. Real and short-length biorthogonal wavelet bases are exploited to build linear-phase quaternion wavelet filters (LPQWFs). Once phases are extracted from the QWF image pair, the disparity estimation is formed as a minimization process of a cost function, which is formulated as a similarity measure for comparing quaternion wavelet phases. With regard to the mismatches near phase singularities, phase stability constraints are imposed on cost aggregation stage. And multi-scale matching strategy is introduced to avoid phase wrapping problem and improve convergence speed. The experimental results are encouraging in various image pairs},
	keywords={filtering theory; image matching; minimisation; stereo image processing; wavelet transforms},
	isbn={0 7803 9333 3}
}

@MastersThesis{RefWorks:391,
  author =       {Pancham Shukla},
  title =        {Complex wavelet transforms and their applications},
  school =       {University of Strathclyde},
  year =         {2003},
  note={\url{http://www.commsp.ee.ic.ac.uk/~pancham/MPHIL_THESIS.pdf}},
  address =   {Glasgow, Scotland}
}

@techreport{RefWorks:392,
	author={O. Egger and V. Vaerman and T. Ebrahimi},
	year={1997},
	title={Subband Image Coding - An Overview},
	institution={Ãcole Polytechnique FÃ©dÃ©rale De Lausanne, Department of Electrical Engineering, Signal Processing Laboratory},
	note={\url{http://citeseer.ist.psu.edu/59431.html}}
}

@article{RefWorks:393,
	author={M. J. T. Smith and T. P. Barnwell III},
	year={1986},
	month=jun,
	title={Exact reconstruction techniques for tree-structured subband coders},
	journal={IEEE Transactions on Acoustics, Speech and Signal Processing},
	volume={ASSP-34},
	number={3},
	pages={434-41},
	abstract={It is shown that it is possible to design tree-structured analysis/reconstruction systems which meet the sampling rate condition for use in subband coders and which result in exact reconstruction of the input signal. The conditions for exact reconstruction are developed and presented. It is shown that these conditions are not overly restrictive and that high quality frequency division may be performed in the analysis section. A filter design procedure is presented which allows high quality filters to be easily designed},
	keywords={digital filters; encoding; speech analysis and processing},
	isbn={0096-3518},
	url={http://dx.doi.org/10.1109/TASSP.1986.1164832}
}

@article{RefWorks:395,
	author={I. W. Selesnick},
	year={2001},
	month=jun,
	title={Hilbert transform pairs of wavelet bases},
	journal={IEEE Signal Processing Letters},
	volume={8},
	number={6},
	pages={170-3},
	abstract={This paper considers the design of pairs of wavelet bases where the wavelets form a Hilbert transform pair. The derivation is based on the limit functions defined by the infinite product formula. It is found that the scaling filters should be offset from one another by a half sample. This gives an alternative derivation and explanation for the result by Kingsbury (1999), that the dual-tree DWT is (nearly) shift-invariant when the scaling filters satisfy the same offset},
	keywords={filtering theory; Hilbert transforms; signal processing; wavelet transforms},
	isbn={1070-9908},
	url={http://dx.doi.org/10.1109/97.923042}
}

@article{RefWorks:396,
	author={I. W. Selesnick},
	year={2002},
	month=may,
	title={The design of approximate Hilbert transform pairs of wavelet bases},
	journal={IEEE Transactions on Signal Processing},
	volume={50},
	number={5},
	pages={1144-52},
	abstract={Several authors have demonstrated that significant improvements can be obtained in wavelet-based signal processing by utilizing a pair of wavelet transforms where the wavelets form a Hilbert transform pair. This paper describes design procedures, based on spectral factorization, for the design of pairs of dyadic wavelet bases where the two wavelets form an approximate Hilbert transform pair. Both orthogonal and biorthogonal FIR solutions are presented, as well as IIR solutions. In each case, the solution depends on an allpass filter having a flat delay response. The design procedure allows for an arbitrary number of vanishing wavelet moments to be specified. A Matlab program for the procedure is given, and examples are also given to illustrate the results},
	keywords={all-pass filters; FIR filters; Hilbert transforms; IIR filters; wavelet transforms},
	isbn={1053-587X},
	url={http://dx.doi.org/10.1109/78.995070}
}

@inproceedings{RefWorks:397,
	author={A. Abbas and T. D. Tran},
	year={2006},
	month={Oct},
	title={Multiplierless design of biorthogonal dual-Tree complex wavelet transform using lifting scheme},
	edition={Atlanta, GA.},
	pages={1605-1608}
}

@article{RefWorks:398,
	author={I. W. Selesnick and R. G. Baraniuk and N. C. Kingsbury},
	year={2005},
	month=nov,
	title={The dual-tree complex wavelet transform},
	journal={IEEE Signal Processing Magazine},
	volume={22},
	number={6},
	pages={123-51},
	abstract={The paper discusses the theory behind the dual-tree transform, shows how complex wavelets with good properties can be designed, and illustrates a range of applications in signal and image processing. The authors use the complex number symbol C in CWT to avoid confusion with the often-used acronym CWT for the (different) continuous wavelet transform. The four fundamentals, intertwined shortcomings of wavelet transform and some solutions are also discussed. Several methods for filter design are described for dual-tree CWT that demonstrates with relatively short filters, an effective invertible approximately analytic wavelet transform can indeed be implemented using the dual-tree approach},
	keywords={channel bank filters; image processing; wavelet transforms},
	isbn={1053-5888},
	url={http://dx.doi.org/10.1109/MSP.2005.1550194}
}

@article{RefWorks:399,
	author={R. Yu and H. Ozkaramanli},
	year={2006},
	month=jun,
	title={Hilbert transform pairs of biorthogonal wavelet bases},
	journal={IEEE Transactions on Signal Processing},
	volume={54},
	number={6},
	pages={2119-25},
	abstract={The forming of Hilbert transform pairs of biorthogonal wavelet bases of two-band filter banks is studied in this paper. We first derive necessary and sufficient conditions on the scaling filters that render two Hilbert transform pairs: one decomposition pair and one reconstruction pair. We show that the Hilbert transform pairs are achieved if and only if the decomposition scaling filter of one filter bank is half-sample delayed from that of the other filter bank; and the reconstruction scaling filter of the former is half-sample advanced from that of the latter. Hilbert transform pairs of wavelet bases are also characterized by equivalent relationships on the wavelet filters and the scaling functions associated with the two filter banks. An illustrative example is provided},
	keywords={channel bank filters; Hilbert transforms; wavelet transforms},
	isbn={1053-587X},
	url={http://dx.doi.org/10.1109/TSP.2006.874293}
}

@inbook{RefWorks:400,
	author={J. Parker},
	year={1997},
	title={Advanced Edge Detection Techniques},
	series={Algorithms for Image Processing and Computer Vision},
	pages={1-62},
	note={\url{http://www.cpsc.ucalgary.ca/Research/vision/501/edgedetect.pdf}}
}

@misc{RefWorks:401,
	author={Kaare Brandt Petersen and Michael Syskind Pedersen},
	year={2006},
	title={The Matrix Cookbook},
	note={\url{http://matrixcookbook.com/}}
}

@article{RefWorks:402,
	author={A. H. Sayed and T. Kailath},
	year={2001},
	title={A survey of spectral factorization methods},
	journal={Numerical linear algebra with applications},
	volume={8},
	number={6-7},
	pages={467-496},
	note={\url{http://citeseer.ist.psu.edu/sayed01survey.html}}
}

@inproceedings{RefWorks:403,
	author={I.W. Selesnick},
	year={2001},
        month=may,
	title={The design of Hilbert transform pairs of wavelet bases via the flat delay filter},
	booktitle={2001 IEEE International Conference on Acoustics, Speech, and Signal Processing. Proceedings, 7-11 May 2001},
	series={2001 IEEE International Conference on Acoustics, Speech, and Signal Processing. Proceedings (Cat. No.01CH37221)},
	publisher={IEEE},
	address={Salt Lake City, UT, USA},
	organization={Polytech. Univ., Brooklyn, NY, USA},
	volume={6},
	pages={3673-3676},
	note={Also available on CD-ROM in PDF format},
	abstract={This paper describes a simple procedure, based on spectral factorization, for the design of a pair of orthonormal wavelet bases where the two wavelets form a Hilbert transform pair. The two scaling filters respectively have the numerator and denominator of the flat delay all-pass filter as factors. The design procedure allows for an arbitrary number of zero wavelet moments to be specified. A Matlab program for the procedure is given, and examples are also given to illustrate the results},
	keywords={all-pass filters; delay filters; Hilbert transforms; signal resolution; spectral analysis; wavelet transforms},
	isbn={0 7803 7041 4},
	url={http://dx.doi.org/10.1109/ICASSP.2001.940639}
}

@inproceedings{RefWorks:404,
	author={Barry M. Trager},
	editor={R. D. Jenks},
	year={1976},
	title={Algebraic factoring and rational function integration},
	publisher={ACM press},
	pages={196-208}
}

@techreport{RefWorks:405,
	author={Arnold SchÃ¶nhage},
	year={1982},
	title={The fundamental theorem of algebra in terms of computational complexity},
	institution={Math. Inst. Univ. TÃ¼bingen},
	note={\url{http://www.informatik.uni-bonn.de/~schoe/fdthmrep.ps.gz}}
}

@book{RefWorks:406,
	author={W. H. Press and S. A. Teukolsky and W. T. Vetterling and B. P. Flannery},
	year={1992},
	title={Numerical Recipes in C: the Art of Scientific Computing},
	publisher={Cambridge University Press}
}

@article{RefWorks:407,
	author={T. BÃ¼low and G. Sommer},
	year={2001},
	month=nov,
	title={Hypercomplex signals-a novel extension of the analytic signal to the multidimensional case},
	journal={IEEE Transactions on Signal Processing},
	volume={49},
	number={1},
	pages={2844-52},
	note={M1: Copyright 2001, IEE; 1},
	abstract={The construction of Gabor's (1946) complex signal-which is also known as the analytic signal-provides direct access to a real one-dimensional (1-D) signal's local amplitude and phase. The complex signal is built from a real signal by adding its Hilbert transform-which is a phase-shifted version of the signal-as an imaginary part to the signal. Since its introduction, the complex signal has become an important tool in signal processing, with applications, for example, in narrowband communication. Different approaches to an n-D analytic or complex signal have been proposed in the past. We review these approaches and propose the hypercomplex signal as a novel extension of the complex signal to n-D. This extension leads to a new definition of local phase, which reveals information on the intrinsic dimensionality of the signal. The different approaches are unified by expressing all of them as combinations of the signal and its partial and total Hilbert transforms. Examples that clarify how the approaches differ in their definitions of local phase and amplitude are shown. An example is provided for the two-dimensional (2-D) hypercomplex signal, which shows how the novel phase concept can be used in texture segmentation},
	keywords={Hilbert transforms; image segmentation; image texture; multidimensional signal processing},
	isbn={1053-587X},
	url={http://dx.doi.org/10.1109/78.960432}
}

@article{RefWorks:408,
	author={I. Daubechies},
	year={1990},
	title={The wavelet transform, time-frequency localization and signal analysis},
	journal={IEEE Transactions on Information Theory},
	volume={36},
	pages={961-1005},
	note={M1: Copyright 1990, IEE; 5},
	abstract={Two different procedures for effecting a frequency analysis of a time-dependent signal locally in time are studied. The first procedure is the short-time or windowed Fourier transform; the second is the wavelet transform, in which high-frequency components are studied with sharper time resolution than low-frequency components. The similarities and the differences between these two methods are discussed. For both schemes a detailed study is made of the reconstruction method and its stability as a function of the chosen time-frequency density. Finally, the notion of time-frequency localization is made precise, within this framework, by two localization theorems},
	keywords={Fourier transforms; signal processing; transforms},
	isbn={0018-9448},
	url={http://dx.doi.org/10.1109/18.57199}
}

@book{RefWorks:409,
	author={G. H. Granlund and H. Knutsson},
	year={1995},
	title={Signal Processing for Computer Vision},
	publisher={Kluwer Academic Publishers},
	isbn={0 7923 9530 1}
}

@inproceedings{RefWorks:410,
	author={Hans Knutsson and Goesta H. Granlund},
	year={1989},
	month={Sep 6-8 1989},
	title={Spatio-temporal analysis using tensors},
	booktitle={Sixth Multidimensional Signal Processing Workshop},
	publisher={Publ by IEEE, Piscataway, NJ, USA},
	address={Pacific Grove, CA, USA},
	organization={Comput Vision Lab, Linkoping Univ, Linkoping, Swed},
	pages={11},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved},
	abstract={Summary form only given. A fundamental issue in the problem of finding an efficient algorithm for estimation of 3-D orientation is how 3-D orientation should be represented. A representation is regarded as suitable if it meets the three basic requirements of uniqueness, uniformity, and polar separability. A tensor representation suitable in the above sense has been obtained. The uniqueness requirement implies a mapping that maps all pairs of 3-D vectors x and -x onto the same tensor T. Uniformity implies that the mapping implicitly carries a definition of distance between 3-D planes (and lines) that is rotation invariant and monotone with the angle between the planes. Polar separability means that the norm of the representing tensor T is rotation invariant. One way to describe the mapping is that it maps a 3-D sphere into 6-D in such a way that the surface is uniformly stretched and all pairs of antipodal points map onto the same tensor. It has been demonstrated that the above mapping can be implemented by sampling the 3-D space using a specific class of symmetrically distributed quadrature filters.},
	keywords={Image Processing -- Image Analysis; Mathematical Techniques--Tensors; Computer Programming--Algorithms},
	url={http://dx.doi.org/10.1109/MDSP.1989.96989}
}

@article{RefWorks:411,
	author={Ingrid Daubechies},
	year={1990},
	title={Wavelet transform, time-frequency localization and signal analysis},
	journal={IEEE Transactions on Information Theory},
	volume={36},
	pages={961-1005},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved; 5},
	abstract={Two different procedures for effecting a frequency analysis of a time-dependent signal locally in time are studied. The first procedure is the short-time or windowed Fourier transform; the second is the wavelet transform, in which high-frequency components are studied with sharper time resolution than low-frequency components. The similarities and the differences between these two methods are discussed. For both schemes a detailed study is made of the reconstruction method and its stability as a function of the chosen time-frequency density. Finally, the notion of time-frequency localization is made precise, within this framework, by two localization theorems.},
	keywords={Spectrum Analysis; Mathematical Transformations--Fourier Transforms},
	isbn={0018-9448},
	url={http://dx.doi.org/10.1109/18.57199}
}

@article{RefWorks:412,
	author={W. Pantleon},
	year={2005},
	title={Retrieving orientation correlations in deformation structures from orientation maps},
	journal={Materials Science and Technology},
	volume={21},
	number={1},
	pages={1392-1396},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved; 2},
	abstract={Orientation information as obtained by electron back scattering diffraction in crystalline material is conventionally visualised in orientation maps with different colours representing different orientations. The possibility of resolving orientation inhomogeneities from such maps depends strongly on the selected colouring scheme. For gaining spatial information on the orientation distribution and retrieving orientation correlations within selected regions of an orientation map, an advanced evaluation scheme is presented. By determining the predominant rotation axis within individual grains of a deformed polycrystal and displaying the sign carrying disorientation angle, characteristic features of the deformation structure, as alternating orientation differences or orientation gradients, are resolved. &copy; 2005 Institute of Materials, Minerals and Mining.},
	keywords={Crystalline materials; Deformation; Crystal orientation; Electron diffraction; Backscattering; Rotation},
	isbn={0267-0836},
	url={http://dx.doi.org/10.1179/174328405X71657}
}

@article{RefWorks:413,
	author={S. L. Hahn and K. M. Snopek},
	year={2005},
	month={08},
	title={Wigner distributions and ambiguity functions of 2-D quaternionic and monogenic signals},
	journal={IEEE Transactions on Signal Processing},
	volume={53},
	pages={3111-28},
	note={M1: Copyright 2005, IEE; 8},
	abstract={The paper presents new notions of Wigner distributions and corresponding ambiguity functions defined by quaternionic Fourier transforms of correlation products of recently defined quaternionic and monogenic two-dimensional (2-D) signals. The properties of new defined Wigner distributions are compared with Wigner distributions of 2-D analytic signals with single-quadrant spectra. It is well known that Wigner distributions of complex signals are real functions. Differently, the Wigner distributions of quaternionic and monogenic signals may be quaternionic-valued functions. However, it may happen that some 2-D slices of 4-D Wigner distributions are real functions},
	keywords={Fourier transforms; multidimensional signal processing; Wigner distribution},
	isbn={1053-587X},
	url={http://dx.doi.org/10.1109/TSP.2005.851134}
}

@article{RefWorks:415,
	author={F. C. A. Fernandes and I. W. Selesnick and R. L. C. van Spaendonck and C. S. Burrus},
	year={2003},
	month=aug,
	title={Complex wavelet transforms with allpass filters},
	journal={Signal Processing},
	volume={83},
	pages={1689-706},
        publisher = {Elsevier North-Holland, Inc.},
	note={M1: Copyright 2004, IEE; 8},
	abstract={Complex discrete wavelet transforms (DWT) have significant advantages over real wavelet transforms for certain signal processing problems. Two approaches to the implementation of complex wavelet transforms have been proposed earlier. Both approaches require discrete-time allpass systems having approximately linear-phase and (fractional) delay. This paper compares the results when different allpass systems are used. In the earlier work, maximally flat delay allpass systems were used. In this paper, it is shown that an allpass system designed according to the minimax criterion yields improvements for the complex DWT},
	keywords={all-pass filters; channel bank filters; delays; discrete time filters; discrete wavelet transforms; linear phase filters; minimax techniques},
	isbn={0165-1684},
	url={http://dx.doi.org/10.1016/S0165-1684(03)00077-X}
}

@inproceedings{RefWorks:416,
	author={R. M. Corless and M. W. Giesbrecht and M. van Hoeij and I. S. Kotsireas and S. M. Watt},
	year={2001},
	month={22-25 July 2001},
	title={Towards factoring bivariate approximate polynomials},
	booktitle={Proceedings of 2001 International Symposium on Symbolic and Algebraic Computation},
	series={ISSAC 2001},
	publisher={ACM},
	address={London, Ont., Canada},
	organization={Res. Centre for Comput. Algebra, Univ. of Western Ontario, London, Ont., Canada},
	pages={85-92},
	note={M1: Copyright 2002, IEE; T3: ISSAC 2001. Proceedings of the 2001 International Symposium on Symbolic and Algebraic Computation},
	abstract={An algorithm is presented for factoring bivariate approximate polynomials over C[x,y]. Given a particular polynomial, the method constructs a nearby composite polynomial, if one exists, and its irreducible factors. Subject to a conjecture, the time to produce the factors is polynomial in the degree of the problem. This method has been implemented in Maple, and has been demonstrated to be efficient and numerically robust},
	keywords={computational complexity; polynomial approximation; symbol manipulation},
	isbn={1 58113 417 7},
	url={http://dx.doi.org/10.1145/384101.384114}
}

@book{RefWorks:417,
  title={Physiologie},
  edition={Fourth},
  author={P. Deetjen and E. J. Speckmann and J. Hescheler},
  year={2005},
  publisher={MÃ¼nchen: Urban \& Fischer}
}

@article{RefWorks:418,
	author={Wai Lam Chan and Hyeokho Choi and Richard G. Baraniuk},
	year={2006},
	title={Coherent Multiscale Image Processing using Quaternion Wavelets},
	journal={IEEE Transactions on Image Processing}
}

@inproceedings{RefWorks:419,
	author={I. W. Selesnick and Ke Yong Li},
	year={2003},
	month=nov,
	title={Video denoising using 2D and 3D dual-tree complex wavelet transforms},
	booktitle={Wavelets: application in Signal and Image Processing X},
	publisher={SPIE-Int. Soc. Opt. Eng},
	address={San Diego, CA, USA},
	organization={Polytech. Univ. Brooklyn, New York, NY, USA},
	volume={5207},
	pages={607-18},
	note={M1: Copyright 2004, IEE; T3: Proc. SPIE - Int. Soc. Opt. Eng. (USA); 1},
	abstract={The denoising of video data should take into account both temporal and spatial dimensions; however, true 3D transforms are rarely used for video denoising. Separable 3D transforms have artifacts that degrade their performance in applications. The paper describes the design and application of the non-separable oriented 3D dual-tree wavelet transform for video denoising. This transform gives a motion-based multi-scale decomposition for video - in its subbands, it isolates motion along different directions. In addition, we investigate the denoising of video using the 2D and 3D dual-tree oriented wavelet transforms, where the 2D transform is applied to each frame individually},
	keywords={image denoising; image motion analysis; trees (mathematics); video signal processing; wavelet transforms},
	isbn={0277-786X},
	url={http://dx.doi.org/10.1117/12.504896}
}

@inproceedings{RefWorks:420,
	author={E. Loupias and N. Sebe and S. Bres and J. -M Jolion},
	year={2000},
	month={Sep 10-13 2000},
	title={Wavelet-based salient points for image retrieval},
	booktitle={International Conference on Image Processing (ICIP 2000)},
	publisher={Institute of Electrical and Electronics Engineers Computer Society},
	address={Vancouver, BC},
	organization={Lab. Reconnaissance de Formes, INSA Lyon, France},
	volume={2},
	pages={518-521},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved; T3: IEEE International Conference on Image Processing},
	abstract={The use of interest points in content-based image retrieval allows image index to represent local properties of the image. Classic corner detectors can be used for this purpose. However, they have drawbacks when applied to various natural images for image retrieval, because visual features need not be corners and corners may gather in small regions. In this paper, we present a salient point detector that extract points where variations occur in the image, whether they are corner-like or not. The detector is based on wavelet transform to detect global variations as well as local ones. The wavelet-based salient points are evaluated for image retrieval with a retrieval system using texture features. In this experiment our method provides better retrieval performance comparing with other point detectors.},
	keywords={Image retrieval; Wavelet transforms; Variational techniques; Feature extraction; Content based retrieval; Edge detection; Visualization},
	url={http://dx.doi.org/10.1109/ICIP.2000.899469}
}

@article{RefWorks:421,
	author={Anil Anthony Bharath and Jeffrey Ng},
	year={2005},
	title={A steerable complex wavelet construction and its application to image denoising},
	journal={IEEE Transactions on Image Processing},
	volume={14},
	pages={948-959},
	note={Compilation and indexing terms, Copyright 2006 Elsevier Inc. All rights reserved; 7},
	abstract={This work addresses the design of a novel complex steerable wavelet construction, the generation of transform-space feature measurements associated with corner and edge presence and orientation properties, and the application of these measurements directly to image denoising. The decomposition uses pairs of bandpass filters that display symmetry and antisymmetry about a steerable axis of orientation. While the angular characterization of the bandpass filters is similar to those previously described, the radial characteristic is new, as is the manner of constructing the interpolation functions for steering. The complex filters have been engineered into a multirate system, providing a synthesis and analysis subband filtering system with good reconstruction properties. Although the performance of our proposed denoising strategy is currently below that of recently reported state-of-the-art techniques in denoising, it does compare favorably with wavelet coring approaches employing global thresholds and with an "Oracle" shrinkage technique, and presents a very promising avenue for exploring structure-based denoising in the wavelet domain. &copy; 2005 IEEE.},
	keywords={Image compression; Feature extraction; Wavelet transforms; Bandpass filters; Interpolation; Algorithms},
	isbn={1057-7149},
	url={http://dx.doi.org/10.1109/TIP.2005.849295}
}

@book{RefWorks:422,
	author={Erik Reinhard and Greg Ward and Sumanta Pattanaik and Paul Debevec},
	year={2006},
	title={High Dynamic Range Imaging: Acquisition, Display, and Image-Based Lighting},
	publisher={Morgan Kaufmann}
}

@misc{RefWorks:423,
	title={Eurographics 2005 Tutorial: High dynamic range techniques in graphics},
	note={\url{http://isg.cs.tcd.ie/eg2005/T7.html}}
}

@article{RefWorks:424,
	author={S. Todorovic and M. C. Nechyba},
	year={2007},
	month={04},
	title={Interpretation of complex scenes using dynamic tree-structure Bayesian networks},
	journal={Computer Vision and Image Understanding},
	volume={106},
	number={1},
	pages={71-84},
	note={M1: Copyright 2007, The Institution of Engineering and Technology},
	abstract={This paper addresses the problem of object detection and recognition in complex scenes, where objects are partially occluded. The approach presented herein is based on the hypothesis that a careful analysis of visible object details at various scales is critical for recognition in such settings. In general, however, computational complexity becomes prohibitive when trying to analyze multiple sub-parts of multiple objects in an image. To alleviate this problem, we propose a generative-model framework-namely, dynamic tree-structure belief networks (DTSBNs). This framework formulates object detection and recognition as inference of DTSBN structure and image-class conditional distributions, given an image. The causal (Markovian) dependencies in DTSBNs allow for design of computationally efficient inference, as well as for interpretation of the estimated structure as follows: each root represents a whole distinct object, while children nodes down the sub-tree represent parts of that object at various scales. Therefore, within the DTSBN framework, the treatment and recognition of object parts requires no additional training, but merely a particular interpretation of the tree/subtree structure. This property leads to a strategy for recognition of objects as a whole through recognition of their visible parts. Our experimental results demonstrate that this approach remarkably outperforms strategies without explicit analysis of object parts. [All rights reserved Elsevier]},
	keywords={belief networks; computational complexity; Markov processes; object detection; object recognition; trees (mathematics)},
	isbn={1077-3142},
	url={http://dx.doi.org/10.1016/j.cviu.2005.09.005}
}

@article{RefWorks:425,
	author={Cheng-en Guo and Song-Chun Zhu and Ying Nian Wu},
	year={2007},
	month={04},
	title={Primal sketch: Integrating structure and texture},
	journal={Computer Vision and Image Understanding},
	volume={106},
	number={1},
	pages={5-19},
	note={M1: Copyright 2007, The Institution of Engineering and Technology},
	abstract={This article proposes a generative image model, which is called "primal sketch," following Marr's insight and terminology. This model combines two prominent classes of generative models, namely, sparse coding model and Markov random field model, for representing geometric structures and stochastic textures, respectively. Specifically, the image lattice is divided into structure domain and texture domain. The sparse coding model is used to represent image intensities on the structure domain, where edge and ridge segments are modeled by image coding functions with explicit geometric and photometric parameters. The edge and ridge segments form a sketch graph whose nodes are corners and junctions. The sketch graph is governed by a simple spatial prior model. The Markov random field model is used to summarize image intensities on the texture domain, where the texture patterns are characterized by feature statistics in the form of marginal histograms of responses from a set of linear filters. The Markov random fields in-paint the texture domain while interpolating the structure domain seamlessly. A sketch pursuit algorithm is proposed for model fitting. A number of experiments on real images are shown to demonstrate the model and the algorithm. [All rights reserved Elsevier]},
	keywords={edge detection; geometry; image coding; image texture; Markov processes},
	isbn={1077-3142},
	url={http://dx.doi.org/10.1016/j.cviu.2005.09.004}
}

@article{RefWorks:426,
	author={E. Bayro-Corrochano and J. Ortegon-Aguilar},
	year={2007},
	month={06/01},
	title={Lie algebra approach for tracking and 3D motion estimation using monocular vision},
	journal={Image and Vision Computing},
	volume={25},
	number={6},
	pages={907-21},
	note={M1: Copyright 2007, The Institution of Engineering and Technology},
	abstract={The main purpose of this paper is to estimate 2D and 3D transformation parameters. All the group transformations are represented in terms of their Lie algebra elements. The Lie algebra approach assures to follow the shortest path or geodesic in the involved Lie group. For the estimation of the Lie algebra parameters, we take advantage of the theory of system identification. Two experiments are presented to show the potential of the method. First, we carry out the estimation of the affine or projective parameters related to the transformation involved in monocular region tracking. Second, we develop a monocular method to estimate 3D motion of an object in the visual space. In the latter, the six parameters of the rigid motion are estimated based on measurements of the six parameters of the affine transformation in the image. [All rights reserved Elsevier]},
	keywords={affine transforms; computer vision; least squares approximations; Lie algebras; Lie groups; motion estimation; optical tracking},
	isbn={0262-8856},
	url={http://dx.doi.org/10.1016/j.imavis.2006.07.005}
}

@article{RefWorks:427,
	author={E. Koller-Meier and M. Bray and L. Van Gool},
	year={2007},
	month={04},
	title={Smart particle filtering for high-dimensional tracking},
	journal={Computer Vision and Image Understanding},
	volume={106},
	number={1},
	pages={116-29},
	note={M1: Copyright 2007, The Institution of Engineering and Technology},
	abstract={Tracking articulated structures like a hand or body within a reasonable time is challenging because of the high-dimensionality of the state space. Recently, a new optimization method, called `Stochastic Meta-Descent' (SMD) has been introduced in computer vision. This is a gradient descent scheme with adaptive and parameter-specific step sizes able to operate in a constrained space. However, while the local optimization works very well, reaching the global optimum is not guaranteed. We therefore propose an enhanced algorithm that wraps a particle filter around multiple SMD-based trackers, which play the role of many particles, i.e. that act as `smart particles'. After the standard particle propagation on the basis of a simple motion model, SMD is performed and the resulting new particle set is included such that the original Bayesian distribution is not altered. The resulting `Smart Particle Filter' (SPF) tracks high-dimensional articulated structures with far fewer samples than previous methods. Additionally, it can handle multiple hypotheses and clutter, where pure optimization approaches have problems. Good performance is demonstrated for the case of hand tracking from 3D range data. [All rights reserved Elsevier]},
	keywords={Bayes methods; computer vision; gradient methods; particle filtering (numerical methods); stochastic processes},
	isbn={1077-3142},
	url={http://dx.doi.org/10.1016/j.cviu.2005.09.013}
}

@book{RefWorks:428,
	author={John H. Heinbockel},
	year={2001},
	title={Introduction to Tensor Calculus and Continuum Mechanics},
	publisher={Trafford Publishing},
	pages={432},
        url={http://www.math.odu.edu/~jhh/counter2.html}
}

@article{RefWorks:429,
	author={T. Serre and L. Wolf and S. Bileschi and M. Riesenhuber and T. Poggio},
	year={2007},
	month={03},
	title={Robust object recognition with cortex-like mechanisms},
	journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
	volume={29},
	number={3},
	pages={411-26},
	note={M1: Copyright 2007, The Institution of Engineering and Technology},
	abstract={We introduce a new general framework for the recognition of complex visual scenes, which is motivated by biology: We describe a hierarchical system that closely follows the organization of visual cortex and builds an increasingly complex and invariant feature representation by alternating between a template matching and a maximum pooling operation. We demonstrate the strength of the approach on a range of recognition tasks: From invariant single object recognition in clutter to multiclass categorization problems and complex scene understanding tasks that rely on the recognition of both shape-based as well as texture-based objects. Given the biological constraints that the system had to satisfy, the approach performs surprisingly well: It has the capability of learning from only a few training examples and competes with state-of-the-art systems. We also discuss the existence of a universal, redundant dictionary of features that could handle the recognition of most object categories. In addition to its relevance for computer vision, the success of this approach suggests a plausibility proof for a class of feedforward models of object recognition in cortex},
	keywords={computer vision; image matching; object recognition},
	isbn={0162-8828},
	url={http://dx.doi.org/10.1109/TPAMI.2007.56}
}

@inproceedings{RefWorks:430,
	author={P. Moreels and P. Perona},
	year={2005},
	month={17-21 Oct. 2005},
	title={Evaluation of features detectors and descriptors based on 3D objects},
	booktitle={Tenth IEEE International Conference on Computer Vision},
	series={Proceedings},
	publisher={IEEE Comput. Soc},
	address={Beijing, China},
	organization={California Inst. of Technol., Pasadena, CA, USA},
	volume={1},
	pages={800-7},
	note={M1: Copyright 2006, IEE; T3: Proceedings. Tenth IEEE International Conference on Computer Vision},
	abstract={We explore the performance of a number of popular feature detectors and descriptors in matching 3D object features across viewpoints and lighting conditions. To this end we design a method, based on intersecting epipolar constraints, for providing ground truth correspondence automatically. We collect a database of 100 objects viewed from 144 calibrated viewpoints under three different lighting conditions. We find that the combination of Hessian-affine feature finder and SIFT features is most robust to viewpoint change. Harris-affine combined with SIFT and Hessian-affine combined with shape context descriptors were best respectively for lighting changes and scale changes. We also find that no detector-descriptor combination performs well with viewpoint changes of more than 25-30&deg;},
	keywords={feature extraction; image matching; object detection; object recognition; stereo image processing},
	isbn={0 7695 2334 X}
}

@inproceedings{RefWorks:431,
	author={Jan Wedekind and Manuel Boissenin and Bala P. Amavasai and Fabio Caparrelli and Jon R. Travis},
	year={2006},
	title={Object Recognition and Real-Time Tracking in Microscope Imaging},
	series={Proceedings of the 2006 Irish Machine Vision and Image Processing Conference (IMVIP 2006)},
	address={Dublin City University},
	pages={164-171},
	url={http://www.rince.ie/imvip2006/proceedings.html;http://vision.eng.shu.ac.uk/jan/IMVIP_wedekind_CR.pdf}
}

@article{RefWorks:432,
	author={E. De Castro and C. Morandi},
	year={1987},
	title={Registration of translated and rotated images using finite Fourier transforms},
	journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
	volume={PAMI-9},
	number={5},
	pages={700-3},
	abstract={A well-known method for image registration is based on a conventional correlation between phase-only, or whitened, versions of the two images to be realigned. The method, covering rigid translational movements, is characterized by an outstanding robustness against correlated noise and disturbances, such as those encountered with nonuniform, time-varying illumination. The authors discuss an extension of the method to cover both translational and rotational movements},
	keywords={Fourier transforms; pattern recognition; picture processing},
	isbn={0162-8828}
}

@misc{RefWorks:433,
	author={Andrew E. Johnson},
	year={1997},
	title={Spin-images: A Representation for 3-D Surface Matching},
	note={\url{http://www.ri.cmu.edu/pubs/pub_559.html}}
}

@techreport{RefWorks:434,
	author={Salman S. Rogers and Thomas A. Waigh and Xiubo Zhao and Jian R. Lu},
	year={2007},
	title={Precise Particle Tracking Against a Complicated Background: Polynomial Fitting with Gaussian Weight},
	url={http://arxiv.org/abs/0707.3602v1}
}

@article{RefWorks:435,
	author={Jie He and Rongzhen Zhou and Zhiliang Hong},
	year={2003},
	month={05},
	title={Modified fast climbing search auto-focus algorithm with adaptive step size searching technique for digital camera},
	journal={IEEE Transactions on Consumer Electronics},
	volume={49},
	number={2},
	pages={257-62},
	abstract={A practical real-time auto-focus algorithm for a digital camera is presented, and it improves the reliability and speed of the auto-focus process, especially suitable for a mega-pixel high definition camera. The proposed algorithm adopts threshold gradient and edge point count technique besides focus value function, instead of the traditional two-stage climbing search algorithm that uses the focus value function only. Additionally, a relative difference ratio circuit is also proposed, which can implement adaptive step size searching to increase the searching speed. By adopting the modified algorithm on the prototype of our mega-pixel digital camera, the real-time auto-focus function is verified. The proposed algorithm is implemented in a test camera chip that has been manufactured in 0.25&mu;m CMOS digital process},
	keywords={cameras; CCD image sensors; consumer electronics; focusing; search problems},
	isbn={0098-3063},
	url={http://dx.doi.org/10.1109/TCE.2003.1209511}
}

@article{RefWorks:436,
	author={Yani Zhang and Ying Zhan and Changyun Wen},
	year={2000},
	title={A new focus measure method using moments},
	journal={Image and Vision Computing},
	volume={18},
	number={12},
	pages={959-65},
	abstract={In this paper, we propose a new simple yet effective focus measure method. By this method, focus information can be deduced from the 2nd- or 4th-order central moments of a sequence of images. The advantage of the moment-based method over existing schemes is that it gives an explicit expression of the parameter of the point spread function (PSF). After appropriate processing, we can get a curve which is independent of imaged objects and use it to express the blur property of the imaging system. Results obtained from simulation studies and a practical application demonstrate the effectiveness of the proposed method},
	keywords={image sequences; inspection; optical transfer function},
	isbn={0262-8856},
	url={http://dx.doi.org/10.1016/S0262-8856(00)00038-X}
}

@MastersThesis{RefWorks:437,
  author =       {Jan Wedekind},
  title =        {{F}okusserien-basierte {R}ekonstruktion von {M}ikroobjekten},
  school =       {University of Karlsruhe (TH)},
  year =         2002,
  month =        may,
  note =         {\url{http://digbib.ubka.uni-karlsruhe.de/volltexte/1872002}},
  annote =       {Meine Diplomarbeit}
}

@article{RefWorks:438,
	author={J. Wedekind and M. Boissenin and A. N. Selvan and B. P. Amavasai and F. Caparrelli and J. R. Travis},
	year={2007},
	month={07/01},
	title={Computer vision methods for optical microscopes},
	journal={Image and Vision Computing},
	volume={25},
	number={7},
	pages={1107-16},
	note={M1: Copyright 2007, The Institution of Engineering and Technology},
	abstract={As the fields of micro- and nano-technology mature, there will be an increased need to build tools that are able to work in these areas. Industry will require solutions for assembling and manipulating components, much as it has done in the macro range. With this need in mind, a new set of challenges requiring novel solutions have to be met. One of them is the ability to provide closed-loop feedback control for manipulators. We foresee that machine vision will play a leading role in this area. This paper introduces a technique for integrating machine vision into the field of micro-technology including two methods, one for tracking and one for depth reconstruction under an optical microscope. [All rights reserved Elsevier]},
	keywords={assembling; closed loop systems; computer vision; feedback; image reconstruction; micromanipulators; optical microscopes; optical tracking},
	isbn={0262-8856},
	url={http://dx.doi.org/10.1016/j.imavis.2006.03.009}
}

@inproceedings{RefWorks:439,
	author={H. Q. H. Viet and M. Sato and H. T. Tanaka},
	year={2004},
	month={6-9 Sept. 2004},
	title={Analysis of Three-dimensional motion of an object using a fixed monocular camera},
	booktitle={2nd International Symposium on 3D Data Processing, Visualization, and Transmission},
	series={Proceedings},
	publisher={IEEE Comput. Soc},
	address={Thessaloniki, Greece},
	organization={Dept. of Comput. Sci., Ritsumeikan Univ., Kusatsu, Japan},
	pages={223-30},
	note={M1: Copyright 2005, IEE; T3: Proceedings. 2nd International Symposium on 3D Data Processing, Visualization, and Transmission},
	abstract={The research on analysis of three-dimensional motion by using a monocular camera instead of a stereo camera has important applications for making the microscopes used in microbiology or constructing the autonomous robots used in various fields of industry. In this paper, we propose a fixed monocular camera whose focus changed cyclically to recognize three-dimensional absolute motion of a rigid object},
	keywords={image matching; image motion analysis; image restoration; image sampling; image sequences; object recognition; video cameras},
	isbn={0 7695 2223 8}
}

@book{RefWorks:440,
	author={V. B. Dr{\"o}scher},
	year={1975},
	title={Magie der Sinne im Tierreich},
	publisher={Dt. Taschenbuch-Verl.},
}


@misc{RefWorks:441,
  author = 	 {Eric Hamilton},
  year = 	 {1992},
  title = 	 {JPEG File Interchange Format},
  url = 	 {http://www.jpeg.org/public/jfif.pdf}
}

@article{RefWorks:442,
	author={T. OâReilly},
	year={2004},
	title={The Open Source Paradigm Shift},
	journal={OâReilly}
}

@article{RefWorks:443,
	author={J. -P Thiran},
	year={1971},
	month={11},
	title={Recursive digital filters with maximally flat group delay},
	journal={IEEE Transactions on Circuit Theory},
	volume={CT-18},
	number={6},
	pages={659-64},
	note={M1: Copyright 1972, IEE},
	abstract={A solution obtained by a direct approximation procedure in the 0RW1S34RfeSDcfkexd09rT2z1RW1S34RfeSDcfkexd09rT2 plane is given. The denominator of the transfer function turns out to be a Gaussian hypergeometric function, more particularly connected with the Legendre functions. The stability of the filters is discussed and some numerical results in regard to the amplitude and phase responses as well as on the pole loci are given},
	keywords={approximation theory; digital filters; stability},
	isbn={0018-9324}
}

@article{RefWorks:444,
	author={J. Magarey and N. Kingsbury},
	year={1998},
	month={04},
	title={Motion estimation using a complex-valued wavelet transform},
	journal={IEEE Transactions on Signal Processing},
	volume={46},
	number={4},
	pages={1069-84},
	note={M1: Copyright 1998, IEE},
	abstract={This paper describes a new motion estimation algorithm that is potentially useful for both computer vision and video compression applications. It is hierarchical in structure, using a separable two-dimensional (2-D) discrete wavelet transform (DWT) on each frame to efficiently construct a multiresolution pyramid of subimages. The DWT is based on a complex-valued pair of four-tap FIR filters with Gabor-like characteristics. The resulting complex DWT (CDWT) effectively implements an analysis by an ensemble of Gabor-like filters with a variety of orientations and scales. The phase difference between the subband coefficients of each frame at a given subpel bears a predictable relation to a local translation in the region of the reference frame subtended by that subpel. That relation is used to estimate the displacement field at the coarsest scale of the multiresolution pyramid. Each estimate is accompanied by a directional confidence measure in the form of the parameters of a quadratic matching surface. The initial estimate field is progressively refined by a coarse-to fine strategy in which finer scale information is appropriately incorporated at each stage. The accuracy, efficiency, and robustness of the new algorithm are demonstrated in comparison testing against hierarchical implementations of intensity gradient-based and fractional-precision block matching motion estimators},
	keywords={computer vision; data compression; filtering theory; FIR filters; image matching; image resolution; motion estimation; transform coding; video coding; wavelet transforms},
	isbn={1053-587X},
	url={http://dx.doi.org/10.1109/78.668557}
}


@inproceedings{RefWorks:445,
	author={P. de Rivaz and N. Kingsbury},
	year={1999},
	month={24-28 Oct. 1999},
	title={Complex wavelet features for fast texture image retrieval},
	booktitle={Proceedings of 6th International Conference on Image Processing (ICIP'99)},
	publisher={IEEE},
	address={Kobe, Japan},
	organization={Dept. of Eng., Cambridge Univ., UK},
	volume={1},
	pages={109-13},
	note={M1: Copyright 2000, IEE; T3: Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348)},
	abstract={Digital libraries and multimedia databases are being rapidly developed and efficient search algorithms must now be developed. Gabor features have been experimentally shown to be the most accurate but have the disadvantage of slow computation. This paper shows how a new complex wavelet transform can be used to approximate the Gabor features and derives a distance metric based on statistical hypothesis testing that gives a better performance than the usual metric. The new features are experimentally compared with both Gabor and standard wavelet techniques},
	keywords={digital libraries; image retrieval; image texture; multimedia databases; wavelet transforms},
	isbn={0 7803 5467 2},
	url={http://dx.doi.org/10.1109/ICIP.1999.821576}
}

@inproceedings{RefWorks:446,
	author={N. Kingsbury},
	year={1999},
	month={15-19 March 1999},
	title={Shift invariant properties of the dual-tree complex wavelet transform},
	booktitle={ICASSP99},
	series={1999 IEEE International Conference on Acoustics, Speech, and Signal Processing. Proceedings},
	publisher={IEEE},
	address={Phoenix, AZ, USA},
	organization={Dept. of Eng., Cambridge Univ., UK},
	volume={3},
	pages={1221-4},
	note={M1: Copyright 1999, IEE; T3: 1999 IEEE International Conference on Acoustics, Speech, and Signal Processing. Proceedings. ICASSP99 (Cat. No.99CH36258)},
	abstract={We discuss the shift invariant properties of a new implementation of the discrete wavelet transform, which employs a dual-tree of wavelet filters to obtain the real and imaginary parts of complex wavelet coefficients. This introduces limited redundancy (20RW1S34RfeSDcfkexd09rT3m1RW1S34RfeSDcfkexd09rT3:1 for m-dimensional signals) and allows the transform to provide approximate shift invariance and directionally selective filters (properties lacking in the traditional wavelet transform) while preserving the usual properties of perfect reconstruction and computational efficiency with good well-balanced frequency responses},
	keywords={discrete wavelet transforms; filtering theory; signal reconstruction; trees (mathematics)},
	isbn={0 7803 5041 3},
	url={http://dx.doi.org/10.1109/ICASSP.1999.756198}
}

@inproceedings{RefWorks:447,
	author={N. Kingsbury},
	year={2000},
	month={29 Feb. 2000},
	title={Complex wavelets and shift invariance},
	booktitle={IEE Seminar on Time-Scale and Time-Frequency Analysis and Applications},
	publisher={IEE},
	address={London, UK},
	organization={Dept. of Eng., Cambridge Univ., UK},
	pages={5-1},
	note={M1: Copyright 2001, IEE; T3: IEE Seminar on Time-Scale and Time-Frequency Analysis and Applications (Ref. No.00/019)},
	abstract={Recently we have developed a new form of discrete wavelet transform, which generates complex coefficients by using a dual tree of wavelet filters to obtain their real and imaginary parts. This introduces limited redundancy (20RW1S34RfeSDcfkexd09rT3m1RW1S34RfeSDcfkexd09rT3:1 for m-dimensional signals) and allows the transform to provide approximate shift invariance and directionally selective filters (properties lacking in the traditional wavelet transform) while preserving the usual properties of perfect reconstruction and computational efficiency with good well-balanced frequency responses. We analyse why the new transform can be designed to be shift invariant, and describe how to estimate the accuracy of this approximation and design suitable filters to achieve this},
	keywords={data compression; discrete wavelet transforms; filtering theory; signal reconstruction}
}

@inproceedings{RefWorks:448,
	author={P. de Rivaz and N. Kingsbury},
	year={2001},
	month={7-10 Oct. 2001},
	title={Bayesian image deconvolution and denoising using complex wavelets},
	booktitle={Proceedings 2001 International Conference on Image Processing},
	publisher={IEEE},
	address={Thessaloniki, Greece},
	organization={Dept. of Eng., Cambridge Univ., UK},
	volume={2},
	pages={273-6},
	note={M1: Copyright 2002, IEE; T3: Proceedings 2001 International Conference on Image Processing (Cat. No.01CH37205)},
	abstract={This paper proposes a new algorithm for image restoration (deconvolution and denoising) which employs the recently developed dual-tree complex wavelet transform in an iterative Bayesian framework. Complex wavelets are selected for their key features: shift invariance, directional selectivity and efficiency. The aim is to find an optimal description of the restored image in the complex wavelet domain, which minimises a quadratic energy function of the wavelet coefficients. The algorithm searches for this minimum using an efficient conjugate gradient method. We show that this can improve the SNR performance of a good minimax deconvolution method, WaRD, which is used to initialise the iterations, by typically 1.2 dB. Convergence is quite rapid, achieving 80% of the ultimate performance gain in about 20 iterations. Each iteration takes around 5 seconds using MatLab on a 400 MHz Pentium computer with 256&times;256 pixel images},
	keywords={Bayes methods; conjugate gradient methods; convergence of numerical methods; deconvolution; image restoration; interference suppression; minimax techniques; trees (mathematics); wavelet transforms},
	isbn={0 7803 6725 1},
	url={http://dx.doi.org/10.1109/ICIP.2001.958477}
}

@inproceedings{RefWorks:450,
	author={C. W. Shaffrey and N. G. Kingsbury and I. H. Jermyn},
	year={2002},
	month={22-25 Sept. 2002},
	title={Unsupervised image segmentation via Markov trees and complex wavelets},
	booktitle={Proceedings of ICIP 2002 International Conference on Image Processing},
	publisher={IEEE},
	address={Rochester, NY, USA},
	organization={Signal Process. Lab., Cambridge Univ., UK},
	volume={3},
	pages={801-4},
	note={M1: Copyright 2003, IEE; T3: Proceedings 2002 International Conference on Image Processing (Cat. No.02CH37396)},
	abstract={The goal in image segmentation is to label pixels in an image based on the properties of each pixel and its surrounding region. Recently content-based image retrieval (CBIR) has emerged as an application area in which retrieval is attempted by trying to gain unsupervised access to the image semantics directly rather than via manual annotation. To this end, we present an unsupervised segmentation technique in which colour and texture models are learned from the image prior to segmentation, and whose output (including the models) may subsequently be used as a content descriptor in a CBIR system. These models are obtained in a multiresolution setting in which hidden Markov trees (HMT) are used to model the key statistical properties exhibited by complex wavelet and scaling function coefficients. The unsupervised mean shift iteration (MSI) procedure is used to determine a number of image regions which are then used to train the models for each segmentation class},
	keywords={content-based retrieval; hidden Markov models; image colour analysis; image resolution; image retrieval; image segmentation; image texture; iterative methods; trees (mathematics); unsupervised learning; wavelet transforms},
	isbn={0 7803 7622 6},
	url={http://dx.doi.org/10.1109/ICIP.2002.1039093}
}

@inproceedings{RefWorks:451,
	author={M. A. Miller and N. G. Kingsbury and R. W. Hobbs},
	year={2004},
	title={Least-squares migration using complex wavelets},
	booktitle={Proc. 2004 Meeting of the Society of Exploration Geophysicists},
	address={Denver}
}

@inproceedings{RefWorks:452,
	author={R. Anderson and N. Kingsbury and J. Fauqueur},
	year={2005},
	month={17-20 July 2006},
	title={Multiscale object features from clustered complex wavelet coefficients},
	booktitle={2005 IEEE/SP 13th Workshop on Statistical Signal Processing},
	publisher={IEEE},
	address={Bordeaux, France},
	organization={Dept. of Eng., Cambridge Univ., UK},
	volume={1},
	pages={398-402},
	note={M1: Copyright 2006, The Institution of Engineering and Technology; T3: 2005 IEEE/SP 13th Workshop on Statistical Signal Processing (IEEE Cat. No. 05TH8839)},
	abstract={This paper introduces a method by which intuitive feature entities can be created from ILP (InterLevel Product) coefficients. The ILP transform is a pyramid of decimated complex-valued coefficients at multiple scales, derived from dual-tree complex wavelets, whose phases indicate the presence of different feature types (edges and ridges). We use an expectation-maximization algorithm to cluster large ILP coefficients that are spatially adjacent and similar in phase. We then demonstrate the relationship that these clusters possess with respect to observable image content, and conclude with a look at potential applications of these clusters, such as rotation- and scale-invariant object recognition},
	keywords={expectation-maximisation algorithm; image processing; trees (mathematics); wavelet transforms},
	isbn={5 7782 0554 6}
}

@inproceedings{RefWorks:453,
	author={R. Anderson and N. Kingsbury and J. Fauqueur},
	year={2006},
	month={11-14 Sept. 2005},
	title={Coarse-level object recognition using interlevel products of complex wavelets},
	booktitle={2005 International Conference on Image Processing},
	publisher={IEEE},
	address={Genova, Italy},
	organization={Dept. of Eng., Cambridge Univ., UK},
	pages={745-8},
	note={M1: Copyright 2006, IEE; T3: 2005 International Conference on Image Processing},
	abstract={This paper introduces the interlevel product (ILP) which is a transform based upon the dual-tree complex wavelet. Coefficients of the ILP have complex values whose magnitudes indicate the amplitude of multilevel features, and whose phases indicate the nature of these features (e.g. ridges vs. edges). In particular, the phases of ILP coefficients are approximately invariant to small shifts in the original images. We accordingly introduce this transform as a solution to coarse scale template matching, where alignment concerns between decimation of a target and decimation of a larger search image can be mitigated, and computational efficiency can be maintained. Furthermore, template matching with ILP coefficients can provide several intuitive "near-matches" that may be of interest in image retrieval applications},
	keywords={image matching; image retrieval; object recognition; wavelet transforms},
	isbn={0 7803 9134 9}
}

@inproceedings{RefWorks:454,
	author={J. Fauqueur and N. Kingsbury and R. Anderson},
	year={2006},
	month={11-14 Sept. 2005},
	title={Semantic discriminant mapping for classification and browsing of remote sensing textures and objects},
	booktitle={2005 International Conference on Image Processing},
	publisher={IEEE},
	address={Genova, Italy},
	organization={Dept. of Eng., Cambridge Univ., UK},
	pages={846-9},
	note={M1: Copyright 2006, IEE; T3: 2005 International Conference on Image Processing},
	abstract={We present a new approach based on discriminant analysis to map a high dimensional image feature space onto a subspace which has the following advantages: 1) each dimension corresponds to a semantic likelihood, 2) an efficient and simple multiclass classifier is proposed and 3) it is low dimensional. This mapping is learnt from a given set of labeled images with a class groundtruth. In the new space a classifier is naturally derived which performs as well as a linear SVM. We show that projecting images in this new space provides a database browsing tool which is meaningful to the user. Results are presented on a remote sensing database with eight classes, made available online. The output semantic space is a low dimensional feature space which opens perspectives for other recognition tasks},
	keywords={geophysical signal processing; image classification; image colour analysis; image texture; remote sensing; support vector machines; visual databases},
	isbn={0 7803 9134 9}
}

@inproceedings{RefWorks:455,
	author={R. Anderson and N. Kingsbury and J. Fauqueur},
	year={2005},
	month={28-30 Sept. 2005},
	title={Determining multiscale image feature angles from complex wavelet phases},
	booktitle={Proceedings},
	series={Image Analysis and Recognition. Second International Conference, ICIAR 2005},
	publisher={Springer-Verlag},
	address={Toronto, Ont., Canada},
	organization={Dept. of Eng., Cambridge Univ., UK},
	pages={490-8},
	note={M1: Copyright 2006, IEE; T3: Image Analysis and Recognition. Second International Conference, ICIAR 2005. (Lecture Notes in Computer Science Vol. 3656)},
	abstract={In this paper, we introduce a new multiscale representation for 2-D images named the inter-coefficient product (ICP). The ICP is a decimated pyramid of complex values based on the dual-tree complex wavelet transform (DT-CWT). The complex phases of its coefficients correspond to the angles of dominant directional features in their support regions. As a sparse representation of this information, the ICP is relatively simple to calculate and is a computationally efficient representation for subsequent analysis in computer vision activities or large data set analysis. Examples of ICP decomposition show its ability to provide an intuitive representation of multiscale features (such as edges and ridges). Its potential uses are then discussed},
	keywords={computer vision; edge detection; feature extraction; image representation; wavelet transforms},
	isbn={3 540 29069 9}
}

@inproceedings{RefWorks:456,
	author={N. Kingsbury and D. B. H. Tay and M. Palaniswami},
	year={2005},
	month={28-30 Sept. 2005},
	title={Multi-scale kernel methods for classification},
	booktitle={2005 IEEE Workshop on Machine Learning for Signal Processing},
	publisher={IEEE},
	address={Mystic, CT, USA},
	organization={Dept. of Eng., Cambridge Univ., UK},
	pages={48-53},
	note={M1: Copyright 2006, IEE; T3: 2005 IEEE Workshop on Machine Learning for Signal Processing (IEEE Cat. No.05TH8851C)},
	abstract={We propose the enhancement of support vector machines for classification, by the use of multi-scale kernel structures (based on wavelet philosophy) which can be linearly combined in a spatially varying way. This provides a good tradeoff between ability to generalize well in areas of sparse training vectors and ability to fit fine detail of the decision surface in areas where the training vector density is sufficient to provide this information. Our algorithm is a sequential machine learning method in that progressively finer kernel functions are incorporated in successive stages of the learning process. Its key advantage is the ability to find the appropriate kernel scale for every local region of the input space},
	keywords={learning (artificial intelligence); pattern classification; support vector machines; wavelet transforms},
	isbn={0 7803 9518 2}
}

@inproceedings{RefWorks:457,
	author={N. G. Kingsbury},
	year={2006},
	title={Rotation-invariant local feature matching with complex wavelets},
	booktitle={Proc. European Conference on Signal Processing (EUSIPCO)},
	address={Florence}
}

@inproceedings{RefWorks:458,
	author={R. Anderson and N. Kingsbury and J. Fauqueur},
	year={2006},
	title={Rotation-invariant object recognition using edge-profile clusters},
	booktitle={Proc. European Conference on Signal Processing (EUSIPCO)},
	address={Florence}
}

@inproceedings{RefWorks:459,
	author={J. Fauqueur and N. Kingsbury and R. Anderson},
	year={1996},
	month={8-11 Oct. 2006},
	title={Multiscale keypoint detection using the dual-tree complex wavelet transform},
	booktitle={2006 International Conference on Image Processing},
	publisher={IEEE},
	address={Atlanta, GA, USA},
	organization={Dept. of Eng., Cambridge Univ., UK},
	pages={4},
	note={M1: Copyright 2007, The Institution of Engineering and Technology; T3: 2006 International Conference on Image Processing},
	abstract={We present a novel approach to detecting multiscale keypoints using the dual tree complex wavelet transform (DTCWT). We show that it is a well-suited basis for this problem as it is directionally selective, smoothly shift invariant, optimally decimated at coarse scales and invertible (no loss of information). Our detection scheme is fast because of the decimated nature of the DTCWT and yet provides accurate and robust keypoint localisation, thanks to the use of the "accumulated energy map". The regularity of this map is used to introduce a new mechanism for robust keypoint scale selection. Key-points of different nature and size can be detected with limited redundancy, in a way which is consistent with our visual perception. Furthermore results show better robustness against rotation compared to the SIFT detector},
	keywords={object detection; visual perception; wavelet transforms},
	isbn={1 4244 0481 9}
}

@inproceedings{RefWorks:460,
	author={A. Bharath and N. Kingsbury},
	title={Phase Invariant Keypoint Detection},
	booktitle={15th International Conference on Digital Signal Processing (DSP2007)},
	address={Cardiff}
}

@article{RefWorks:461,
	author={M. A. Miller and N. G. Kingsbury},
	year={2007},
	title={Image Estimation using Interscale Phase Properties of Complex Wavelet Coefficients},
	journal={IEEE Transactions on Image Processing}
}

@article{RefWorks:462,
	author={M. A. Miller and N. G. Kingsbury},
	year={2007},
	title={Image Denoising using Derotated Complex Wavelet Coefficients},
	journal={IEEE Transactions on Image Processing}
}

@inproceedings{RefWorks:463,
	author={T. Serre and L. Wolf and T. Poggio},
	year={2005},
	month={20-25 June 2005},
	title={Object recognition with features inspired by visual cortex},
	booktitle={2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
	series={Proceedings},
	publisher={IEEE Comput. Soc},
	address={San Diego, CA, USA},
	organization={Dept. of Brain & Cognitive Sci., MIT, Cambridge, MA, USA},
	volume={2},
	pages={994-1000},
	note={M1: Copyright 2005, IEE; T3: Proceedings. 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
	abstract={We introduce a novel set of features for robust object recognition. Each element of this set is a complex feature obtained by combining position- and scale-tolerant edge-detectors over neighboring positions and multiple orientations. Our system's architecture is motivated by a quantitative model of visual cortex. We show that our approach exhibits excellent recognition performance and outperforms several state-of-the-art systems on a variety of image datasets including many different object categories. We also demonstrate that our system is able to learn from very few examples. The performance of the approach constitutes a suggestive plausibility proof for a class of feedforward models of object recognition in cortex},
	keywords={edge detection; feature extraction; object recognition},
	isbn={0 7695 2372 2}
}

@article{RefWorks:464,
	author={T. Serre and A. Oliva and T. Poggio},
	year={2007},
	month={Apr 10},
	title={A feedforward architecture accounts for rapid categorization},
	journal={Proceedings of the National Academy of Sciences of the United States of America},
	volume={104},
	number={15},
	pages={6424-6429},
	note={PUBM: Print-Electronic; GR: 1 P20MH66239-01A1/MH/NIMH; DEP: 20070402; JID: 7505876; 2007/04/02 [aheadofprint]; ppublish},
	abstract={Primates are remarkably good at recognizing objects. The level of performance of their visual system and its robustness to image degradations still surpasses the best computer vision systems despite decades of engineering effort. In particular, the high accuracy of primates in ultra rapid object categorization and rapid serial visual presentation tasks is remarkable. Given the number of processing stages involved and typical neural latencies, such rapid visual processing is likely to be mostly feedforward. Here we show that a specific implementation of a class of feedforward theories of object recognition (that extend the Hubel and Wiesel simple-to-complex cell hierarchy and account for many anatomical and physiological constraints) can predict the level and the pattern of performance achieved by humans on a rapid masked animal vs. non-animal categorization task.},
	keywords={Adult; Humans; Models, Neurological; Pattern Recognition, Visual/physiology; Photic Stimulation; Psychophysics; Recognition (Psychology); Visual Perception/physiology},
	isbn={0027-8424},
	language={eng}
}

@article{RefWorks:465,
	author={J. Lewis},
	year={1995},
	title={Fast normalized cross-correlation},
	journal={Vision Interface},
	pages={120â123}
}

@inproceedings{RefWorks:466,
	author={J. K. Romberg and M. B. Wakin and Hyeokho Choi and R. G. Baraniuk},
	year={2003},
	month={11/14},
	title={A geometric hidden Markov tree wavelet model},
	booktitle={Wavelets: application in Signal and Image Processing X},
	publisher={SPIE-Int. Soc. Opt. Eng},
	address={San Diego, CA, USA},
	organization={Dept. of Electr. \& Comput. Eng., Rice Univ., Houston, TX, USA},
	volume={5207},
	chapter={1},
	pages={80-6},
	note={M1: Copyright 2004, IEE; T3: Proc. SPIE - Int. Soc. Opt. Eng. (USA)},
	abstract={Traditional wavelet-based image processing algorithms and models have significant shortcomings in their treatment of edge contours. The standard modeling paradigm exploits the fact that wavelet coefficients representing smooth regions in images tend to be small; the multiscale nature of the wavelet transform implies that these small coefficients persist across scale. The edge contours in an image, however, cause ever larger wavelet coefficients as we move to finer resolutions. But if the contours are smooth, they become simple as we zoom in on them, and are well approximated by straight lines at fine scales. Standard wavelet models exploit the grayscale regularity of the smooth regions of the image, but not the geometric regularity of the contours. We build a model that accounts for this geometric regularity by capturing the dependencies between complex wavelet coefficients along a contour. The geometric hidden Markov tree (GHMT) assigns each wavelet coefficient (or spatial cluster of wavelet coefficients) a hidden state corresponding to a linear approximation of the local contour structure. The shift and rotational-invariance properties of the complex wavelet transform allow the GHMT to model the behavior of each coefficient given the presence of a linear edge at a specified orientation - the behavior of the wavelet coefficient given the state. By connecting the states together in a quadtree, the GHMT ties together wavelet coefficients along a contour, and also models how the contour itself behaves across scale. We demonstrate the effectiveness of the model by applying it to feature extraction},
	keywords={edge detection; feature extraction; hidden Markov models; image resolution; invariance; quadtrees; wavelet transforms},
	isbn={0277-786X},
	url={http://dx.doi.org/10.1117/12.506853}
}

@article{RefWorks:467,
	author={S. Baker and I. Matthew},
	year={2004},
	month={02},
	title={Lucas-Kanade 20 years on: a unifying framework},
	journal={International Journal of Computer Vision},
	volume={56},
	number={3},
	pages={221-55},
	note={M1: Copyright 2004, IEE},
	abstract={Since the Lucas-Kanade algorithm was proposed in 1981 image alignment has become one of the most widely used techniques in computer vision. Applications range from optical flow and tracking to layered motion, mosaic construction, and face coding. Numerous algorithms have been proposed and a wide variety of extensions have been made to the original formulation. We present an overview of image alignment, describing most of the algorithms and their extensions in a consistent framework. We concentrate on the inverse compositional algorithm, an efficient algorithm that we recently proposed. We examine which of the extensions to Lucas-Kanade can be used with the inverse compositional algorithm without any significant loss of efficiency, and which cannot. In this paper, part 1 in a series of papers, we cover the quantity approximated, the warp update rule, and the gradient descent approximation. In future papers, we will cover the choice of the error function, how to allow linear appearance variation, and how to impose priors on the parameters},
	keywords={computer vision; image segmentation; image sequences},
	isbn={0920-5691},
	url={http://www.ri.cmu.edu/projects/project_515.html}
}

@article{RefWorks:468,
	author={Andrew J. Davison and Ian D. Reid and Nicholas D. Molton and Olivier Stasse},
	year={2007},
	title={MonoSLAM: Real-time single camera SLAM},
	journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
	volume={29},
	number={6},
	pages={1052-1067},
	note={Compilation and indexing terms, Copyright 2007 Elsevier Inc. All rights reserved},
	abstract={We present a real-time algorithm which can recover the 3D trajectory of a monocular camera, moving rapidly through a previously unknown scene. Our system, which we dub MonoSLAM, is the first successful application of the SLAM methodology from mobile robotics to the "pure vision" domain of a single uncontrolled camera, achieving real time but drift-free performance inaccessible to Structure from Motion approaches. The core of the approach is the online creation of a sparse but persistent map of natural landmarks within a probabilistic framework. Our key novel contributions include an active approach to mapping and measurement, the use of a general motion model for smooth camera movement, and solutions for monocular feature initialization and feature orientation estimation. Together, these add up to an extremely efficient and robust algorithm which runs at 30 Hz with standard PC and camera hardware. This work extends the range of robotic systems in which SLAM can be usefully applied, but also opens up new areas. We present applications of MonoSLAM to real-time 3D localization and mapping for a high-performance full-size humanoid robot and live augmented reality with a hand-held camera. (C) 2007 IEEE.},
	keywords={Mobile robots; Algorithms; Computer simulation; Digital cameras; Motion picture cameras; Real time systems; Robotics; Virtual reality},
	isbn={0162-8828},
	url={http://dx.doi.org/10.1109/TPAMI.2007.1049; http://dx.doi.org/10.1109/TPAMI.2007.1049}
}

@article{RefWorks:469,
	author={Fan Xiang and Xia Shun-ren},
	year={2007},
	title={Feature Based Automatic Stitching of Microscopic Images},
	journal={Communications in Computer and Information Science},
	volume={2},
	pages={791-800},
	note={\url{http://dx.doi.org/10.1007/978-3-540-74282-1_88}},
	abstract={Mosaicing of microscopic images is often necessary when the observed  specimen cannot be captured into a single image. Automatic method is  preferred because it will greatly reduce the work involved. In the  paper, we present a feature based automatic mosaicing method based on  the related research on panorama reconstruction for photography. Scale  invariant feature transform (SIFT) is first applied to extract robust  features from the images, and by careful implementation of  Best-Bin-First (BBF) algorithm, we construct the global 0RW1S34RfeSDcfkexd09rT2k1RW1S34RfeSDcfkexd09rT2d-Tree from all the features  and search for the possible overlapping image pairs efficiently. Random  sample consensus (RANSAC) is chosen to further verify the matches. And  once the image pairs are all validated, minimum spanning tree (MST) is  used to obtain the best connected-component of the image set to recover  the transformation between images and project them into the mosaic  frame. Our experiment results show that the approach is robust to  background noises and illumination change in the images and can give  reliable and accurate results even for images of low overlapping or  with relatively few features.}
}

@techreport{RefWorks:470,
	author={M. Brown and R. Szeliski and S. Winder},
	year={2004},
	title={Multi-Scale Oriented Patches},
	number={MSR-TR-2004-133}
}

@article{RefWorks:471,
	author={Krystian Mikolajczyk and Cordelia Schmid},
	year={2005},
	title={A performance evaluation of local descriptors},
	journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
	volume={27},
	number={10},
	pages={1615-1630},
	note={Compilation and indexing terms, Copyright 2007 Elsevier Inc. All rights reserved},
	abstract={In this paper, we compare the performance of descriptors computed for local interest regions, as, for example, extracted by the Harris-Affine detector [32]. Many different descriptors have been proposed in the literature. It is unclear which descriptors are more appropriate and how their performance depends on the interest region detector. The descriptors should be distinctive and at the same time robust to changes in viewing conditions as well as to errors of the detector. Our evaluation uses as criterion recall with respect to precision and is carried out for different image transformations. We compare shape context [3], steerable filters [12], PCA-SIFT [19], differential invariants [20], spin images [21], SIFT [26], complex filters [37], moment invariants [43], and cross-correlation for different types of interest regions. We also propose an extension of the SIFT descriptor and show that it outperforms the original method. Furthermore, we observe that the ranking of the descriptors is mostly independent of the interest region detector and that the SIFT-based descriptors perform best. Moments and steerable filters show the best performance among the low dimensional descriptors. &copy; 2005 IEEE.},
	keywords={Pattern recognition systems; Feature extraction; Edge detection; Pattern matching; Invariance; Mathematical transformations; Correlation methods},
	isbn={0162-8828},
	url={http://dx.doi.org/10.1109/TPAMI.2005.188; http://dx.doi.org/10.1109/TPAMI.2005.188}
}

@article{RefWorks:472,
	author={P. Moreels and P. Perona},
	year={2007},
	month={07},
	title={Evaluation of features detectors and descriptors based on 3D objects},
	journal={International Journal of Computer Vision},
	volume={73},
	number={3},
	pages={263-84},
	note={M1: Copyright 2007, The Institution of Engineering and Technology},
	abstract={We explore the performance of a number of popular feature detectors and descriptors in matching 3D object features across viewpoints and lighting conditions. To this end we design a method, based on intersecting epipolar constraints, for providing ground truth correspondence automatically. These correspondences are based purely on geometric information, and do not rely on the choice of a specific feature appearance descriptor. We test detector-descriptor combinations on a database of 100 objects viewed from 144 calibrated viewpoints under three different lighting conditions. We find that the combination of Hessian-affine feature finder and SIFT features is most robust to viewpoint change. Harris-affine combined with SIFT and Hessian-affine combined with shape context descriptors were best respectively for lighting change and change in camera focal length. We also find that no detector-descriptor combination performs well with viewpoint changes of more than 25-30&deg;},
	keywords={affine transforms; feature extraction; object recognition},
	isbn={0920-5691},
	url={http://dx.doi.org/10.1007/s11263-006-9967-1}
}

@inproceedings{RefWorks:473,
	author={K. Mikolajczyk and C. Schmid},
	year={2002},
	month={28-31 May 2002},
	title={An affine invariant interest point detector},
	booktitle={Proceedings},
	series={Computer Vision - ECCV 2002. 7th European Conference on Computer Vision},
	publisher={Springer-Verlag},
	address={Copenhagen, Denmark},
	organization={INRIA Rhone-Alpes, Montbonnot, France},
	pages={128-42},
	note={M1: Copyright 2002, IEE; T3: Computer Vision - ECCV 2002. 7th European Conference on Computer Vision. Proceedings, Part I (Lecture Notes in Computer Science Vol.2350)},
	abstract={This paper presents a novel approach for detecting affine invariant interest points. Our method can deal with significant affine transformations including large scale changes. Such transformations introduce significant changes in the point location as well as in the scale and shape of the neighbourhood of an interest point. Our approach allows one to solve for these problems simultaneously. It is based on three key ideas: 1) the second moment matrix computed in a point can be used to normalize a region in an affine invariant way (skew and stretch); 2) the scale of the local structure is indicated by local extrema of normalized derivatives over scale; and 3) an affine-adapted Harris detector determines the location of interest points. A multi-scale version of this detector is used for initialization. An iterative algorithm then modifies location, scale and neighbourhood of each point and converges to affine invariant points. For matching and recognition, the image is characterized by a set of affine invariant points; the affine transformation associated with each point allows the computation of an affine invariant descriptor which is also invariant to affine illumination changes. A quantitative comparison of our detector with existing ones shows a significant improvement in the presence of large affine deformations. Experimental results for wide baseline matching show an excellent performance in the presence of large perspective transformations including significant scale changes. Results for recognition are very good for a database with more than 5000 images},
	keywords={feature extraction; image matching; image recognition; iterative methods; method of moments},
	isbn={3 540 43745 2}
}

@article{RefWorks:474,
	author={Krystian Mikolajczyk and Cordelia Schmid},
	year={2004},
	title={Scale and affine invariant interest point detectors},
	journal={International Journal of Computer Vision},
	volume={60},
	number={1},
	pages={63-86},
	note={Compilation and indexing terms, Copyright 2007 Elsevier Inc. All rights reserved},
	abstract={In this paper we propose a novel approach for detecting interest points invariant to scale and affine transformations. Our scale and affine invariant detectors are based on the following recent results: (1) Interest points extracted with the Harris detector can be adapted to affine transformations and give repeatable results (geometrically stable). (2) The characteristic scale of a local structure is indicated by a local extremum over scale of normalized derivatives (the Laplacian). (3) The affine shape of a point neighborhood is estimated based on the second moment matrix. Our scale invariant detector computes a multi-scale representation for the Harris interest point detector and then selects points at which a local measure (the Laplacian) is maximal over scales. This provides a set of distinctive points which are invariant to scale, rotation and translation as well as robust to illumination changes and limited changes of viewpoint. The characteristic scale determines a scale invariant region for each point. We extend the scale invariant detector to affine invariance by estimating the affine shape of a point neighborhood. An iterative algorithm modifies location, scale and neighborhood of each point and converges to affine invariant points. This method can deal with significant affine transformations including large scale changes. The characteristic scale and the affine shape of neighborhood determine an affine invariant region for each point. We present a comparative evaluation of different detectors and show that our approach provides better results than existing methods. The performance of our detector is also confirmed by excellent matching results; the image is described by a set of scale/affine invariant descriptors computed on the regions associated with our points.},
	keywords={Computer vision; Mathematical transformations; Probability; Feature extraction; Object recognition; Algorithms; Image analysis; Automation; Problem solving},
	isbn={0920-5691},
	url={http://dx.doi.org/10.1023/B:VISI.0000027790.02288.f2; http://dx.doi.org/10.1023/B:VISI.0000027790.02288.f2}
}

@article{RefWorks:475,
	author={R. Dedekind},
	year={1885},
	title={Zur Theorie der aus n Haupteinheiten gebildeten GrÃ¶Ãen},
	journal={Nachrichten von der KÃ¶niglichen Gesellschaft der Wissenschaften und der Georg-Augusts-UniversitÃ¤t zu GÃ¶ttingen},
	volume={1885},
	number={4},
	pages={141-159},
	note={\url{http://www.digizeitschriften.de/resolveppn/PPN252457072}}
}

@article{RefWorks:476,
	author={N. Stefanov and A. Galata and R. Hubbold},
	year={2007},
	month={10},
	title={A real-time hand tracker using variable-length Markov models of behaviour},
	journal={Computer Vision and Image Understanding},
	volume={108},
	number={1-2},
	pages={98-115},
	note={M1: Copyright 2007, The Institution of Engineering and Technology},
	abstract={We present a novel approach for visual tracking of structured behaviour as observed in human-computer interaction. An automatically acquired variable-length Markov model is used to represent the high-level structure and temporal ordering of gestures. Continuous estimation of hand posture is handled by combining the model with annealed particle filtering. The stochastic simulation updates and automatically switches between different model representations of hand posture that correspond to distinct gestures. The implementation executes in real time and demonstrates significant improvement in robustness over comparable methods. We provide a measurement of user performance when our method is applied to a Fitts&psila; law drag-and-drop task, and an analysis of the effects of latency that it introduces.[All rights reserved Elsevier].},
	keywords={gesture recognition; human computer interaction; Markov processes; particle filtering (numerical methods)},
	isbn={1077-3142},
	url={http://dx.doi.org/10.1016/j.cviu.2006.10.017}
}

@article{RefWorks:477,
	author={Zhengyou Zhang and Li-Wei He},
	year={2007},
	month={03},
	title={Whiteboard scanning and image enhancement},
	journal={Digital Signal Processing},
	volume={17},
	number={2},
	pages={414-32},
	note={M1: Copyright 2007, The Institution of Engineering and Technology},
	abstract={A whiteboard can be an easy tool for collaboration such as brainstorming, and is widely used, but the content on a whiteboard is hard to archive and share. While digital cameras can be used to capture whiteboard content, the images are usually taken from an angle, resulting in undesired perspective distortion. They may contain other distracting regions such as walls and shadows. The visual quality of those images is usually poor. This paper describes a system that automatically locates the boundary of a whiteboard, crops out the whiteboard region, rectifies it into a rectangle, and corrects the color to make the whiteboard completely white. In case a single image is not enough (e.g., large whiteboard and low-resolution camera), we have developed a robust feature-based technique to automatically stitch multiple overlapping images. The system has been tested extensively, and very good results have been obtained. [All rights reserved Elsevier]},
	keywords={document image processing; image enhancement; image resolution; image sensors},
	isbn={1051-2004},
	url={http://dx.doi.org/10.1016/j.dsp.2006.05.006}
}

@article{RefWorks:478,
	author={Shin-ichi Todoroki and Satoru Inoue},
	year={2004},
	title={Multi-dimensional data management by virtual sample library written in object-oriented script language Ruby},
	journal={Transactions of the Materials Research Society of Japan},
	volume={29},
	number={1},
	pages={293-296}
}

@article{RefWorks:479,
	author={S. Vinoski},
	year={2006},
	title={Ruby extensions [dynamic language application]},
	journal={IEEE Internet Computing},
	volume={10},
	number={5},
	pages={85-7},
	note={M1: Copyright 2006, The Institution of Engineering and Technology},
	abstract={The author reviewed Maik Schmidt's enterprise integration with Ruby as a means of exploring dynamic languages' applicability to middleware integration projects. Using languages such as Ruby for these projects is straight forward when developers can create pure dynamic language applications that access preexisting services, even though such services are typically implemented in middleware languages such as Java, C++, or C. This approach works reasonably well because the dynamic language applications typically reside in separate address spaces from the services they use, accessing the services only through avenues that guarantee separation, including database drivers and network connections. Are dynamic languages like Ruby useful in middleware integration projects that require you to directly couple the dynamic code to legacy code? The author explores what it takes to cleanly integrate Ruby into an existing C++ middleware system},
	keywords={C++ language; middleware},
	isbn={1089-7801},
	url={http://dx.doi.org/10.1109/MIC.2006.109}
}

@article{RefWorks:480,
	author={Brent Roman and Chris Scholin and Scott Jensen and Eugene Massion and Roman Marin III and Christina Preston and Dianne Greenfield and William Jones and Kevin Wheeler},
	year={2007},
	title={Controlling a Robotic Marine Environmental Sampler with the Ruby Scripting Language},
	journal={JALA - Journal of the Association for Laboratory Automation},
	volume={12},
	number={1},
	pages={56-61},
	note={Compilation and indexing terms, Copyright 2007 Elsevier Inc. All rights reserved},
	abstract={The Environmental Sample Processor (ESP) is an autonomous robotic instrument developed at the Monterey Bay Research Aquarium Institute (MBARI) that operates below the ocean's surface, sampling raw seawater and executing a variety of sample manipulation and analytical protocols, in situ. It uses DNA and antibody probes to identify marine planktonic organisms and substances they produce. Initial prototypes of the ESP were hosted on an Intel i486 CPU running a commercial real-time operating system (OS). The application, coded in C++, included a custom 'macro' language interpreter to direct biochemical analyses. To achieve greater flexibility and minimize the development effort for the 2nd generation of the ESP (2G ESP), MBARI replaced its 'macro' language with a general purpose, open-source scripting language, selecting Ruby for its unique combination of a succinct, English-like syntax with a seamless underlying object-oriented paradigm. The 2G ESP application, aside from custom servo control firmware, is coded entirely in Ruby, hosted on a low-power ARM9 CPU running Linux. Servo control was distributed onto a network of dedicated microcontrollers to cope with the nondeterministic delays inherent in the Linux operating system and Ruby interpreter. &copy; 2007 The Association for Laboratory Automation.},
	keywords={Marine biology; Biochemistry; C (programming language); Computer operating systems; DNA; Macros; Microcontrollers; Object oriented programming; Real time systems},
	isbn={1535-5535},
	url={http://dx.doi.org/10.1016/j.jala.2006.07.013; http://dx.doi.org/10.1016/j.jala.2006.07.013}
}

@article{RefWorks:481,
	author={John Joyce},
	year={2005},
	title={The Glistening Ruby: An interpreted scripting language with an object-oriented heritage},
	journal={Scientific Computing},
	volume={22},
	number={11},
	pages={18-48},
	note={Compilation and indexing terms, Copyright 2007 Elsevier Inc. All rights reserved},
	abstract={A new interpreted programming language, Ruby, has been designed by Yukihiro Matsumoto in Japan from the ground up to be object oriented. Unlike other object-oriented languages, the object orientation in Ruby is easier to make use of, where many of the features which are implemented as functions in other languages, they are implemented as functions in Ruby. It has many of the classic control structures found in other languages including if and while, but it allows more flexible use of them by allowing the option of concise format. By design, Ruby supports single inheritance, but includes most of the benefits of multiple inheritance by including modules, which function similar to a class with a number of restrictions.},
	keywords={Computer programming languages; Natural sciences computing; Object oriented programming},
	isbn={1524-2560}
}

@article{RefWorks:482,
	author={D. Thomas and A. Hunt},
	year={2001},
	month={01},
	title={Programming in Ruby},
	journal={Dr.Dobb's Journal},
	volume={26},
	number={1},
	pages={44-51},
	note={M1: Copyright 2001, IEE},
	abstract={Ruby is a freely available pure object oriented language. Ruby is being used worldwide for text processing, XML and Web applications, GUI building, in middle-tier servers, and general system administration. Ruby is used in artificial intelligence and machine learning research, and as an engine for exploratory mathematics. Ruby's simple syntax and transparent semantics make it easy to learn. Its direct execution model and dynamic typing let you develop code incrementally. You can typically add a feature and then try it immediately, with no need for scaffolding code. Ruby programs are typically more concise than their Perl, Python, or C++ counterparts, and their simplicity makes them easier to understand and maintain. When you bump up against some facility that Ruby is lacking, you'll find it easy to write Ruby extensions using both Ruby and low-level C code that adds new features to the language},
	keywords={object-oriented languages; object-oriented programming; public domain software},
	isbn={1044-789X},
        note={\url{http://www.ddj.com/web-development/184404436}}
}

@article{RefWorks:483,
	author={D. M. Beazley},
	year={2003},
	month={07},
	title={Automated scientific software scripting with {SWIG}},
	journal={Future Generation Computer Systems},
	volume={19},
	number={5},
	pages={599-609},
	note={M1: Copyright 2004, IEE},
	abstract={Scripting languages such as Python and Tcl are a powerful tool for the construction of flexible scientific software because they provide scientists with an interpreted problem solving environment and they provide a modular framework for controlling software components written in C, C++, and Fortran. However, a common problem faced by the developers of a scripted scientific application is that of integrating compiled code with an interpreter. To solve this problem, an extensible compiler, simplified wrapper and interface generator (SWIG), has been developed to automate the task of integrating compiled code with scripting language interpreters. SWIG requires no modifications to existing code and uses existing source to create bindings for nine different target languages including Python, Perl, Tcl, Ruby, Guile, and Java. By automating language integration, SWIG enables scientists to use scripting languages at all stages of software development and allows existing software to be more easily integrated into a scripting environment. Although SWIG has been in use for more than 6 years, little has been published on its design and the underlying mechanisms that make it work. Therefore, the primary goal of this paper is to cover these topics},
	keywords={C++ language; compiler generators; FORTRAN; problem solving; program interpreters; software engineering},
	isbn={0167-739X},
	url={http://dx.doi.org/10.1016/S0167-739X(02)00171-1}
}

@article{RefWorks:484,
	author={L. D. Paulson},
	year={2007},
	month={02},
	title={Developers shift to dynamic programming languages},
	journal={Computer},
	volume={40},
	number={2},
	pages={12-15},
	note={M1: Copyright 2007, The Institution of Engineering and Technology},
	abstract={Software developers are always looking for ways to boost their effectiveness and productivity and perform complex jobs more quickly and easily, particularly as projects have become increasingly large and complex. Programmers want to shed unneeded complexity and outdated methodologies and move to approaches that focus on making programming simpler and faster. With this in mind, many developers are increasingly using dynamic languages such as JavaScript, Perl, Python, and Ruby. Although software experts disagree on the exact definition, a dynamic language basically enables programs that can change their code and logical structures at runtime, adding variable types, module names, classes, and functions as they are running. These languages frequently are interpreted and generally check typing at runtime},
	keywords={C++ language; Java; parallel languages; Perl},
	isbn={0018-9162},
	url={http://dx.doi.org/10.1109/MC.2007.53}
}

@article{RefWorks:485,
	author={S. Vinoski},
	year={2006},
	month={03},
	title={The language divide},
	journal={IEEE Internet Computing},
	volume={10},
	number={2},
	pages={82-4},
	note={M1: Copyright 2006, The Institution of Engineering and Technology},
	abstract={The days of C++-only or Java-only middleware systems are numbered, and dynamic scripting languages will soon become an important part of middleware development. When it comes to Web development, scripting languages such as Perl, Python, Ruby, PHP, and Javascript seem to rule the roost. Java has some presence there as well, of course, in the form of servlets JavaServer Pages and JavaServer Faces, and frameworks such as Struts and Tapestry. Java, and now C#, might also provide a more direct answer to bridging the language divide between middleware and the Web},
	keywords={C++ language; Internet; Java; middleware},
	isbn={1089-7801},
	url={http://dx.doi.org/10.1109/MIC.2006.44}
}

@article{RefWorks:486,
	author={Laurence Tratt and Roel Wuyts},
	year={2007},
	title={Guest editors' introduction: Dynamically typed languages},
	journal={IEEE Software},
	volume={24},
	number={5},
	pages={28-30},
	note={Compilation and indexing terms, Copyright 2007 Elsevier Inc. All rights reserved},
	abstract={The languages discussed in this special issue have a long history, which is perhaps why some have had several different names over the years. One such language is Lisp, the second-oldest programming language. For years, many somewhat dismissively described languages such as Lisp as "scripting languages." Today, we more commonly refer to them as dynamically typed languages, typified by Python and Ruby, and their impact is arguably greater than ever. This issue highlights the practical uses of such languages and shows how they're frequently a vehicle for innovation in the development sphere. This article is part of a special issue on dynamically typed languages. &copy; 2007 IEEE.},
	isbn={0740-7459},
	url={http://dx.doi.org/10.1109/MS.2007.140; http://dx.doi.org/10.1109/MS.2007.140}
}

@article{RefWorks:487,
	author={Zaljko Obrenovic and Dragan Gasevic},
	year={2007},
	title={Open source software: All you do is put it together},
	journal={IEEE Software},
	volume={24},
	number={5},
	pages={86-95},
	note={Compilation and indexing terms, Copyright 2007 Elsevier Inc. All rights reserved},
	abstract={The authors propose an infrastructure for rapidly prototyping applications from open source software components. The Adaptable Multi-Interface Communicator infrastructure (AMICO) is based on ideas of middleware platforms for component integration, but it focuses on pragmatic aspects of OSS integration, often absent from many existing integration platforms. The authors also identify the key requirements of middleware for rapid prototyping with OSS components and illustrate their approach through two examples in complex scenarios. Another article related to software composition also appears in this issue ("Dynamic Detection of COTS Component Incompatibility").] &copy; 2007 IEEE.},
	keywords={Computer software; Middleware; Rapid prototyping; Software prototyping},
	isbn={0740-7459},
	url={http://dx.doi.org/10.1109/MS.2007.141; http://dx.doi.org/10.1109/MS.2007.141}
}

@article{RefWorks:488,
	author={Marcus Denker and Stephane Ducasse},
	year={2007},
	title={Software Evolution from the Field. An Experience Report from the {S}queak Maintainers},
	journal={Electronic Notes in Theoretical Computer Science},
	volume={166},
	pages={81-91},
	abstract={Over the last few years, we actively participated in the maintenance and evolution of Squeak, an open-source Smalltalk. The community is constantly faced with the problem of enabling changes while at the same time preserving compatibility. In this paper we describe the current situation, the problems that faced the community and we outline the improvements that have been introduced. We also identify some areas where problems continue to exist and propose these as potential problems to addressed by the research community. &copy; 2006 Elsevier B.V. All rights reserved.},
	keywords={Software engineering; Computer software; Open systems; Problem solving; Requirements engineering; Maintenance},
	isbn={1571-0661},
	url={http://dx.doi.org/10.1016/j.entcs.2006.08.003; http://dx.doi.org/10.1016/j.entcs.2006.08.003}
}

@techreport{RefWorks:489,
	author={James Diebel},
	year={2006},
	title={Representing Attitude: Euler Angles, Quaternions, and Rotation Vectors},
	note={\url{http://ai.stanford.edu/~diebel/attitude/attitude.pdf}},
	abstract={We present the three main mathematical constructs used to represent the attitude of a rigid body in three-dimensional space. These are (1) the rotation matrix, (2) a triple of Euler angles, and (3) the unit quaternion. To these we add a fourth, the rotation vector, which has many of the benefits of both Euler angles and quaternions, but neither the singularities of the former, nor the quadratic constraint of the latter. There are several other subsidiary representations, such as Cayley-Klein parameters and the axis-angle representation, whose relations to the three main representations are also described. Our exposition is catered to those who seek a thorough and unified reference on the whole subject; detailed derivations of some results are not presented.}
}

@article{RefWorks:490,
	author={R. Jones and I. Svalbe},
	year={1994},
	month={04},
	title={Morphological filtering as template matching},
	journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
	volume={16},
	number={4},
	pages={438-43},
	note={M1: Copyright 1994, IEE},
	abstract={Binary morphological operations with single and multiple structuring elements are implemented using look-up table (LUT) driven templates. Many complex operations can be implemented in one pipeline processing cycle for 3*3 regions of support and in four or five cycles for 5*5 regions of support. The basis representation of the operations is used to specify the required templates},
	keywords={filtering and prediction theory; mathematical morphology; pattern recognition; pipeline processing; table lookup},
	isbn={0162-8828},
	url={http://dx.doi.org/10.1109/34.277599}
}

@article{RefWorks:491,
	author={M. J. Swain and D. H. Ballard},
	year={1991},
	month={11},
	title={Color indexing},
	journal={International Journal of Computer Vision},
	volume={7},
	number={1},
	pages={11-32},
	note={M1: Copyright 1992, IEE},
	abstract={Two fundamental goals in computer vision are determining the identification location of a known object. Color can be successfully used for both tasks. This article demonstrates that color histograms of multicolored objects provide a robust, efficient cue for indexing into a large database of models. It shows that color histograms are stable object representations in the presence of occlusion and over change in view, and that they can differentiate among a large number of objects. For solving the identification problem, it introduces a technique called Histogram Intersection which matches model and image histograms and a fast incremental version of Histogram Intersection, which allows real-time indexing into a large database of stored models. For solving the location problem it introduces an algorithm called Histogram Backprojection, which performs this task efficiently in crowded scenes},
	keywords={colour; computer vision},
	isbn={0920-5691}
}

@inproceedings{RefWorks:492,
	author={R. J. Wood and S. Avadhanula and E. Steltz and M. Seeman and J. Entwistle and A. Bachrach and G. Barrows and S. Sanders and R. S. Fearing},
	year={2005},
	month={6-10 Nov. 2005},
	title={Design, fabrication and initial results of a 2g autonomous glider},
	booktitle={Thirty-First Annual Conference of the IEEE Industrial Electronics Society},
	series={IECON 2005},
	publisher={IEEE},
	address={Raleigh, NC, USA},
	organization={California Univ., Berkeley, CA, USA},
	pages={8},
	note={M1: Copyright 2006, The Institution of Engineering and Technology; T3: IECON 2005. Thirty-First Annual Conference of the IEEE Industrial Electronics Society (IEEE Cat. No.05CH37699)},
	abstract={Utilizing the core technologies of emerging microrobotic structures, the rapid design and prototyping of a passive micro air vehicle with the final goal of locating an audio source while avoiding hazardous obstacles is presented. The airfoil and control surfaces are optimized empirically to maximize lift and maneuverability while minimizing drag. Bimorph piezoelectric bending cantilevers actuate the control surfaces. Since such actuators require high voltages, an efficient boost circuit is presented along with appropriate high voltage electronics. To locate audio sources, a pair of acoustic sensors is designed and prototyped using a phase detection algorithm while a custom optic flow sensor is developed to avoid obstacles and give estimates of object distances and velocities. Finally, each subsystem is demonstrated and the complete glider is integrated to demonstrate initial open loop control performance},
	keywords={acoustic radiators; aerospace robotics; collision avoidance; microrobots; open loop systems; piezoelectric actuators; power electronics},
	isbn={0 7803 9252 3}
}

@inproceedings{RefWorks:493,
	author={R. 1. Sukthankar and R. G. 1. Stockton and M. D. 1. Mullin},
	year={2001},
	month={7-14 July 2001},
	title={Smarter presentations: exploiting homography in camera-projector systems},
	booktitle={Proceedings Eighth IEEE International Conference on Computer Vision},
	publisher={IEEE Comput. Soc},
	address={Vancouver, BC, Canada},
	organization={Just Res., Pittsburgh, PA, USA},
	volume={1},
	pages={247-53},
	note={M1: Copyright 2001, IEE; T3: Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001},
	abstract={Standard presentation systems consisting of a laptop connected to a projector suffer from two problems: (1) the projected image appears distorted (keystoned) unless the projector is precisely aligned to the projection screen; (2) the speaker is forced to interact with the computer rather than the audience. This paper shows how the addition of an uncalibrated camera, aimed at the screen, solves both problems. Although the locations, orientations and optical parameters of the camera and projector are unknown, the projector-camera system calibrates itself by exploiting the homography between the projected slide and the camera image. Significant improvements are possible over passively calibrating systems since the projector actively manipulates the environment by placing feature points into the scene. For instance, using a low-resolution (160&times;120) camera, we can achieve an accuracy of &plusmn;3 pixels in a 1024&times;768 presentation slide. The camera-projector system infers models for the projector-to-camera and projector-to-screen mappings in order to provide two major benefits},
	keywords={business graphics; technical presentation},
	isbn={0 7695 1143 0},
	url={http://dx.doi.org/10.1109/ICCV.2001.937525}
}

@article{RefWorks:494,
	author={Yu Liu and King Ngi Ngan},
	year={2007},
	title={Fast multiresolution motion estimation algorithms for wavelet-based scalable video coding},
	journal={Signal Processing: Image Communication},
	volume={22},
	number={5},
	pages={448-465},
	note={Compilation and indexing terms, Copyright 2008 Elsevier Inc.},
	abstract={Motion estimation and compensation in wavelet domain have received much attention recently. To overcome the inefficiency of motion estimation in critically sampled wavelet domain, the low-band-shift (LBS) method and the complete-to-overcomplete discrete wavelet transform (CODWT) method are proposed for motion estimation in shift-invariant wavelet domain. However, a major disadvantage of these methods is the computational complexity. Although the CODWT method has reduced the computational complexity by skipping the inverse wavelet transform and making the direct link between the critically sampled subbands and the shift-invariant subbands, the full search algorithm (FSA) increases it. In this paper, we proposed two fast multiresolution motion estimation algorithms in shift-invariant wavelet domain: one is the wavelet matching error characteristic based partial distortion search (WMEC-PDS) algorithm, which improves computational efficiency of conventional partial distortion search algorithms while keeping the same estimate accuracy as the FSA; another is the anisotropic double cross search (ADCS) algorithm using multiresolution-spatio-temporal context, which provides a significantly computational load reduction while only introducing negligible distortion compared with the FSA. Due to the multiresolution nature, both the proposed approaches can be applied to wavelet-based scalable video coding. Experimental results show the superiority of the proposed fast motion estimation algorithms against other fast algorithms in terms of speed-up and quality. &copy; 2007 Elsevier B.V. All rights reserved.},
	keywords={Algorithms; Computational complexity; Image coding; Motion estimation; Wavelet analysis},
	isbn={0923-5965},
	url={http://dx.doi.org/10.1016/j.image.2007.03.001}
}

@inproceedings{RefWorks:495,
	author={Hyeokho Choi1 and J. 1. Romberg and R. 1. Baraniuk and N. Kingsbury},
	year={2000},
	month={5-9 June 2000},
	title={Hidden Markov tree modeling of complex wavelet transforms},
	booktitle={Proceedings of 2000 International Conference on Acoustics, Speech and Signal Processing},
	publisher={IEEE},
	address={Istanbul, Turkey},
	organization={Dept. of Electr. \& Comput. Eng., Rice Univ., Houston, TX, USA},
	volume={1},
	pages={133-6},
	note={M1: Copyright 2000, IEE; T3: 2000 IEEE International Conference on Acoustics, Speech, and Signal Processing. Proceedings (Cat. No.00CH37100)},
	abstract={Multiresolution signal and image models such as the hidden Markov tree aim to capture the statistical structure of smooth and singular (edgy) regions. Unfortunately, models based on the orthogonal wavelet transform suffer from shift-variance, making them less accurate and realistic. We extend the HMT modeling framework to the complex wavelet transform, which features near shift-invariance and improved angular resolution compared to the standard wavelet transform. The model is computationally efficient (with linear-time computation and processing algorithms) and applicable to general Bayesian inference problems as a prior density for the data. In a simple estimation experiment, the complex wavelet HMT model outperforms a number of high-performance denoising algorithms, including redundant wavelet thresholding (cycle spinning) and the redundant HMT},
	keywords={AWGN; channel bank filters; filtering theory; hidden Markov models; image resolution; trees (mathematics); wavelet transforms},
	isbn={0 7803 6293 4},
	url={http://dx.doi.org/10.1109/ICASSP.2000.861889}
}

@article{RefWorks:496,
	author={M. S. 1. Crouse and R. D. Nowak and R. G. Baraniuk},
	year={1998},
	month={04},
	title={Wavelet-based statistical signal processing using hidden Markov models},
	journal={IEEE Transactions on Signal Processing},
	volume={46},
	number={4},
	pages={886-902},
	note={M1: Copyright 1998, IEE},
	abstract={Wavelet-based statistical signal processing techniques such as denoising and detection typically model the wavelet coefficients as independent or jointly Gaussian. These models are unrealistic for many real-world signals. We develop a new framework for statistical signal processing based on wavelet-domain hidden Markov models (HMMs) that concisely models the statistical dependencies and non-Gaussian statistics encountered in real-world signals. Wavelet-domain HMMs are designed with the intrinsic properties of the wavelet transform in mind and provide powerful, yet tractable, probabilistic signal models. Efficient expectation maximization algorithms are developed for fitting the HMMs to observational signal data. The new framework is suitable for a wide range of applications, including signal estimation, detection, classification, prediction, and even synthesis. To demonstrate the utility of wavelet-domain HMMs, we develop novel algorithms for signal denoising, classification, and detection},
	keywords={Gaussian noise; hidden Markov models; maximum likelihood detection; probability; signal processing; statistical analysis; wavelet transforms; white noise},
	isbn={1053-587X},
	url={http://dx.doi.org/10.1109/78.668544}
}

@article{RefWorks:497,
	author={Leonard E. Baum and Ted Petrie and George Soules and Norman Weiss},
	year={1970},
	title={A Maximization Technique Occurring in the Statistical Analysis of Probabilistic Functions of Markov Chains},
	journal={The Annals of Mathematical Statistics},
	volume={41},
	pages={164-171}
}

@article{RefWorks:498,
	author={Lloyd R. Welch},
	year={2003},
	title={Hidden Markov Models and the Baum-Welch Algorithm},
	journal={IEEE Information Theory Society Newsletter},
	note={The Shannon Lecture}
}

@article{RefWorks:499,
	author={M. 1. Pollefeys and L. Van Gool and M. Vergauwen and F. Verbiest and K. Cornelis and J. Tops and R. Koch},
	year={2004},
	title={Visual modeling with a hand-held camera},
	journal={International Journal of Computer Vision},
	volume={59},
	number={3},
	pages={207-32},
	note={M1: Copyright 2005, IEE},
	abstract={In this paper a complete system to build visual models from camera images is presented. The system can deal with uncalibrated image sequences acquired with a hand-held camera. Based on tracked or matched features the relations between multiple views are computed. From this both the structure of the scene and the motion of the camera are retrieved. The ambiguity on the reconstruction is restricted from projective to metric through self-calibration. A flexible multi-view stereo matching scheme is used to obtain a dense estimation of the surface geometry. From the computed data different types of visual models are constructed. Besides the traditional geometry- and image-based approaches, a combined approach with view-dependent geometry and texture is presented. As an application fusion of real and virtual scenes is also shown},
	keywords={calibration; cameras; computer vision; feature extraction; image matching; image reconstruction; image sequences; rendering (computer graphics); stereo image processing},
	isbn={0920-5691},
	url={http://dx.doi.org/10.1023/B:VISI.0000025798.50602.3a}
}

@inproceedings{RefWorks:500,
	author={Jingyu Yan and Marc Pollefeys},
	year={2006},
	month={Jun 17-22 2006},
	title={Automatic kinematic chain building from feature trajectories of articulated objects},
	booktitle={2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, CVPR 2006},
	publisher={Institute of Electrical and Electronics Engineers Computer Society, Piscataway, NJ 08855-1331, United States},
	address={New York, NY, United States},
	organization={Department of Computer Science, University of North Carolina at Chapel Hill, Chapel Hill, NC 27599},
	volume={1},
	pages={712-719},
	note={Compilation and indexing terms, Copyright 2008 Elsevier Inc.; T3: Proceedings - 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, CVPR 2006},
	abstract={We investigate the problem of learning the structure of an articulated object, i.e. its kinematic chain, from feature trajectories under affine projections. We demonstrate this possibility by proposing an algorithm which first segments the trajectories by local sampling and spectral clustering, then builds the kinematic chain as a minimum spanning tree of a graph constructed from the segmented motion subspaces. We test our method in challenging data sets and demonstrate the ability to automatically build the kinematic chain of an articulated object from feature trajectories. The algorithm also works when there are multiple articulated objects in the scene. Furthermore, we take into account non-rigid articulated parts that exist in human motions. We believe this advance will have impact on articulated object tracking and dynamical structure from motion. &copy; 2006 IEEE.},
	keywords={Object recognition; Problem solving; Learning systems; Algorithms; Graph theory; Image segmentation; Motion estimation},
	url={http://dx.doi.org/10.1109/CVPR.2006.66}
}

@inproceedings{RefWorks:501,
	author={Jingyu Yan and Marc Pollefeys},
	year={2006},
	month={May 7-13 2006},
	title={A general framework for motion segmentation: Independent, articulated, rigid, non-rigid, degenerate and non-degenerate*},
	booktitle={9th European Conference on Computer Vision, ECCV 2006},
	publisher={Springer Verlag, Heidelberg, D-69121, Germany},
	address={Graz, Austria},
	organization={Department of Computer Science, University of North Carolina at Chapel Hill, Chapel Hill, NC 27599, United States},
	volume={3954 NCS},
	pages={94-106},
	note={Compilation and indexing terms, Copyright 2008 Elsevier Inc.; T3: Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	abstract={We cast the problem of motion segmentation of feature trajectories as linear manifold finding problems and propose a general framework for motion segmentation under affine projections which utilizes two properties of trajectory data: geometric constraint and locality. The geometric constraint states that the trajectories of the same motion lie in a low dimensional linear manifold and different motions result in different linear manifolds; locality, by which we mean in a transformed space a data and its neighbors tend to lie in the same linear manifold, provides a cue for efficient estimation of these manifolds. Our algorithm estimates a number of linear manifolds, whose dimensions are unknown beforehand, and segment the trajectories accordingly. It first transforms and normalizes the trajectories; secondly, for each trajectory it estimates a local linear manifold through local sampling; then it derives the affinity matrix based on principal subspace angles between these estimated linear manifolds; at last, spectral clustering is applied to the matrix and gives the segmentation result. Our algorithm is general without restriction on the number of linear manifolds and without prior knowledge of the dimensions of the linear manifolds. We demonstrate in our experiments that it can segment a wide range of motions including independent, articulated, rigid, non-rigid, degenerate, non-degenerate or any combination of them. In some highly challenging cases where other state-of-the-art motion segmentation algorithms may fail, our algorithm gives expected results. &copy; Springer-Verlag Berlin Heidelberg 2006.},
	keywords={Motion control; Image segmentation; Problem solving; Constraint theory; Computational geometry; Algorithms},
	isbn={0302-9743}
}

@inproceedings{RefWorks:502,
	author={Jingyu Yan and Marc Pollefeys},
	year={2005},
	month={Jun 20-25 2005},
	title={A factorization-based approach to articulated motion recovery},
	booktitle={2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, CVPR 2005},
	publisher={Institute of Electrical and Electronics Engineers Computer Society, Piscataway, NJ 08855-1331, United States},
	address={San Diego, CA, United States},
	organization={Department of Computer Science, University of North Carolina at Chapel Hill, Chapel Hill, NC 27599, United States},
	volume={II},
	pages={815-821},
	note={Compilation and indexing terms, Copyright 2008 Elsevier Inc.; T3: Proceedings - 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, CVPR 2005},
	abstract={This paper addresses the subspace properties and the recovery of articulated motion. We point out that the global motion subspace of an articulated object is a combination of a number of intersecting rigid motion subspaces of the parts. Depending on whether a link of two parts is a joint or an axis, the global motion subspace loses one or two in rank for each link. The rank loss results from the intersection between the rigid motion subspaces of linked parts. Furthermore, the intersection is, in fact, the motion subspace of the link. From these observations, we describe the rank constraint of the global motion subspace of an articulated object; we give an algorithm to recover the image motion of a link, either a joint or an axix; and we propose a novel but simple approach, which is based on subspace clustering, to recover articulated shape and motion from a single-view image sequence.},
	keywords={Motion estimation; Image analysis; Constraint theory; Adaptive algorithms; Linear algebra; Computational methods},
	isbn={0769523722},
	url={http://dx.doi.org/10.1109/CVPR.2005.27}
}

@inproceedings{RefWorks:504,
	author={Jingyu Yan1 and M. 1. Pollefeys},
	year={2005},
	month={21 Oct. 2005},
	title={Articulated motion segmentation using RANSAC with priors},
	booktitle={Revised Papers},
	series={Dynamical Vision. ICCV 2005 and ECCV 2006 Workshops WDV 2005 and WDV 2006},
	publisher={Springer-Verlag},
	address={Beijing, China},
	organization={Dept. of Comput. Sci., North Carolina Univ., Chapel Hill, NC, USA},
	pages={75-85},
	note={M1: Copyright 2007, The Institution of Engineering and Technology; T3: Dynamical Vision. ICCV 2005 and ECCV 2006 Workshops WDV 2005 and WDV 2006. Revised Papers (Lecture Notes in Computer Science Vol. 4358)},
	abstract={Articulated motions are partially dependent. Most of the existing segmentation methods, e.g. Costeira and Kanade, can not be applied to articulated motions. We propose a novel algorithm for articulated motion segmentation called RANSAC with priors. It does not require prior knowledge of the number of articulated parts. It is both robust and efficient. Its robustness comes from its RANSAC nature. Its efficiency is due to the priors, which are derived from the spectral affinities between every pair of trajectories. We test our algorithm with synthetic and real data. In some highly challenging case, where other motion segmentation algorithms may fail, our algorithm still achieves robust results. Though our algorithm is inspired by articulated motions, it also applies to independent motions which can be regarded as a special case and treated uniformly},
	keywords={image segmentation; motion estimation},
	isbn={3 540 70931 2}
}

@article{RefWorks:505,
	author={M. S. 1. Jaeger and T. Mueller and T. Schnelle},
	year={2007},
	month={01/07},
	title={Thermometry in dielectrophoresis chips for contact-free cell handling},
	journal={Journal of Physics D (Applied Physics)},
	volume={40},
	number={1},
	pages={95-105},
	note={M1: Copyright 2007, The Institution of Engineering and Technology},
	abstract={Cell biology applications, protocols in immunology and stem cell research, require that individual cells are handled under strict control of their contacts to other cells or synthetic surfaces. Dielectrophoresis (DEP) in microfluidic chips is an established technique to investigate, group, wash, cultivate and sort cells contact-free under physiological conditions: microelectrode octode cages, versatile dielectrophoretic elements energized with radio frequency electric fields, stably trap single cells or cellular aggregates. For medical applications and cell cultivation, possible side effects of the dielectrophoretic manipulation, such as membrane polarization and Joule heating, have to be quantified. Therefore, we characterized the electric field-induced warming in dielectrophoretic cages using ohmic resistance measurements, fluorometry, liquid crystal beads, infra-red thermography and bubble size thermometry. We compare the results of these techniques with respect to the influences of voltage, electric conductivity of buffer, frequency, cage size and electrode surface. We conclude that in the culture medium thermal effects may be neglected if low voltages and an electric field-reducing phase pattern are used. Our experimental results provide explicit values for estimating the thermal effect on dielectrophoretically caged cells and show that Joule heating is best minimized by optimizing the cage geometry and reducing the buffer conductivity. The results may additionally serve to evaluate and improve theoretical predictions on field-induced effects. Based on present-day chip processing possibilities, DEP is well suited for the manipulation of cells},
	keywords={bioelectric phenomena; biological effects of fields; biothermics; cellular biophysics; electrophoresis; infrared imaging},
	isbn={0022-3727},
	url={http://dx.doi.org/10.1088/0022-3727/40/1/S14}
}

@inproceedings{RefWorks:506,
	author={M. P. 1. Hughes},
	year={2000},
	month={06},
	title={AC electrokinetics: applications for nanotechnology},
	booktitle={7th Foresight Conference on Molecular Nanotechnology},
	publisher={IOP Publishing},
	address={San Francisco, CA, USA},
	organization={European Inst. of Health & Med. Sci., Surrey Univ., Guildford, UK},
	volume={11},
	chapter={2},
	pages={124-32},
	note={M1: Copyright 2000, IEE; T3: Nanotechnology (UK)},
	abstract={The phenomena of dielectrophoresis and electrorotation, collectively referred to as AC electrokinetics, have been used for many years to study, manipulate and separate particles on the cellular (1 &mu;m or more) scale. However, the technique has much to offer the expanding field of nanotechnology, that is the precise manipulation of particles on the nanometre scale. In this paper we present the principles of AC electrokinetics for particle manipulation, review the current state of AC electrokinetic techniques for the manipulation of particles on the nanometre scale, and consider how these principles may be applied to nanotechnology},
	keywords={biological techniques; Brownian motion; colloids; electrokinetic effects; electrophoresis; nanotechnology; reviews; separation},
	isbn={0957-4484},
	url={http://dx.doi.org/10.1088/0957-4484/11/2/314}
}

@article{RefWorks:507,
	author={F. Yan and L. Cheng and H. Wang},
	year={2007},
	title={Higher density dual-tree discrete wavelet transform},
	journal={IET Signal Processing},
	volume={1},
	number={3},
	pages={164-169},
	note={Compilation and indexing terms, Copyright 2008 Elsevier Inc.},
	abstract={A new family of dual-tree based dyadic complex (approximate analytic) wavelet tight frames that is an extension of higher density discrete wavelet transform (DWT) introduced by Selesnick (in A Higher-density DWT, IEEE Transaction on Signal Processing) is proposed. Because the proposed wavelet frames are good combinations of the higher-density DWT and the dual tree complex wavelet transform, the corresponding new wavelet transform can be potentially applied to the applications when properties of both transforms are required simultaneously. The design problem to obtain finite impulse response filters satisfying the numerous constraints imposed by this new wavelet transform is addressed. The proposed wavelet frames are compactly supported, nearly shift-invariant, having vanishing moments and intermediate scales. Several explicit examples are discussed to illustrate the construction and properties of the wavelet frames. &copy; The Institution of Engineering and Technology 2007.},
	keywords={Wavelet transforms; Approximation theory; FIR filters; Signal processing; Trees (mathematics)},
	isbn={1751-9675},
	url={http://dx.doi.org/10.1049/iet-spr:20070028}
}

@article{RefWorks:508,
	author={I. W. 1. Selesnick},
	year={2004},
	month={05},
	title={The double-density dual-tree DWT},
	journal={IEEE Transactions on Signal Processing},
	volume={52},
	number={5},
	pages={1304-14},
	note={M1: Copyright 2004, IEE},
	abstract={This paper introduces the double-density dual-tree discrete wavelet transform (DWT), which is a DWT that combines the double-density DWT and the dual-tree DWT, each of which has its own characteristics and advantages. The transform corresponds to a new family of dyadic wavelet tight frames based on two scaling functions and four distinct wavelets. One pair of the four wavelets are designed to be offset from the other pair of wavelets so that the integer translates of one wavelet pair fall midway between the integer translates of the other pair. Simultaneously, one pair of wavelets are designed to be approximate Hilbert transforms of the other pair of wavelets so that two complex (approximately analytic) wavelets can be formed. Therefore, they can be used to implement complex and directional wavelet transforms. The paper develops a design procedure to obtain finite impulse response (FIR) filters that satisfy the numerous constraints imposed. This design procedure employs a fractional-delay allpass filter, spectral factorization, and filterbank completion. The solutions have vanishing moments, compact support, a high degree of smoothness, and are nearly shift-invariant},
	keywords={approximation theory; discrete wavelet transforms; filtering theory; FIR filters; Hilbert transforms; spectral analysis; trees (mathematics)},
	isbn={1053-587X},
	url={http://dx.doi.org/10.1109/TSP.2004.826174}
}

@article{RefWorks:509,
	author={I. W. Selesnick},
	year={2006},
	month={08},
	title={A higher density discrete wavelet transform},
	journal={IEEE Transactions on Signal Processing},
	volume={54},
	number={8},
	pages={3039-48},
	note={M1: Copyright 2006, The Institution of Engineering and Technology},
	abstract={This paper describes a new set of dyadic wavelet frames with two generators. The construction is simple, yet the wavelets cover the time-frequency plane in an arrangement that provides a higher sampling in both time and frequency. Specifically, the spectrum of the first wavelet is concentrated halfway between the spectrum of the second wavelet and the spectrum of its dilated version. In addition, the second wavelet is translated by half integers rather than whole integers in the frame construction. This arrangement leads to an expansive wavelet transform that is approximately shift invariant and has intermediate scales. The wavelet frames presented in this paper are compactly supported and have vanishing moments},
	keywords={discrete wavelet transforms; filtering theory; signal denoising; time-frequency analysis},
	isbn={1053-587X},
	url={http://dx.doi.org/10.1109/TSP.2006.875388}
}

@book{RefWorks:510,
	author={von Hippel, Eric v.},
	year={2005},
	title={Democratizing Innovation},
	publisher={The MIT Press},
	note={\url{http://web.mit.edu/evhippel/www/democ1.htm}},
	abstract={Innovation is rapidly becoming democratized. Users, aided by  improvements in computer and communications technology, increasingly  can develop their own new products and services. These innovating users  -- both individuals and firms -- often freely share their innovations  with others, creating user-innovation communities and a rich  intellectual commons. In Democratizing Innovation,  Eric von Hippel looks closely at this emerging system of user-centered  innovation. He explains why and when users find it profitable to  develop new products and services for themselves, and why it often pays  users to reveal their innovations freely for the use of all.
The trend toward democratized innovation can be seen  in software and information products -- most notably in the free and  open-source software movement -- but also in physical products. Von  Hippel's many examples of user innovation in action range from surgical  equipment to surfboards to software security features. He shows that  product and service development is concentrated among "lead users," who  are ahead on marketplace trends and whose innovations are often  commercially attractive.
Von Hippel argues  that manufacturers should redesign their innovation processes and that  they should systematically seek out innovations developed by users. He  points to businesses -- the custom semiconductor industry is one  example -- that have learned to assist user-innovators by providing  them with toolkits for developing new products. User innovation has a  positive impact on social welfare, and von Hippel proposes that  government policies, including R&D subsidies and tax credits,  should be realigned to eliminate biases against it. The goal of a  democratized user-centered innovation system, says von Hippel, is well  worth striving for. An electronic version of this book is available  under a Creative Commons license.}
}

@inproceedings{RefWorks:511,
	author={M. 1. Venkatraman and V. 1. Govindaraju},
	year={1995},
	month={23-26 Oct. 1995},
	title={Zero crossings of a non-orthogonal wavelet transform for object location},
	booktitle={Proceedings International Conference on Image Processing},
	publisher={IEEE Comput. Soc. Press},
	address={Washington, DC, USA},
	organization={Center of Excellence in Document Anal. & Recognition, State Univ. of New York, Buffalo, NY, USA},
	volume={3},
	pages={57-60},
	note={M1: Copyright 1996, IEE; T3: Proceedings. International Conference on Image Processing (Cat. No.95CB35819)},
	abstract={In this paper we address the task of segmentation of objects from photographs. A method of extraction of features based on the zero-crossings of a wavelet transform is described. The wavelet transform basis functions are derived from the second derivative of a Gaussian function. The extracted features are then used in a multilevel hypothesis generate and test algorithm to locate the objects of interest. The matching algorithm is based on the springs and templates framework of Fischler and Eschlanger (1973). The zero-crossings of the wavelet coefficients at different scales are combined in the model-matching stage to generate possible candidates. We apply this method to segment human faces from newspaper photographs},
	keywords={face recognition; feature extraction; image matching; image segmentation; object detection; wavelet transforms},
	isbn={0 7803 3122 2},
	url={http://dx.doi.org/10.1109/ICIP.1995.537579}
}

@article{RefWorks:512,
	author={Stephen Se and David Lowe and Jim Little},
	year={2002},
	title={Mobile robot localization and mapping with uncertainty using scale-invariant visual landmarks},
	journal={International Journal of Robotics Research},
	volume={21},
	number={8},
	pages={735-758},
	note={Compilation and indexing terms, Copyright 2008 Elsevier Inc.},
	abstract={A key component of a mobile robot system is the ability to localize itself accurately and, simultaneously, to build a map of the environment. Most of the existing algorithms are based on laser range finders, sonar sensors or artificial landmarks. In this paper, we describe a vision-based mobile robot localization and mapping algorithm, which uses scale-invariant image features as natural landmarks in unmodified environments. The invariance of these features to image translation, scaling and rotation makes them suitable landmarks for mobile robot localization and map building. With our Triclops stereo vision system, these landmarks are localized and robot ego-motion is estimated by least-squares minimization of the matched landmarks. Feature viewpoint variation and occlusion are taken into account by maintaining a view direction for each landmark. Experiments show that these visual landmarks are robustly matched, robot pose is estimated and a consistent three-dimensional map is built. As image features are not noise-free, we carry out error analysis for the landmark positions and the robot pose. We use Kalman filters to track these landmarks in a dynamic environment, resulting in a database map with landmark positional uncertainty.},
	keywords={Mobile robots; Uncertain systems; Algorithms; Computer vision; Error analysis; Database systems; Sonar; Range finders; Kalman filtering},
	isbn={0278-3649},
	url={http://dx.doi.org/10.1177/027836402761412467}
}

@PhdThesis{RefWorks:513,
  author =       {Mark Pupilli},
  title =        {Particle Filtering for Real-time Camera Localisation},
  school =       {Department of Computer Science, Bristol University},
  year =         {2006},
  note =         {\url{http://www.cs.bris.ac.uk/Publications/pub_master.jsp?id=2000621}}
}

@article{RefWorks:514,
	author={Ronald J. Mann},
	year={2006},
	title={Commercializing Open Source Software: Do Property Rights Still Matter?},
	journal={Harvard Journal of Law & Technology},
	volume={20},
	number={1},
	pages={1-47},
	note={\url{http://jolt.law.harvard.edu/articles/pdf/v20/20HarvJLTech001.pdf}}
}

@article{RefWorks:515,
	author={Chi-Man Pun and Moon-Chuen Lee},
	year={2004},
	title={Extraction of shift invariant wavelet features for classification of images with different sizes},
	journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
	volume={26},
	number={9},
	pages={1228-33},
	note={M1: Copyright 2004, IEE},
	abstract={An effective shift invariant wavelet feature extraction method for classification of images with different sizes is proposed. The feature extraction process involves a normalization followed by an adaptive shift invariant wavelet packet transform. An energy signature is computed for each subband of these invariant wavelet coefficients. A reduced subset of energy signatures is selected as the feature vector for classification of images with different sizes. Experimental results show that the proposed method can achieve high classification accuracy of 98.5 percent and outperforms the other two image classification methods},
	keywords={feature extraction; image classification; image texture; wavelet transforms},
	isbn={0162-8828},
	url={http://dx.doi.org/10.1109/TPAMI.2004.67}
}

@techreport{RefWorks:516,
	author={Jaroslav BoroviÄka},
	year={2003},
	title={Circle Detection Using Hough Transform Documentation},
	note={\url{http://linux.fjfi.cvut.cz/~pinus/bristol/imageproc/hw1/report.pdf}}
}

@techreport{RefWorks:517,
	author={Jean-Yves Bouget},
	title={Pyramidal Implementation of the Lucas Kanade Deature Tracker Description of the algorithm},
	note={\url{http://robots.stanford.edu/cs223b04/algo_tracking.pdf}},
        annote={OpenCV paper}
}

@article{RefWorks:518,
	author={G. E. Hinton and R. R. Satakhutdinov},
	year={2006},
	month={07/28},
	title={Reducing the dimensionality of data with neural networks},
	journal={Science},
	volume={313},
	number={5786},
	pages={504-7},
	note={M1: Copyright 2006, The Institution of Engineering and Technology},
	abstract={High-dimensional data can be converted to low-dimensional codes by training a multilayer neural network with a small central layer to reconstruct high-dimensional input vectors. Gradient descent can be used for fine-tuning the weights in such "autoencoder" networks, but this works well only if the initial weights are close to a good solution. We describe an effective way of initializing the weights that allows deep autoencoder networks to learn low-dimensional codes that work much better than principal components analysis as a tool. to reduce the dimensionality of data},
	keywords={data reduction; encoding; multilayer perceptrons},
	isbn={0036-8075},
	url={http://dx.doi.org/10.1126/science.1127647}
}

@article{RefWorks:519,
	author={M. Subbarao and G. Surya},
	year={1994},
	month={12},
	title={Depth from defocus: a spatial domain approach},
	journal={International Journal of Computer Vision},
	volume={13},
	number={3},
	pages={271-94},
	note={M1: Copyright 1995, IEE},
	abstract={A new method named STM is described for determining distance of objects and rapid STM uses image defocus information and is based on a new spatial-domain convolution/deconvolution transform. The method requires only two images taken with different camera parameters such as lens position, focal length, and aperture diameter. Both images can be arbitrarily blurred and neither of them needs to be a focused image. Therefore STM is very fast in comparison with depth-from-focus methods which search for the lens position or focal length of best focus. The method involves simple local operations and can be easily implemented in parallel to obtain the depth-map of a scene. STM has been implemented on an actual camera system named SPARCS. Experiments on the performance of STM and their results on real-world planar objects are presented. The results indicate that the accuracy of STM compares well with depth-from-focus methods and is useful in practical applications. The utility of the method is demonstrated for rapid autofocusing of electronic cameras},
	keywords={computer vision},
	isbn={0920-5691}
}

@article{RefWorks:520,
	author={J. 1. Portilla and E. P. 1. Simoncelli},
	year={2000},
	title={A parametric texture model based on joint statistics of complex wavelet coefficients},
	journal={International Journal of Computer Vision},
	volume={40},
	number={1},
	pages={49-71},
	note={M1: Copyright 2001, IEE},
	abstract={We present a universal statistical model for texture images in the context of an overcomplete complex wavelet transform. The model is parameterized by a set of statistics computed on pairs of coefficients corresponding to basis functions at adjacent spatial locations, orientations, and scales. We develop an efficient algorithm for synthesizing random images subject to these constraints, by iteratively projecting onto the set of images satisfying each constraint, and we use this to test the perceptual validity of the model. In particular, we demonstrate the necessity of subgroups of the parameter set by showing examples of texture synthesis that fail when those parameters are removed from the set. We also demonstrate the power of our model by successfully synthesizing examples drawn from a diverse collection of artificial and natural textures},
	keywords={computer vision; Markov processes; wavelet transforms},
	isbn={0920-5691},
	url={http://dx.doi.org/10.1023/A:1026553619983}
}

@article{RefWorks:521,
	author={J. 1. Portilla and V. Strela and M. J. Wainwright and E. P. Simoncelli},
	year={2003},
	month={11},
	title={Image denoising using scale mixtures of Gaussians in the wavelet domain},
	journal={IEEE Transactions on Image Processing},
	volume={12},
	number={11},
	pages={1338-51},
	note={M1: Copyright 2003, IEE},
	abstract={We describe a method for removing noise from digital images, based on a statistical model of the coefficients of an overcomplete multiscale oriented basis. Neighborhoods of coefficients at adjacent positions and scales are modeled as the product of two independent random variables: a Gaussian vector and a hidden positive scalar multiplier. The latter modulates the local variance of the coefficients in the neighborhood, and is thus able to account for the empirically observed correlation between the coefficient amplitudes. Under this model, the Bayesian least squares estimate of each coefficient reduces to a weighted average of the local linear estimates over all possible values of the hidden multiplier variable. We demonstrate through simulations with images contaminated by additive white Gaussian noise that the performance of this method substantially surpasses that of previously published methods, both visually and in terms of mean squared error},
	keywords={AWGN; Bayes methods; hidden Markov models; image denoising; image restoration; least squares approximations; parameter estimation; statistical analysis; wavelet transforms},
	isbn={1057-7149},
	url={http://dx.doi.org/10.1109/TIP.2003.818640}
}

@article{RefWorks:522,
	author={W. C. Y. Lam and S. Y. Yuen},
	year={1996},
	month={10},
	title={Efficient technique for circle detection using hypothesis filtering and Hough transform},
	journal={IEE Proceedings-Vision, Image and Signal Processing},
	volume={143},
	number={5},
	pages={292-300},
	note={M1: Copyright 1996, IEE},
	abstract={A fast circle detection method using a variant of Hough-like technique is reported. The proposed technique is simple in implementation, efficient in computation and robust to noise. In general, to evaluate circle parameters for all possible point triplets in an edge image containing n points, nC3 enumerations of the points have to be examined. However, if specific relations of the circle points are sought, the required number of enumerations can be reduced. The authors propose one such scheme of detection with point triplets possessing right angle property and the required enumerations can be reduced to nC2. Moreover, a novel processing strategy known as hypothesis filtering is introduced. The strategy includes two hypothesis constraints termed consistency checking with gradient angles and neighbouring points validation. Experimental results are demonstrated to reveal the performance of the method in detecting circles in both synthetic and real images. Since the proposed method adopts a right angle criterion for hypothesis, circles occluded or broken by more than one half may not be detected. Test results show that the limitation of the proposed method appears to be acceptable. When compared with established Hough transform techniques, the main strengths of the proposed detection method are its attractively computational and memory complexities and good accuracy of detection},
	keywords={computational complexity; edge detection; filtering theory; Hough transforms},
	isbn={1350-245X},
	url={http://dx.doi.org/10.1049/ip-vis:19960794}
}

@inproceedings{RefWorks:523,
	author={Ali Ajdari Rad and Karim Faez and Navid Qaragozlou},
	year={2003},
	title={Fast Circle Detection Using Gradient Pair Vectors},
	booktitle={DICTA},
	pages={879-888},
	note={\url{http://www.ms.sro.au/Hugues.Tabot/dta2003/drom/pdf/0879.pdf}}
}

@inproceedings{RefWorks:524,
	author={P. Azad and T. Asfour and R. Dillmann},
	year={2007},
	month={29 Oct.-2 Nov. 2007},
	title={Stereo-based 6D object localization for grasping with humanoid robot systems},
	booktitle={2007 IEEE/RSJ International Conference on Intelligent Robots and Systems},
	publisher={IEEE},
	address={San Diego, CA, USA},
	organization={Univ. of Karlsruhe, Karlsruhe, Germany},
	pages={919-24},
	note={M1: Copyright 2008, The Institution of Engineering and Technology; T3: 2007 IEEE/RSJ International Conference on Intelligent Robots and Systems},
	abstract={Robust vision-based grasping is still a hard problem for humanoid robot systems. When being restricted to using the camera system built-in into the robot's head for object localization, the scenarios get often very simplified in order to allow the robot to grasp autonomously. Within the computer vision community, many object recognition and localization systems exist, but in general, they are not tailored to the application on a humanoid robot. In particular, accurate 6D object localization in the camera coordinate system with respect to a 3D rigid model is crucial for a general framework for grasping. While many approaches try to avoid the use of stereo calibration, we will present a system that makes explicit use of the stereo camera system in order to achieve maximum depth accuracy. Our system can deal with textured objects as well as objects that can be segmented globally and are defined by their shape. Thus, it covers the cases of objects with complex texture and complex shape. Our work is directly linked to a grasping framework being implemented on the humanoid robot ARM AR and serves as its perception module for various grasping and manipulation experiments in a kitchen scenario.},
	keywords={humanoid robots; image texture; object recognition; robot vision; stereo image processing},
	isbn={978-1-4244-0911-2}
}

@book{RefWorks:525,
	author={Andrew Blake and Michael Isard},
	year={1998},
	title={Active Contours: The Application of Techniques from Graphics,Vision,Control Theory and Statistics to Visual Tracking of Shapes in Motion},
	address={Secaucus, NJ, USA},
	note={\url{http://research.microsoft.com/~ablake/contours/}}
}

@book{RefWorks:526,
	author={Bruce G. Batchelor and Paul F. Whelan},
	year={1997},
	title={Intelligent Vision Systems for Industry},
	publisher={Springer-Verlag New York, Inc},
	address={Secaucus, NJ, USA}},
	note={\url{http://elm.eeng.dcu.ie/~whelanp/ivsi/}},
	isbn={3540199691}
}

@book{RefWorks:527,
	author={S. M. LaValle},
	year={2006},
	title={Planning Algorithms},
	publisher={Cambridge University Press},
	note={\url{http://msl.cs.uiuc.edu/planning}}
}

@book{RefWorks:528,
	author={A. C. Kak and Malcolm Slaney},
	year={2001},
	title={Principles of computerized tomographic imaging},
	publisher={Society for Industrial and Applied Mathematics},
	address={Philadelphia, PA, USA},
	note={\url{http://cobweb.ecn.purdue.edu/~malcolm/pct/}},
	isbn={0-89871-494-X}
}

@book{RefWorks:529,
	author={D. H. Ballard and C. M. Brown},
	year={1982},
	title={Computer Vision},
	publisher={Prentice Hall},
	note={\url{http://homepages.inf.ed.ac.uk/rbf/BOOKS/BANDB/bandb.htm}}
}

@inproceedings{RefWorks:530,
	author={Jung-Me Park and C. G. Looney and Hui-Chuan Chen},
	year={2000},
	month={29-31 March 2000},
	title={Fast connected component labeling algorithm using a divide and conquer technique},
	booktitle={15th International Conference on Computers and their Applications},
	series={Proceedings of CATA-2000},
	publisher={Int. Soc. Comput. & Their Appl.- ISCA},
	address={New Orleans, LA, USA},
	organization={Dept. of Comput. Sci., Alabama Univ., Tuscaloosa, AL, USA},
	pages={373-6},
	note={\url{cs.ua.edu/research/TechnicalReports/TR-2000-04.pdf}},
	abstract={We investigate a method to speed up the O(n3) labeling algorithm of Rosenfeld and Pfaltz for segmenting binary images, which is unduly complex for large images. That algorithm searches line-by-line, top to bottom, to assign a blob label to each current pixel that is connected to a blob. A large number K of labels arises of which many are equivalent, so the equivalence must be resolved. This requires a K&times;K matrix to represent the connectivity and O(K3) operations for resolution, which is very large for large images. Our approach partitions the binary image into N&times;N rectangles and performs local equivalence resolution on each while keeping track of the global equivalence with list pointers to equivalence lists. Such a divide and conquer technique greatly increases the run time speed},
	keywords={computational complexity; divide and conquer methods; image representation; image resolution; image segmentation; matrix algebra; search problems},
	isbn={1 880843 32 3}
}

@inproceedings{RefWorks:531,
	author={K. Krajsek and R. Mester},
	year={2006},
	month={25-28 Feb. 2006},
	title={An unified theory for steerable and quadrature filters},
	booktitle={Proceedings},
	series={VISAPP 2006. First International Conference on Computer Vision Theory and Applications},
	publisher={Institute for Systems and Technologies of Information, Control and Communication},
	address={Setubal, Portugal},
	organization={Visual Sensorics \& Inf. Process. Lab., J. W. Goethe Univ., Frankfurt am Main, Germany},
	pages={8},
	note={\url{http://citeseer.ist.psu.edu/krajsek06unified.html} M1: Copyright 2007, The Institution of Engineering and Technology; T3: VISAPP 2006. First International Conference on Computer Vision Theory and Applications. Proceedings},
	abstract={In this paper, a complete theory of steerable filters is presented which shows that quadrature filters are only a special case of steerable filters. Although there have been a large number of approaches dealing with the theory of steerable filters, none of these gives a complete theory with respect to the transformation groups which deform the filter kernel. Michaelis and Sommer (1995) and Hel-Or and Teo (1996; 1998) were the first ones who gave a theoretical justification for steerability based on Lie group theory. But the approach of Michaelis and Sommer considers only Abelian Lie groups. Although the approach of Hel-Or and Teo considers all Lie groups, their method for generating the basis functions may fail as shown in this paper. We extend these steerable approaches to arbitrary Lie groups, like the important case of the rotation group SO(3) in three dimensions. Quadrature filters serve for computing the local energy and local phase of a signal. Whereas for the one dimensional case quadrature filters are theoretically well founded, this is not the case for higher dimensional signal spaces. The monogenic signal (Felsberg and Sommer, 2001) based on the Riesz transformation has been shown to be a rotational invariant generalization of the analytic signal. A further generalization of the monogenic signal, the 2D rotational invariant quadrature filter (Kothe, 2003), has been shown to capture richer structures in images as the monogenic signal. We present a generalization of the rotational invariant quadrature filter based on our steerable theory. Our approach includes the important case of 3D rotational invariant quadrature filters but it is not limited to any signal dimension and includes all transformation groups that own a unitary group representation},
	keywords={filtering theory; Lie groups},
	isbn={972 8865 40 6}
}


@article{RefWorks:532,
	author={Brandon Whitcher and Thomas Lee C.M. and Jeffrey Weiss B. and Timothy J. Hoar and Douglas W. Nychka},
	year={2008},
	month={June},
	title={A multi-resolution census algorithm for calculating vortex statistics in turbulent flows},
	journal={Journal of the Royal Statistical Society: Series C (Applied Statistics)},
	volume={57},
	number={3},
	pages={293-312},
	isbn={0035-9254},
	url={10.1111/j.1467-9876.2007.00614.x; http://dx.doi.org/10.1111/j.1467-9876.2007.00614.x}
}

@article{RefWorks:533,
	author={Zhengyou Zhang},
	year={2003},
	month={May 23-24},
	title={Vision-based Interaction with Fingers and Papers},
	journal={Proc. International Symposium on the CREST Digital Archiving Project},
	pages={83-106},
	note={\url{http://research.microsoft.com/users/zhang/Papers/CREST03.pdf}}
}

@inproceedings{RefWorks:534,
	author={Johnny C. Lee and Paul H. Dietz and Dan Maynes-Aminzade and Ramesh Raskar and Scott E. Hudson},
	year={2004},
	month={Oct 24-27 2004},
	title={Automatic projector calibration with embedded light sensors},
	booktitle={UIST: Proceedings of the Annual ACM Symposium on User Interface Software and Technology},
	publisher={Association for Computing Machinery, New York, NY 10036-5701, United States},
	address={Santa Fe, NM, United States},
	organization={Human-Computer Interaction Institute, Carnegie Mellon University, Pittsburgh, PA 15213, United States},
	pages={123-126},
	note={Compilation and indexing terms, Copyright 2008 Elsevier Inc.; T3: UIST: Proceedings of the Annual ACM Symposium on User Interface Softaware and Technology},
	abstract={Projection technology typically places several constraints on the geometric relationship between the projector and the projection surface to obtain an undistorted, properly sized image. In this paper we describe a simple, robust, fast, and low-cost method for automatic projector calibration that eliminates many of these constraints. We embed light sensors in the target surface, project Gray-coded binary patterns to discover the sensor locations, and then prewarp the image to accurately fit the physical features of the projection surface. This technique can be expanded to automatically stitch multiple projectors, calibrate onto nonplanar surfaces for object decoration, and provide a method for simple geometry acquisition. Copyright &copy; 2004 ACM.},
	keywords={Projection systems; Sensors; Calibration; Holography; Computer vision; Lighting; Image quality; Computer software; Human computer interaction}
}

@inproceedings{RefWorks:535,
	author={D. Comaniciu and V. Ramesh and P. Meer},
	year={2000},
	month={13-15 June 2000},
	title={Real-time tracking of non-rigid objects using mean shift},
	booktitle={CVPR 2000},
	series={Proceedings IEEE Conference on Computer Vision and Pattern Recognition},
	publisher={IEEE Comput. Soc},
	address={Hilton Head Island, SC, USA},
	organization={Imaging \& Visualization Dept., Siemens Corp. Res. Inc., Princeton, NJ, USA},
	volume={2},
	pages={142-9},
	note={M1: Copyright 2000, IEE; T3: Proceedings IEEE Conference on Computer Vision and Pattern Recognition. CVPR 2000 (Cat. No.PR00662)},
	abstract={A new method for real time tracking of non-rigid objects seen from a moving camera is proposed. The central computational module is based on the mean shift iterations and finds the most probable target position in the current frame. The dissimilarity between the target model (its color distribution) and the target candidates is expressed by a metric derived from the Bhattacharyya coefficient. The theoretical analysis of the approach shows that it relates to the Bayesian framework while providing a practical, fast and efficient solution. The capability of the tracker to handle in real time partial occlusions, significant clutter, and target scale variations, is demonstrated for several image sequences},
	keywords={Bayes methods; computer vision; image sequences; iterative methods; optical tracking; real-time systems},
	isbn={0 7695 0662 3},
	url={http://dx.doi.org/10.1109/CVPR.2000.854761}
}

@article{RefWorks:536,
	author={M. Michaelis and G. Sommer},
	year={1995},
	month={11},
	title={A Lie group approach to steerable filters},
	journal={Pattern Recognition Letters},
	volume={16},
	number={11},
	pages={1165-74},
	note={M1: Copyright 1995, IEE},
	abstract={Freeman and Adelson (1991) and Simoncelli et al. (1992) published an approach to steer filters in their orientation and scale by Fourier decompositions. The authors present a generalization of their formalism based on Lie group theory. Within this framework they especially clarify the following points: (1) the possible scope of steerability by Fourier decompositions, (2) approximate steerability with a limited number of basis functions, (3) the singularity that occurs when steering the scale},
	keywords={eigenvalues and eigenfunctions; filtering theory; Fourier transforms; Lie groups},
	isbn={0167-8655},
	url={http://dx.doi.org/10.1016/0167-8655(95)00066-P}
}

@article{RefWorks:537,
	author={P. Perona},
	year={1995},
	month={05},
	title={Deformable kernels for early vision},
	journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
	volume={17},
	number={5},
	pages={488-99},
	note={M1: Copyright 1995, IEE},
	abstract={Early vision algorithms often have a first stage of linear-filtering that `extracts' from the image information at multiple scales of resolution and multiple orientations. A common difficulty in the design and implementation of such schemes is that one feels compelled to discretize coarsely the space of scales and orientations in order to reduce computation and storage costs. A technique is presented that allows: 1) computing the best approximation of a given family using linear combinations of a small number of `basis' functions; and 2) describing all finite-dimensional families, i.e., the families of filters for which a finite dimensional representation is possible with no error. The technique is based on singular value decomposition and may be applied to generating filters in arbitrary dimensions and subject to arbitrary deformations. The relevant functional analysis results are reviewed and precise conditions for the decomposition to be feasible are stated. Experimental results are presented that demonstrate the applicability of the technique to generating multiorientation multi-scale 2D edge-detection kernels. The implementation issues are also discussed},
	keywords={approximation theory; computer vision; edge detection; filtering theory; functional analysis; image representation; singular value decomposition},
	isbn={0162-8828},
	url={http://dx.doi.org/10.1109/34.391394}
}

@inproceedings{RefWorks:538,
	author={E. Rosten and T. Drummond},
	year={2006},
	month={7-13 May 2006},
	title={Machine learning for high-speed corner detection},
	booktitle={Proceedings, Part I},
	series={Computer Vision - ECCV 2006. 9th European Conference on Computer Vision},
	publisher={Springer-Verlag},
	address={Graz, Austria},
	organization={Dept. of Eng., Cambridge Univ., UK},
	pages={430-43},
	note={M1: Copyright 2006, The Institution of Engineering and Technology; T3: Computer Vision - ECCV 2006. 9th European Conference on Computer Vision. Proceedings, Part I (Lecture Notes in Computer Science Vol. 3951)},
	abstract={Where feature points are used in real-time frame-rate applications, a high-speed feature detector is necessary. Feature detectors such as SIFT (DoG), Harris and SUSAN are good methods which yield high quality features, however they are too computationally intensive for use in real-time applications of any complexity. Here we show that machine learning can be used to derive a feature detector which can fully process live PAL video using less than 7% of the available processing time. By comparison neither the Harris detector (120%) nor the detection stage of SIFT (300%) can operate at full frame rate. Clearly a high-speed detector is of limited use if the features produced are unsuitable for downstream processing. In particular, the same scene viewed from two different positions should yield features which correspond to the same real-world 3D locations. Hence the second contribution of this paper is a comparison corner detectors based on this criterion applied to 3D scenes. This comparison supports a number of claims made elsewhere concerning existing corner detectors. Further, contrary to our initial expectations, we show that despite being principally constructed for speed, our detector significantly outperforms existing feature detectors according to this criterion},
	keywords={learning (artificial intelligence); object detection},
	isbn={3 540 33832 2}
}

@article{RefWorks:539,
	author={A. Criminisi and I. Reid and A. Zisserman},
	year={1999},
	month={06},
	title={A plane measuring device},
	journal={Image and Vision Computing},
	volume={17},
	number={8},
	pages={625-34},
	note={M1: Copyright 1999, IEE},
	abstract={A requirement of a visual measurement device is that both measurements and their uncertainties can be determined. This paper develops an uncertainty analysis which includes both the errors in image localization and the uncertainty in the imaging transformation. The matrix representing the imaging transformation is estimated from image-to-world point correspondences. A general expression is derived for the covariance of this matrix. This expression is valid if the matrix is over determined and also if the minimum number of correspondences are used. A bound on the errors of the first order approximations involved is also derived. Armed with this covariance result the uncertainty of any measurement can be predicted, and furthermore the distribution of correspondences can be chosen to achieve a particular bound on the uncertainty. Examples are given of measurements such as distance and parallelism for several applications. These include indoor scenes and architectural measurements},
	keywords={computer vision; error analysis},
	isbn={0262-8856},
	url={http://dx.doi.org/10.1016/S0262-8856(98)00183-8}
}

@inproceedings{RefWorks:540,
	author={V. Lepetit and P. Lagger and P. Fua},
	year={2005},
	month={20-25 June 2005},
	title={Randomized trees for real-time keypoint recognition},
	booktitle={2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
	series={Proceedings},
	publisher={IEEE Comput. Soc},
	address={San Diego, CA, USA},
	organization={Comput. Vision Lab., Ecole Polytech. Fed. de Lausanne, Switzerland},
	volume={2},
	pages={775-81},
	note={M1: Copyright 2005, IEE; T3: Proceedings. 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
	abstract={In earlier work, we proposed treating wide baseline matching of feature points as a classification problem, in which each class corresponds to the set of all possible views of such a point. We used a K-mean plus Nearest Neighbor classifier to validate our approach, mostly because it was simple to implement. It has proved effective but still too slow for real-time use. In this paper, we advocate instead the use of randomized trees as the classification technique. It is both fast enough for real-time performance and more robust. It also gives us a principled way not only to match keypoints but to select during a training phase those that are the most recognizable ones. This results in a real-time system able to detect and position in 3D planar, non-planar, and even deformable objects. It is robust to illuminations changes, scale changes and occlusions},
	keywords={feature extraction; learning (artificial intelligence); object detection; pattern classification; pattern matching; real-time systems; trees (mathematics)},
	isbn={0 7695 2372 2}
}

@book{RefWorks:541,
	author={Hal Fulton},
	year={2006},
        month=nov,
	title={The Ruby Way},
	publisher={Addison Wesley},
	note={\url{http://rubyhacker.com/}}
}

@article{RefWorks:542,
	author={S. Alkaabi and F. Deravi},
	year={2004},
	month={01/08},
	title={Candidate pruning for fast corner detection},
	journal={Electronics Letters},
	volume={40},
	number={1},
	pages={18-19},
	note={M1: Copyright 2004, IEE},
	abstract={A novel scheme for fast corner detection is presented. This is based on pruning candidate corners to reduce the need for computing local autocorrelation. The algorithm is tested on real image sequences and compared with other widely used corner detectors},
	keywords={computational complexity; correlation methods; edge detection; eigenvalues and eigenfunctions; image sequences},
	isbn={0013-5194},
	url={http://dx.doi.org/10.1049/el:20040023}
}

@inproceedings{RefWorks:543,
	author={R. Laganiere},
	year={1998},
	month={4-7 Jan. 1998},
	title={Morphological corner detection},
	booktitle={Proceedings of IEEE 6th International Conference on Computer Vision},
	publisher={Narosa Publishing House},
	address={New Delhi, India},
	organization={Sch. of Inf. Technol. \& Eng., Ottawa Univ., Ont., Canada},
	pages={280-5},
	note={M1: Copyright 1998, IEE; T3: Sixth International Conference on Computer Vision (IEEE Cat. No.98CH36271)},
	abstract={This paper presents a new operator for corner detection. This operator uses a variant of the morphological closing operator, which we have called asymmetrical closing. It consists of the successive application of different morphological transformations using different structuring elements. Each of these structuring elements used to probe the image under study is tuned to affect corners of different orientation and brightness. We found that this kind of approach, based on brightness comparisons, leads to better quality results than others and is achieved at a lower computational cost},
	keywords={edge detection},
	isbn={81 7319 221 9},
	url={http://dx.doi.org/10.1109/ICCV.1998.710731}
}

@inproceedings{RefWorks:544,
	author={Robert J. Barsanti and Edwin Spencer and James Cares and Lucas Parobek},
	year={2006},
	month={Mar 5-7 2006},
	title={Feature matching and signal recognition using wavelet analysis},
	booktitle={38th Southeastern Symposium on System Theory},
	publisher={Institute of Electrical and Electronics Engineers Inc},
	address={Piscataway, NJ 08855-1331, United States},
	organization={Department of Electrical and Computer Engineering, Citadel, Charleston, SC, 29407, United States},
	volume={2006},
	pages={448-452},
	note={Compilation and indexing terms, Copyright 2008 Elsevier Inc.; T3: Proceedings of the Annual Southeastern Symposium on System Theory},
	abstract={This paper investigates the application of multi-resolution wavelet analysis to the problem of feature matching in the presence of additive white Gaussian noise. The proposed algorithm computes the normalized cross correlation between the signal and the feature, using filtered wavelet coefficients. Simulations are conducted comparing the method to the classical optimum receiver. &copy; 2006 IEEE.},
	keywords={Feature extraction; Signal processing; Wavelet transforms; Algorithms; Computer simulation; Correlation methods; Gaussian noise (electronic)}
}

@article{RefWorks:545,
	author={A. S. Mian and M. Bennamoun and R. A. Owens},
	year={2006},
	month={01},
	title={A novel representation and feature matching algorithm for automatic pairwise registration of range images},
	journal={International Journal of Computer Vision},
	volume={66},
	number={1},
	pages={19-40},
	note={M1: Copyright 2006, The Institution of Engineering and Technology},
	abstract={Automatic registration of range images is a fundamental problem in 3D modeling of free-form objects. Various feature matching algorithms have been proposed for this purpose. However, these algorithms suffer from various limitations mainly related to their applicability, efficiency, robustness to resolution, and the discriminating capability of the used feature representation. We present a novel feature matching algorithm for automatic pairwise registration of range images which overcomes these limitations. Our algorithm uses a novel tensor representation which represents semi-local 3D surface patches of a range image by third order tensors. Multiple tensors are used to represent each range image. Tensors of two range images are matched to identify correspondences between them. Correspondences are verified and then used for pairwise registration of the range images. Experimental results show that our algorithm is accurate and efficient. Moreover, it is robust to the resolution of the range images, the number of tensors per view, the required amount of overlap, and noise. Comparisons with the spin image representation revealed that our representation has more discriminating capabilities and performs better at a low resolution of the range images},
	keywords={feature extraction; image matching; image registration; image representation; tensors},
	isbn={0920-5691},
	url={http://dx.doi.org/10.1007/s11263-005-3221-0}
}

@article{RefWorks:546,
	author={Gong-Jian Wen and Jin-jian Lv and Wen-xian Yu},
	year={2008},
	month={04},
	title={A high-performance feature-matching method for image registration by combining spatial and similarity information},
	journal={IEEE Transactions on Geoscience and Remote Sensing},
	volume={46},
	number={4},
	pages={1266-77},
	note={M1: Copyright 2008, The Institution of Engineering and Technology},
	abstract={A crucial problem that involves feature-based image registration algorithms is how to reliably establish the correspondence between the features detected in the sensed image and those detected in the reference image. Generally, most existing methods only use spatial relations or feature similarity, or a simple combination of them, to solve this problem, and all have some limitations. In this paper, a new feature-matching strategy is developed. It is realized by introducing a function whose independent variable is the match matrix, which describes the correspondence of the features, to combine spatial relations and organically feature similarity, and its global maximum is assumed to be reached if the sensed image is completely aligned with the reference image. Thus, the feature correspondence can be estimated by finding the maximum of the function. Two approaches are devised to solve the optimization problem. One is based on the branch-and-bound strategy to yield a global optimal solution, and the other uses an iterative algorithm that combines graduated assignment and variable metric methods to search for a local optimal solution with low computational complexity. The proposed method can work without the limitations of feature type, similarity criterion, and transform model, and its performance is evaluated using a variety of real images. Compared with some existing methods, it is fast and robust, and has the highest accuracy.},
	keywords={feature extraction; geophysical signal processing; image registration; remote sensing},
	isbn={0196-2892},
	url={http://dx.doi.org/10.1109/TGRS.2007.912443}
}

@article{RefWorks:547,
	author={Sungho Kim and In So Kweon},
	year={2005},
	month={12},
	title={Automatic model-based 3D object recognition by combining feature matching with tracking},
	journal={Machine Vision and Applications},
	volume={16},
	number={5},
	pages={267-72},
	note={M1: Copyright 2006, IEE},
	abstract={We propose a vision-based robust automatic 3D object recognition, which provides object identification and 3D pose information by combining feature matching with tracking. For object identification, we propose a robust visual feature and a probabilistic voting scheme. An initial object pose is estimated using correlations between the model image and the 3D CAD model, which are predefined, and the homography, byproduct of the identification. In tracking, Lie group formalism is used for robust and fast motion computation. Experimental results show that object recognition by the proposed method improves the recognition range considerably},
	keywords={CAD; correlation methods; image matching; Lie groups; object recognition; robot vision; tracking; Zernike polynomials},
	isbn={0932-8092},
	url={http://dx.doi.org/10.1007/s00138-005-0174-9}
}

@inproceedings{RefWorks:548,
	author={J. S. Beis and D. G. Lowe},
	year={1997},
	month={17-19 June 1997},
	title={Shape indexing using approximate nearest-neighbour search in high-dimensional spaces},
	booktitle={Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
	publisher={IEEE Comput. Soc},
	address={Los Alamitos, CA, USA},
	organization={Dept. of Comput. Sci., British Columbia Univ., Vancouver, BC, Canada},
	pages={1000-6},
	note={M1: Copyright 1997, IEE; T3: Proceedings. 1997 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.97CB36082)},
	abstract={Shape indexing is a way of making rapid associations between features detected in an image and object models that could have produced them. When model databases are large, the use of high-dimensional features is critical, due to the improved level of discrimination they can provide. Unfortunately, finding the nearest neighbour to a query point rapidly becomes inefficient as the dimensionality of the feature space increases. Past indexing methods have used hash tables for hypothesis recovery, but only in low-dimensional situations. In this paper we show that a new variant of the k-d tree search algorithm makes indexing in higher-dimensional spaces practical. This Best Bin First, or BBF search is an approximate algorithm which finds the nearest neighbour for a large fraction of the queries, and a very close neighbour in the remaining cases. The technique has been integrated into a fully developed recognition system, which is able to detect complex objects in real, cluttered scenes in just a few seconds},
	keywords={computer vision; feature extraction; indexing; tree searching; visual databases},
	isbn={0 8186 7822 4},
	url={http://dx.doi.org/10.1109/CVPR.1997.609451}
}

@article{RefWorks:549,
	author={S. Arya and D. M. Mount and N. Netanyahu and R. Silverman and A. Y. Wu},
	year={1998},
	month={11},
	title={An optimal algorithm for approximate nearest neighbor searching in fixed dimensions},
	journal={Journal of the ACM},
	volume={45},
	number={6},
	pages={891-923},
	note={M1: Copyright 1999, IEE},
	abstract={Consider a set S of n data points in real d-dimensional space, Rd, where distances are measured using any Minkowski metric. In nearest-neighbor searching, we preprocess S into a data structure so that, given any query point q&isin;Rd, the closest point of S to q can be reported quickly. Given any positive real &epsiv;, a data point p is a (1+&epsiv;)-approximate nearest neighbor of q if its distance from q is within a factor of (1+&epsiv;) of the distance to the true nearest neighbor. We show that it is possible to preprocess a set of n points in Rd in O(dn log n) time and O(dn) space, so that given a query point q&isin;Rd, and &epsiv;>0, a (1+&epsiv;)-approximate nearest neighbor of q can be computed in O(cd,&epsiv; log n) time, where cd,&epsiv;&les;d[1+6d/&epsiv;]d is a factor depending only on the dimension and &epsiv;. In general, we show that, given an integer k&ges;1, (1+&epsiv;)-approximations to the k nearest neighbors of q can be computed in additional O(kd log n) time},
	keywords={approximation theory; computational complexity; data structures; database theory; optimisation; query processing; search problems},
	isbn={0004-5411},
	url={http://dx.doi.org/10.1145/293347.293348}
}

@inproceedings{RefWorks:550,
	author={G. R. Bradski},
	year={1998},
	month={19-21 Oct. 1998},
	title={Real time face and object tracking as a component of a perceptual user interface},
	booktitle={Proceedings of WACV98 - Computer Vision},
	publisher={IEEE Comput. Soc},
	address={Los Alamitos, CA, USA},
	organization={Microcomput. Res. Lab., Intel Corp., USA},
	pages={214-19},
	note={M1: Copyright 1998, IEE; T3: Proceedings Fourth IEEE Workshop on Applications of Computer Vision. WACV'98 (Cat. No.98EX201)},
	abstract={As a step towards a perceptual user interface, an object tracking algorithm is developed and demonstrated tracking human faces. Computer vision algorithms that are intended to form part of a perceptual user interface must be fast and efficient. They must be able to track in real time and yet not absorb a major share of computational resources. An efficient, new algorithm is described here based on the mean shift algorithm. The mean shift algorithm robustly finds the mode (peak) of probability distributions. We first describe histogram based methods of producing object probability distributions. In our case, we want to track the mode of an object's probability distribution within a video scene. Since the probability distribution of the object can change and move dynamically in time, the mean shift algorithm is modified to deal with dynamically changing probability distributions. The modified algorithm is called the Continuously Adaptive Mean Shift (CAMSHIFT) algorithm. CAMSHIFT is then used as an interface for games and graphics},
	keywords={computer vision; graphical user interfaces; real-time systems},
	isbn={0 8186 8606 5},
	url={http://dx.doi.org/10.1109/ACV.1998.732882}
}

@inproceedings{RefWorks:551,
	author={E. Vincent and R. Laganiere},
	year={2001},
	month={19-21 June 2001},
	title={Detecting planar homographies in an image pair},
	booktitle={Proceedings of the 2nd International Symposium on Image and Signal Processing and Analysis},
	series={ISPA 2001},
	publisher={Univ. Zagreb},
	address={Zagreb, Croatia},
	organization={Sch. of Inf. Technol. \& Eng., Ottawa Univ., Ont., Canada},
	pages={182-7},
	note={M1: Copyright 2001, IEE; T3: ISPA 2001. Proceedings of the 2nd International Symposium on Image and Signal Processing and Analysis. In conjunction with 23rd International Conference on Information Technology Interfaces (IEEE Cat. No.01EX480)},
	abstract={Because of their abundance and simplicity, planes are used in several computer vision tasks. Their simplicity results in that, under perspective projection, the transformation between a world plane and its corresponding image plane is projective linear, or a homography. These relations also hold between perspective views of a plane in different images. This paper proposes an algorithm that detects planar homographies in uncalibrated image pairs. It then demonstrates how this plane identification method can be used as a first step in an image analysis process, when point matching between images is unreliable. The detection is performed using a RANSAC scheme based on the linear computation of the homography matrix elements using four points. Results are shown on real image pairs},
	keywords={computer vision; feature extraction; image matching; matrix algebra},
	isbn={953 96769 4 0},
	url={http://dx.doi.org/10.1109/ISPA.2001.938625}
}

@article{RefWorks:552,
	author={Gary R. Bradski},
	year={1998},
	title={Computer Vision Face Tracking For Use in a Perceptual User Interface},
	journal={Intel Technology Journal},
	number={Q2}
}

@article{RefWorks:553,
	author={B. K. P. Horn and B. G. Schunck},
	year={1981},
	month={08},
	title={Determining optical flow},
	journal={Artificial Intelligence},
	volume={17},
	number={1-3},
	pages={185-203},
	note={M1: Copyright 1982, IEE},
	abstract={Optical flow cannot be computed locally, since only one independent measurement is available from the image sequence at a point, while the flow velocity has two components. A second constraint is needed. A method for finding the optical flow pattern is presented which assumes that the apparent velocity of the brightness pattern varies smoothly almost everywhere in the image. An iterative implementation is shown which successfully computes the optical flow for a number of synthetic image sequences. The algorithm is robust in that it can handle image sequences that are quantized rather coarsely in space and time. It is also insensitive to quantization of brightness levels and additive noise. Examples are included where the assumption of smoothness is violated at singular points or along lines in the image},
	keywords={iterative methods; pattern recognition; picture processing},
	isbn={0004-3702},
	url={http://dx.doi.org/10.1016/0004-3702(81)90024-2}
}

@inproceedings{RefWorks:554,
	author={J. Klein and C. Lecomte and P. Miche},
	year={2007},
	month={11-14 Dec. 2007},
	title={Tracking objects in videos with texture features},
	booktitle={2007 14th IEEE International Conference on Electronics, Circuits and Systems (ICECS '07)},
	publisher={IEEE},
	address={Piscataway, NJ, USA},
	organization={Univ. of Rouen, Rouen, France},
	pages={546-9},
	note={M1: Copyright 2008, The Institution of Engineering and Technology; T3: 2007 14th IEEE International Conference on Electronics, Circuits and Systems (ICECS '07)},
	abstract={In this article, we address the problem of object tracking in videos for multimedia applications. To produce a reliable and robust tracking algorithm, several visual characteristics of the target object must be examined. The different sources of information must be carefully chosen so as to select only the most informative ones. We argue that color and texture cues can be both quickly handled by cooccurrence matrices. Yet these matrices are too sensitive to illumination changes occurring in natural scenes. By adding weights, drawn from kernels centered on representative colors of the object, the feature can cope with this matter. We provide experimental result obtained from different kinds of natural scenes.},
	keywords={image colour analysis; image texture; matrix algebra; multimedia communication},
	isbn={978-1-4244-1377-5}
}

@article{RefWorks:555,
	author={Gang Qian and R. Chellapa},
	year={2004},
	month={08},
	title={Structure from motion using sequential Monte Carlo methods},
	journal={International Journal of Computer Vision},
	volume={59},
	number={1},
	pages={5-31},
	note={M1: Copyright 2004, IEE},
	abstract={In this paper, the structure from motion (SfM) problem is addressed using sequential Monte Carlo methods. A new SfM algorithm based on random sampling is derived to estimate the posterior distributions of camera motion and scene structure for the perspective projection camera model. Experimental results show that challenging issues in solving the SfM problem, due to erroneous feature tracking, feature occlusion, motion/structure ambiguity, mixed-domain sequences, mismatched features, and independently moving objects, can be well modeled and effectively addressed using the proposed method},
	keywords={cameras; hidden feature removal; image sampling; Monte Carlo methods; motion estimation; random processes; video signal processing},
	isbn={0920-5691},
	url={http://dx.doi.org/10.1023/B:VISI.0000020669.68126.4b}
}

@inproceedings{RefWorks:556,
	author={D. A. Forsyth and S. Ioffe and J. Haddon},
	year={1999},
	month={20-27 Sept. 1999},
	title={Bayesian structure from motion},
	booktitle={Proceedings of the Seventh IEEE International Conference on Computer Vision},
	publisher={IEEE Comput. Soc},
	address={Los Alamitos, CA, USA},
	organization={Comput. Sci. Div., California Univ., Berkeley, CA, USA},
	volume={1},
	pages={660-5},
	note={M1: Copyright 1999, IEE; T3: Proceedings of the Seventh IEEE International Conference on Computer Vision},
	abstract={Formulates structure from motion as a Bayesian inference problem and uses a Markov-chain Monte Carlo sampler to sample the posterior on this problem. This results in a method that can identify both small and large tracker errors and yields reconstructions that are stable in the presence of these errors. Furthermore, the method gives detailed information on the range of ambiguities in structure given a particular data set and requires no special geometric formulation to cope with degenerate situations. Motion segmentation is obtained by a layer of discrete variables associating a point with an object. We demonstrate a sampler that successfully samples an approximation to the marginal on this domain, producing a relatively unambiguous segmentation},
	keywords={Bayes methods; computer vision; error detection; image reconstruction; image segmentation; importance sampling; inference mechanisms; Markov processes; motion estimation; uncertainty handling},
	isbn={0 7695 0164 8},
	url={http://dx.doi.org/10.1109/ICCV.1999.791288}
}

@inproceedings{RefWorks:557,
	author={A. Blake and M. Isard},
	year={1997},
	month={2-5 Dec. 1996},
	title={The CONDENSATION algorithm - conditional density propagation and applications to visual tracking},
	booktitle={Proceedings of the 1996 Conference},
	series={Advances in Neural Information Processing Systems 9},
	publisher={MIT Press},
	address={London, UK},
	organization={Dept. of Eng. Sci., Oxford Univ., UK},
	pages={361-7},
	note={M1: Copyright 1997, IEE; T3: Advances in Neural Information Processing Systems 9. Proceedings of the 1996 Conference},
	abstract={The power of sampling methods in Bayesian reconstruction of noisy signals is well known. The extension of sampling to temporal problems is discussed. Efficacy of sampling over time is demonstrated with visual tracking. More pervasive noise distributions, as commonly arise in visual background clutter, demand a more powerful, non-Gaussian approach. One very effective approach is to use random sampling. The CONDENSATION algorithm, described here, combines random sampling with learned dynamical models to propagate an entire probability distribution for object position and shape, over time. The result is accurate tracking of agile motion in clutter, decidedly more robust than what has previously been attainable by Kalman Altering. Despite the use of random sampling, the algorithm is efficient, running in near real-time when applied to visual tracking},
	keywords={computer vision; image recognition; image sequences; iterative methods; motion estimation; optical tracking; probability},
	isbn={0 262 10065 7}
}

@inproceedings{RefWorks:558,
	author={M. Isard and A. Blake},
	year={1996},
	month={Apr 1996},
	title={Contour tracking by stochastic propagation of conditional density},
	booktitle={Part 1 (of 2)},
	series={Proceedings of the 4th European Conference on Computer Vision, ECCV'96},
	volume={1064},
	pages={343},
	note={Compilation and indexing terms, Copyright 2008 Elsevier Inc.; T3: Lecture Notes in Computer Science}
}

@article{RefWorks:559,
	author={W. Landry},
	year={2003},
	title={Implementing a high performance tensor library},
	journal={Scientific Programming},
	volume={11},
	number={4},
	pages={273-90},
	note={M1: Copyright 2004, IEE},
	abstract={Template methods have opened up a new way of building C++ libraries. These methods allow the libraries to combine the seemingly contradictory qualities of ease of use and uncompromising efficiency. However, libraries that use these methods are notoriously difficult to develop. This article examines the benefits reaped and the difficulties encountered in using these methods to create a friendly, high performance, tensor library. We find that template methods mostly deliver on this promise, though requiring moderate compromises in usability and efficiency},
	keywords={C++ language; matrix algebra; software libraries; tensors},
	isbn={1058-9244}
}

@inproceedings{RefWorks:560,
	author={J. Wedekind and B. P. Amavasai and K. Dutton and M. Boissenin},
	year={2008},
	month={20-23 June 2008},
	title={A machine vision extension for the Ruby programming language},
	booktitle={2008 International Conference on Information and Automation (ICIA)},
	publisher={IEEE},
	address={Piscataway, NJ, USA},
	organization={Microsyst. \& Machine Vision Lab., Sheffield Hallam Univ., Sheffield, UK},
	pages={991-6},
	note={M1: Copyright 2008, The Institution of Engineering and Technology; T3: 2008 International Conference on Information and Automation (ICIA)},
	abstract={Dynamically typed scripting languages have become popular in recent years. Although interpreted languages allow for substantial reduction of software development time, they are often rejected due to performance concerns. In this paper we present an extension for the programming language Ruby, called HornetsEye, which facilitates the development of real-time machine vision algorithms within Ruby. Apart from providing integration of crucial libraries for input and output, HornetsEye provides fast native implementations (compiled code) for a generic set of array operators. Different array operators were compared with equivalent implementations in C++. Not only was it possible to achieve comparable real-time performance, but also to exceed the efficiency of the C++ implementation in several cases. Implementations of several algorithms were given to demonstrate how the array operators can be used to create concise implementations.},
	keywords={authoring languages; C++ language; computer vision; specification languages},
	isbn={978-1-4244-2183-1},
	url={http://dx.doi.org/10.1109/ICINFA.2008.4608143}
}

@article{RefWorks:561,
	author={Marcus Denker and Mathieu Suen and Stéphane Ducasse},
	year={2008},
	title={The Meta in Meta-object Architectures},
	journal={Proceedings of TOOLS EUROPE 2008, Lecture Notes in Business Information Processing},
	volume={11},
	pages={218--237},
	note={\url{http://www.iam.unibe.ch/~scg/Archive/Papers/Denk08bMetaContextLNBIP.pdf}}
}

@inbook{RefWorks:562,
  author =    {Ullrich KÃ¶the},
  editor =    {B. JÃ¤hne and H. HauÃecker and P. GeiÃler},
  series =        {Handbook on Computer Vision and Applications},
  title =      {Reusable software in computer vision},
  publisher =    {Academic Press},
  year =         {1999}
}

@inproceedings{RefWorks:563,
	author={X. Li and W. Hu and Z. Zhang and X. Zhang and G. Luo},
	year={2007},
	title={Robust Visual Tracking Based on Incremental Tensor Subspace Learning},
	booktitle={IEEE 11th International Conference on Computer Vision, 2007. ICCV 2007}
}

@inproceedings{RefWorks:564,
	author={Mao Vasilescu and D. Terzopoulos},
	year={2007},
	title={Multilinear Projection for Appearance-Based Recognition in the Tensor Framework},
	booktitle={IEEE 11th International Conference on Computer Vision, 2007. ICCV 2007},
	pages={1-8}
}

@article{RefWorks:565,
	author={M. Fowler},
	year={2001},
	title={To be explicit},
	journal={IEEE Software},
	volume={18},
	number={6},
	pages={10-15},
	note={Compilation and indexing terms, Copyright 2008 Elsevier Inc.; undefined; undefined; undefined; undefined; undefined},
	abstract={The drive toward changeability is why it's so important for a design to clearly show what the program does and how it does it. Three examples are presented to illustrate this. The first concerns attributes and dictionaries, the second on events and explicit calls, and the third on data-driven code and explicit subclasses.},
	keywords={Software engineering; Data structures; Computer programming languages; Algorithms; Codes (symbols); Glossaries; Electronic mail; Program debugging; Digital libraries},
	isbn={0740-7459},
	url={http://dx.doi.org/10.1109/52.965796}
}

@MastersThesis{RefWorks:566,
    author  = {Chris Lattner},
    title   = {LLVM: An Infrastructure for Multi-Stage Optimization},
    school  = {Computer Science Dept., University of Illinois at Urbana-Champaign},
    year    = {2002},
    address = {Urbana, IL},
    month   = dec,
    note    = {\url{http://llvm.cs.uiuc.edu}}
}

@article{RefWorks:567,
	author={A. Einstein},
	year={2005},
	title={Die Grundlage der allgemeinen Relativitatstheorie; The foundation of the general theory of relativity},
	journal={Annalen der Physik (Leipzig)},
	volume={14},
	pages={517-571},
	isbn={0003-3804},
	note={\url{http://www.alberteinstein.info/gallery/gtext3.html}}
}

@inproceedings{RefWorks:568,
	author={Peng Chang and M. Hebert},
	year={2002},
	month={11-15 May 2002},
	title={Robust tracking and structure from motion with sample based uncertainty representation},
	booktitle={Proceedings 2002 IEEE International Conference on Robotics and Automation},
	publisher={IEEE},
	address={Piscataway, NJ, USA},
	organization={Carnegie Mellon Univ., Pittsburgh, PA, USA},
	volume={3},
	pages={3030-7},
	note={M1: Copyright 2002, IEE; T3: Proceedings 2002 IEEE International Conference on Robotics and Automation (Cat. No.02CH37292); undefined; undefined; undefined; undefined; undefined; undefined; undefined; undefined; undefined},
	abstract={Geometric reconstruction of the environment from images is critical in autonomous mapping and robot navigation. Geometric reconstruction involves feature tracking, i.e., locating corresponding image features in consecutive images, and structure from motion (SFM), i.e., recovering the 3D structure of the environment from a set of correspondences between images. Although algorithms for feature tracking and structure from motion are well-established, their use in practical mobile robot applications is still difficult because of occluded features, non-smooth motion between frames, and ambiguous patterns in images. We show how a sampling-based representation can be used in place of the traditional Gaussian representation of uncertainty. We show how sampling can be used for both feature tracking and SFM and we show how they are combined in this framework. The approach is exercised in the context of a mobile robot navigating through an outdoor environment with an omnidirectional camera},
	keywords={filtering theory; mobile robots; path planning; probability; robot vision; tracking},
	isbn={0 7803 7272 7},
	url={http://dx.doi.org/10.1109/ROBOT.2002.1013692}
}

@inproceedings{RefWorks:569,
	author={A. J. Davison},
	year={2003},
	month={13-16 Oct. 2003},
	title={Real-time simultaneous localisation and mapping with a single camera},
	booktitle={ICCV 2003: 9th International Conference on Computer Vision},
	publisher={IEEE Comput. Soc},
	address={Los Alamitos, CA, USA},
	organization={Dept. of Eng. Sci., Oxford Univ., UK},
	volume={2},
	pages={1403-10},
	note={M1: Copyright 2004, IEE; T3: Proceedings Ninth IEEE International Conference on Computer Vision; undefined; undefined; undefined; undefined; undefined; undefined; undefined; undefined; undefined; undefined; undefined; undefined; undefined; undefined; undefined; undefined; undefined; undefined; undefined; undefined; undefined; undefined; undefined; undefined},
	abstract={Ego-motion estimation for an agile single camera moving through general, unknown scenes becomes a much more challenging problem when real-time performance is required rather than under the off-line processing conditions under which most successful structure from motion work has been achieved. This task of estimating camera motion from measurements of a continuously expanding set of self-mapped visual features is one of a class of problems known as Simultaneous Localisation and Mapping (SLAM) in the robotics community, and we argue that such real-time mapping research, despite rarely being camera-based, is more relevant here than off-line structure from motion methods due to the more fundamental emphasis placed on propagation of uncertainty. We present a top-down Bayesian framework for single-camera localisation via mapping of a sparse set of natural features using motion modelling and an information-guided active measurement strategy, in particular addressing the difficult issue of real-time feature initialisation via a factored sampling approach. Real-time handling of uncertainty permits robust localisation via the creating and active measurement of a sparse map of landmarks such that regions can be re-visited after periods of neglect and localisation can continue through periods when few features are visible. Results are presented of real-time localisation for a hand-waved camera with very sparse prior scene knowledge and all processing carried out on a desktop PC},
	keywords={Bayes methods; computer vision; feature extraction; motion estimation; real-time systems; video cameras},
	isbn={0 7695 1950 4},
	url={http://dx.doi.org/10.1109/ICCV.2003.1238654}
}

@inproceedings{RefWorks:570,
	author={D. -G Sim and H. -K Kim and D. -I Oh},
	year={2000},
	month={Sep 10-13 2000},
	title={Translation, scale, and rotation invariant texture descriptor for texture-based image retrieval},
	booktitle={International Conference on Image Processing (ICIP 2000)},
	publisher={Institute of Electrical and Electronics Engineers Computer Society},
	organization={Hyundai Electron. Indust., Co. Ltd., 1451-34 Seocho-dong Seocho-ku, Seoul, South Korea},
	volume={3},
	pages={742-745},
	note={Compilation and indexing terms, Copyright 2008 Elsevier Inc.; T3: IEEE International Conference on Image Processing; undefined; undefined},
	abstract={A texture descriptor invariant to translation, rotation and scale changes is presented in this paper. A power spectral image is obtained by using DFT transformation to extract the proposed descriptor for the translation invariance of a given texture. The power spectral image is scale-normalized by a cut-off frequency on the power spectral image that is calculated as the total energy inside a circle with its radius of the cut-off frequency amounts to a predetermined value. Finally, the rotation invariant Zernike moments are calculated on the translation and scale normalized image for a rotation, scale and translation invariant descriptor. The extraction is simple and fast, using fast known DFT and Zernike transformation. The matching is also simple and fast using the Euclidean distance measure between a query and test textures. The effectiveness of the proposed algorithm is shown with various texture databases.},
	keywords={Image retrieval; Feature extraction; Discrete Fourier transforms; Algorithms; Database systems; Object recognition; Computer vision; Multimedia systems; Color image processing}
}

@inproceedings{RefWorks:571,
	author={E. Vincent and R. Laganiere},
	title={An empirical study of some feature matching strategies},
	booktitle={Proc. 15th International Conference on Vision Interface},
	pages={139-145}
}

@inproceedings{RefWorks:572,
	author={A. Boffy and Y. Tsin and Y. Genc},
	year={2006},
	title={Real-Time Feature Matching using Adaptive and Spatially Distributed Classification Trees},
	booktitle={BMVC06},
	volume={II},
	pages={529}
}

@inproceedings{RefWorks:573,
	author={H. Yang and Q. Wang and Z. He},
	year={2008},
	title={Indexing Sub-Vector Distance for High-Dimensional Feature Matching},
	booktitle={BMVC08}
}

@book{RefWorks:574,
	author={R. Hartley and A. Zisserman},
	year={2003},
	title={Multiple view geometry in computer vision},
	publisher={Cambridge university press}
}

@article{RefWorks:575,
	author={Elisabetta Delponte and Francesco Isgro and Francesca Odone and Alessandro Verri},
	year={2006},
	title={SVD-matching using SIFT features},
	journal={Graphical Models},
	volume={68},
	number={5-6},
	pages={415-431},
	note={Compilation and indexing terms, Copyright 2008 Elsevier Inc.; undefined; undefined; undefined},
	abstract={The paper tackles the problem of feature points matching between pair of images of the same scene. This is a key problem in computer vision. The method we discuss here is a version of the SVD-matching proposed by Scott and Longuet-Higgins and later modified by Pilu, that we elaborate in order to cope with large scale variations. To this end we add to the feature detection phase a keypoint descriptor that is robust to large scale and view-point changes. Furthermore, we include this descriptor in the equations of the proximity matrix that is central to the SVD-matching. At the same time we remove from the proximity matrix all the information about the point locations in the image, that is the source of mismatches when the amount of scene variation increases. The main contribution of this work is in showing that this compact and easy algorithm can be used for severe scene variations. We present experimental evidence of the improved performance with respect to the previous versions of the algorithm. &copy; 2006 Elsevier Inc. All rights reserved.},
	keywords={Pattern matching; Graphic methods; Image processing; Problem solving; Feature extraction; Robustness (control systems); Algorithms},
	isbn={1524-0703},
	url={http://dx.doi.org/10.1016/j.gmod.2006.07.002}
}



@inproceedings{RefWorks:576,
	author={Feng Zhao and Wen Gao},
	year={2004},
	month={18-20 Dec. 2004},
	title={Singular value decomposition based image matching},
	booktitle={Third International Conference on Image and Graphics},
	series={Proceedings},
	publisher={IEEE Computer Soc},
	address={Los Alamitos, CA, USA},
	organization={Inst. of Comput. Technol., Chinese Acad. of Sci., Beijing, China},
	pages={192-5},
	note={M1: Copyright 2005, IEE; T3: Proceedings. Third International Conference on Image and Graphics; undefined; undefined; undefined; undefined; undefined; undefined; undefined; undefined},
	abstract={This paper presents a simple and effective method for matching two uncalibrated images. Corner points are firstly extracted as interest points in the two images. Each interest point is assigned one dominant orientation. The initial set of point matches is then obtained by singular value decomposition of a correspondence strength matrix. A new expression of this matrix is introduced to handle more complicated imaging conditions. Each element of this matrix is the similarity measure between two interest points. The new similarity measure is invariant to image rotation by taking into account the dominant orientation of the two interest points. The epipolar geometry constraint is finally imposed to reject the false matches. Experimental results on real images show this approach to be effective for general image matching},
	keywords={image matching; matrix algebra; singular value decomposition},
	isbn={0 7695 2244 0}
}

@techreport{RefWorks:577,
	author={M. Pilu},
	year={1997},
	title={Uncalibrated stereo correspondence by singular value decomposition},
	institution={Hwelett Packard Lab Technical Publ Dept},
	pages={3-11},
	note={Compilation and indexing terms, Copyright 2008 Elsevier Inc.; undefined},
	abstract={This paper presents a new simple method for achieving feature correspondence across a pair of images which requires no calibration information and draws from the method proposed by Scott and Longuet Higgins [8]. Despite the well-known combinatorial complexity of the problem, this work shows that an acceptably good solution can be obtained directly by singular value decomposition of an appropriate image-based correspondence strength matrix. The paper includes several experiments and discusses the method and draws comparisons with a related relaxation-based method by [14]. Given its tremendous performance/complexity figure, the method is particularly suitable for research purposes where an off the shelf but reliable feature correspondence is needed. For this reason, a succinct MATLAB implementation of the method is included and a C version will be soon available on the WEB.},
	keywords={Image analysis; Value engineering; Stereo vision; Image segmentation; Combinatorial mathematics; Matrix algebra; Performance}
}

@article{RefWorks:578,
	author={P. H. S. Torr and D. W. Murray},
	year={1997},
	title={The development and comparison of robust methods for estimating the fundamental matrix},
	journal={International Journal of Computer Vision},
	volume={24},
	number={3},
	pages={271-300},
	note={M1: Copyright 1998, IEE; undefined; undefined; undefined; undefined; undefined; undefined; undefined; undefined; undefined; undefined; undefined; undefined; undefined; undefined; undefined; undefined; undefined; undefined; undefined; undefined; undefined; undefined; undefined; undefined},
	abstract={This paper has two goals. The first is to develop a variety of robust methods for the computation of the fundamental matrix, the calibration-free representation of camera motion. The methods are drawn from the principal categories of robust estimators, viz. case deletion diagnostics, M-estimators and random sampling, and the paper develops the theory required to apply them to nonlinear orthogonal regression problems. Although a considerable amount of interest has focused on the application of robust estimation in computer vision, the relative merits of the many individual methods are unknown. The second goal is therefore to compare and judge the methods. Comparative tests are carried out using correspondences generated both synthetically in a statistically controlled fashion and from feature matching in real imagery. In contrast with previously reported methods, the goodness of fit to the synthetic observations is judged not in terms of the fit to the observations per se but in terms of fit to the ground truth. A variety of error measures are examined. The experiments allow a statistically satisfying and quasi-optimal method to be synthesized, which is shown to be stable with up to 50\% outlier contamination, and may still be used if there are more than 50\% outliers. Performance bounds are established for the method, and a variety of robust methods to estimate the standard deviation of the error and covariance matrix of the parameters are examined. The results of the comparison have broad applicability to vision algorithms where the input data are corrupted not only by noise but also by gross outliers},
	keywords={cameras; computer vision; estimation theory; image matching; matrix algebra; motion estimation; statistics},
	isbn={0920-5691},
	url={http://dx.doi.org/10.1023/A:1007927408552}
}

@inproceedings{RefWorks:579,
	author={M. A. O. Vasilescu and D. Terzopoulos},
	year={2002},
	month={28-31 May 2002},
	title={Multilinear analysis of image ensembles: TensorFaces},
	booktitle={Proceedings},
	series={Computer Vision - ECCV 2002. 7th European Conference on Computer Vision},
	publisher={Springer-Verlag},
	address={Berlin, Germany},
	organization={Courant Inst. of Math. Sci., New York Univ., NY, USA},
	pages={447-60},
	note={M1: Copyright 2002, IEE; T3: Computer Vision - ECCV 2002. 7th European Conference on Computer Vision. Proceedings, Part I (Lecture Notes in Computer Science Vol.2350); undefined; undefined; undefined; undefined; undefined; undefined; undefined; undefined; undefined; undefined; undefined; undefined},
	abstract={Natural images are the composite consequence of multiple factors related to scene structure, illumination, and imaging. Multilinear algebra, the algebra of higher-order tensors, offers a potent mathematical framework for analyzing the multifactor structure of image ensembles and for addressing the difficult problem of disentangling the constituent factors or modes. Our multilinear modeling technique employs a tensor extension of the conventional matrix singular value decomposition (SVD), known as the N-mode SVD. As a concrete example, we consider the multilinear analysis of ensembles of facial images that combine several modes, including different facial geometries (people), expressions, head poses, and lighting conditions. Our resulting "TensorFaces" representation has several advantages over conventional eigenfaces. More generally, multilinear analysis shows promise as a unifying framework for a variety of computer vision problems},
	keywords={computer vision; face recognition; image representation; singular value decomposition; tensors},
	isbn={3 540 43745 2}
}

@book{RefWorks:580,
	author={Y. Matsumoto},
	year={2002},
	title={Ruby in a nutshell: a desktop quick reference},
	publisher={O'Reilly}
}

@inproceedings{RefWorks:581,
	author={J. Wedekind and B. Amavasai and K. Dutton},
	year={2008},
	month={24-27 Nov. 2007},
	title={Steerable filters generated with the hypercomplex dual-tree wavelet transform},
	booktitle={2007 IEEE International Conference on Signal Processing and Communications},
	publisher={IEEE},
	address={Piscataway, NJ, USA},
	organization={Mater. \& Eng. Res. Inst., Sheffield Hallam Univ., Sheffield, UK},
	pages={1291-4},
	note={M1: Copyright 2009, The Institution of Engineering and Technology; T3: 2007 IEEE International Conference on Signal Processing and Communications; undefined; undefined; undefined; undefined; undefined; undefined},
	abstract={The use of wavelets in the image processing domain is still in its infancy, and largely associated with image compression. With the advent of the dual-tree hypercomplex wavelet transform (D-HWT) and its improved shift invariance and directional selectivity, applications in other areas of image processing are more conceivable. This paper discusses the problems and solutions in developing the DHWT and its inverse. It also offers a practical implementation of the algorithms involved. The aim of this work is to apply the DHWT in machine vision. Tentative work on a possible new way of feature extraction is presented. The paper shows that 2-D hypercomplex basis wavelets can be used to generate steerable filters which allow rotation as well as translation.},
	keywords={computer vision; feature extraction; filtering theory; trees (mathematics); wavelet transforms},
	url={http://dx.doi.org/10.1109/ICSPC.2007.4728563}
}

@book{RefWorks:582,
	author={John C. Russ},
	year={1995},
	title={The image processing handbook},
	publisher={CRC Press},
	pages={347-480}
}

@book{RefWorks:583,
	author={David MacKay},
	year={2003},
	title={Information Theory, Inference, and Learning Algorithms},
	publisher={Barnes and Noble},
	note={\url{http://www.inference.phy.cam.ac.uk/mackay/itila/book.html}},
        annote={
1	Introduction to Information Theory
		2	Probability, Entropy, and Inference
		3	More about Inference
Part I	Data Compression
		4	The Source Coding Theorem
		5	Symbol Codes
		6	Stream Codes
		7	Codes for Integers
Part II	Noisy-Channel Coding
		8	Dependent Random Variables
		9	Communication over a Noisy Channel
		10	The Noisy-Channel Coding Theorem
		11	Error-Correcting Codes and Real Channels
Part III 	Further Topics in Information Theory
		12	Hash Codes: Codes for Efficient Information Retrieval
		13	Binary Codes
		14	Very Good Linear Codes Exist
		15	Further Exercises on Information Theory
		16	Message Passing
		17	Communication over Constrained Noiseless Channels
		18	Crosswords and Codebreaking
		19	Why have Sex? Information Acquisition and Evolution
Part IV 	Probabilities and Inference
		20	An Example Inference Task: Clustering
		21	Exact Inference by Complete Enumeration
		22	Maximum Likelihood and Clustering
		23	Useful Probability Distributions
		24	Exact Marginalization
		25	Exact Marginalization in Trellises
		26	Exact Marginalization in Graphs
		27	Laplace's Method
		28	Model Comparison and Occam's Razor
		29	Monte Carlo Methods
		30	Efficient Monte Carlo Methods
		31	Ising Models
		32	Exact Monte Carlo Sampling
		33	Variational Methods
		34	Independent Component Analysis and Latent Variable Modelling
		35	Random Inference Topics
		36	Decision Theory
		37	Bayesian Inference and Sampling Theory
Part V 	Neural networks
		38	Introduction to Neural Networks
		39	The Single Neuron as a Classifier
		40	Capacity of a Single Neuron
		41	Learning as Inference
		42	Hopfield Networks
		43	Boltzmann Machines
		44	Supervised Learning in Multilayer Networks
		45	Gaussian Processes
		46	Deconvolution
Part VI 	Sparse Graph Codes
		47	Low-Density Parity-Check Codes
		48	Convolutional Codes and Turbo Codes
		49	Repeat-Accumulate Codes
		50	Digital Fountain Codes
Part VII 	Appendices
			Notation; Some Physics; Some Mathematics}
}

@book{RefWorks:584,
	author={G. Medioni and S. B. Kang},
	year={2004},
	title={Emerging topics in computer vision},
	publisher={Prentice Hall PTR Upper Saddle River, NJ, USA}
}

@Misc{fourcc,
  author =    {Dave Wilson},
  title =     {Video Codecs and Pixel Formats},
  howpublished = {Web site},
  year =      {2007},
  note =      {\url{http://www.fourcc.org/}}
}

@Misc{roberts,
  author =    {Bob Fisher and Simon Perkins and Ashley Walker and Erik Wolfart},
  title =     {Roberts Cross Edge Detector},
  howpublished = {Web page},
  year =      {2003},
  note =      {\url{http://homepages.inf.ed.ac.uk/rbf/HIPR2/roberts.htm}}
}

@Misc{log,
  author =    {Bob Fisher and Simon Perkins and Ashley Walker and Erik Wolfart},
  title =     {Laplacian/Laplacian of Gaussian},
  howpublished = {Web page},
  year =      {1994},
  note =      {\url{http://www.cee.hw.ac.uk/hipr/html/log.html}}
}

@Book{bronstein,
  author =    {M. Bronstein},
  title =     {Symbolic Integration I: Transcendental Functions (Algorithms and Computation in Mathematics)},
  publisher =    {Springer},
  year =         {2004},
  annote =    {ISBN-10: 3540214933, ISBN-13: 978-3540214939}
}


@TechReport{mpl,
  author =    {A. Gurtovoy and D. Abrahams},
  title =     {The {B}oost {C}++ metaprogramming library},
  institution =  {Boost Group},
  year =         {2002},
  note =      {\url{http://www.boost.org/libs/mpl/doc/paper/mpl_paper.pdf}}
}
